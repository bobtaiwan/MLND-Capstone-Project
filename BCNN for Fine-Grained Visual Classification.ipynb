{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student provides a high-level overview of the project in layman’s terms. Background information such as the problem domain, the project origin, and related data sets or input data is given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem which needs to be solved is clearly defined. A strategy for solving the problem, including discussion of the expected solution, has been made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics used to measure performance of a model or result are clearly defined. Metrics are justified based on the characteristics of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a dataset is present, features and calculated statistics relevant to the problem have been reported and discussed, along with a sampling of the data. In lieu of a dataset, a thorough description of the input space or input data has been made. Abnormalities or characteristics about the data or input that need to be addressed have been identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A visualization has been provided that summarizes or extracts a relevant characteristic or feature about the dataset or input data with thorough discussion. Visual cues are clearly defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms and Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms and techniques used in the project are thoroughly discussed and properly justified based on the characteristics of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student clearly defines a benchmark result or threshold for comparing performances of solutions obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All preprocessing steps have been clearly documented. Abnormalities or characteristics about the data or input that needed to be addressed have been corrected. If no data preprocessing is necessary, it has been clearly justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for which metrics, algorithms, and techniques were implemented with the given datasets or input data has been thoroughly documented. Complications that occurred during the coding process are discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of improving upon the algorithms and techniques used is clearly documented. Both the initial and final solutions are reported, along with intermediate solutions, if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model’s qualities — such as parameters — are evaluated in detail. Some type of analysis is used to validate the robustness of the model’s solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final results are compared to the benchmark result or threshold with some type of statistical analysis. Justification is made as to whether the final model and solution is significant enough to have adequately solved the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free-Form Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A visualization has been provided that emphasizes an important quality about the project with thorough discussion. Visual cues are clearly defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student adequately summarizes the end-to-end problem solution and discusses one or two particular aspects of the project they found interesting or difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion is made as to how one aspect of the implementation could be improved. Potential solutions resulting from these improvements are considered and compared/contrasted to the current solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project report follows a well-organized structure and would be readily understood by its intended audience. Each section is written in a clear, concise and specific manner. Few grammatical and spelling mistakes are present. All resources used to complete the project are cited and referenced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is formatted neatly with comments that effectively explain complex implementations. Output produces similar results and solutions as to those discussed in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Tensforflow build BCNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is BCNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BCNN is a recignition architecture that consists of two feature extrators whose outputs are multipled using outer product at each location of the image and pooled to obtaine an image descriptor(as cited in http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf).\n",
    "\n",
    "So basically we need to use two feature extractors, namely A and B, and use the outer product of A and B as the input of FC-layer, the whole architecture as below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BCNN architecture](img/bcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingcheng.yen\\AppData\\Local\\Continuum\\anaconda3\\envs\\python3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from sklearn.utils import shuffle\n",
    "#import tflearn\n",
    "#from tflearn.data_preprocessing import ImagePreprocessing\n",
    "#from tflearn.data_augmentation import ImageAugmentation\n",
    "#import os\n",
    "from tflearn.data_utils import shuffle\n",
    "\n",
    "import pickle \n",
    "#from tflearn.data_utils import image_preloader\n",
    "import h5py\n",
    "import math\n",
    "import logging\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes -- (train, val, test) (506, 112, 112, 3) (203, 112, 112, 3) (203, 112, 112, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = h5py.File('train_112.h5', 'r')\n",
    "val_data = h5py.File('val_112.h5', 'r')\n",
    "X_train, Y_train = train_data['X'], train_data['Y']\n",
    "X_val, Y_val = val_data['X'], val_data['Y']\n",
    "test_data = h5py.File('test_112.h5', 'r')\n",
    "X_test, Y_test = test_data['X'], test_data['Y']\n",
    "print(\"Data shapes -- (train, val, test)\", X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_right_to_left(image_batch):\n",
    "    result = []\n",
    "    for n in range(image_batch.shape[0]):\n",
    "        if bool(random.getrandbits(1)):\n",
    "            result.append(image_batch[n][:,::-1,:])\n",
    "        else:\n",
    "            result.append(image_batch[n])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16_train_last:\n",
    "    \n",
    "    def __init__(self, imgs ,weights=None, sess=None):\n",
    "        self.images=imgs\n",
    "        #self.imgs=imgs\n",
    "        self.last_layer_parameters=[]\n",
    "        self.parameters=[]\n",
    "        self.cnn_layers()\n",
    "        self.fc_layers()\n",
    "        self.weight_file=weights\n",
    "        #self.load_weights(weights, sess)\n",
    "    \n",
    "    def cnn_layers(self):\n",
    "        \n",
    "        \n",
    "        #conv1_1\n",
    "        with tf.name_scope('conv1_1') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                   trainable=False)\n",
    "            conv = tf.nn.conv2d(self.images, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "            \n",
    "        # conv1_2\n",
    "        with tf.name_scope('conv1_2') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64],  dtype=tf.float32),\n",
    "                                   trainable=False)\n",
    "            conv = tf.nn.conv2d(self.conv1_1, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "    \n",
    "        # pool1\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool1')\n",
    "        \n",
    "        # conv2_1\n",
    "        with tf.name_scope('conv2_1') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                   trainable=False)\n",
    "            conv = tf.nn.conv2d(self.pool1, weights, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "            \n",
    "        # conv2_2\n",
    "        with tf.name_scope('conv2_2') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32), trainable=False)\n",
    "            conv = tf.nn.conv2d(self.conv2_1, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            \n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "        \n",
    "        # pool2\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool2')\n",
    "        \n",
    "        # conv3_1\n",
    "        with tf.name_scope('conv3_1') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1),  trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                   trainable=False)\n",
    "\n",
    "            conv = tf.nn.conv2d(self.pool2, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "            \n",
    "         # conv3_2\n",
    "        with tf.name_scope('conv3_2') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                   trainable=False)\n",
    "            conv = tf.nn.conv2d(self.conv3_1, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # conv3_3\n",
    "        with tf.name_scope('conv3_3') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1),  trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                   trainable=False)\n",
    "\n",
    "            conv = tf.nn.conv2d(self.conv3_2, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # pool3\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool3')\n",
    "        \n",
    "         # conv4_1\n",
    "        with tf.name_scope('conv4_1') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                  trainable=False)\n",
    "\n",
    "            conv = tf.nn.conv2d(self.pool3, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # conv4_2\n",
    "        with tf.name_scope('conv4_2') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                  trainable=False)\n",
    "            conv = tf.nn.conv2d(self.conv4_1, weights, [1, 1, 1, 1], padding='SAME')\n",
    "           \n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # conv4_3\n",
    "        with tf.name_scope('conv4_3') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                  trainable=False)\n",
    "            conv = tf.nn.conv2d(self.conv4_2, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # pool4\n",
    "        self.pool4 = tf.nn.max_pool(self.conv4_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "        \n",
    "        # conv5_1\n",
    "        with tf.name_scope('conv5_1') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1),  trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                  trainable=False)\n",
    "            conv = tf.nn.conv2d(self.pool4, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # conv5_2\n",
    "        with tf.name_scope('conv5_2') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                  trainable=False)\n",
    "            conv = tf.nn.conv2d(self.conv5_1, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # conv5_3\n",
    "        with tf.name_scope('conv5_3') as scope:\n",
    "            weights = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), trainable=False)\n",
    "            conv = tf.nn.conv2d(self.conv5_2, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                  trainable=False)\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [weights, biases]\n",
    "        \n",
    "        print('Shape of conv5_3', self.conv5_3.get_shape())\n",
    "        self.phi_I = tf.einsum('ijkm,ijkn->imn', self.conv5_3, self.conv5_3)\n",
    "        print('Shape of phi_I after einsum', self.phi_I.get_shape())\n",
    "        \n",
    "        self.phi_I = tf.reshape(self.phi_I,[-1,512*512])\n",
    "        print('Shape of phi_I after reshape', self.phi_I.get_shape())\n",
    "\n",
    "        self.phi_I = tf.divide(self.phi_I,784.0)  \n",
    "        print('Shape of phi_I after division', self.phi_I.get_shape())\n",
    "\n",
    "        self.y_ssqrt = tf.multiply(tf.sign(self.phi_I),tf.sqrt(tf.abs(self.phi_I)+1e-12))\n",
    "        print('Shape of y_ssqrt', self.y_ssqrt.get_shape())\n",
    "\n",
    "        self.z_l2 = tf.nn.l2_normalize(self.y_ssqrt, axis=1)\n",
    "        print('Shape of z_l2', self.z_l2.get_shape())\n",
    "    \n",
    "    def fc_layers(self):\n",
    "            \n",
    "        with tf.name_scope('fc-new') as scope:\n",
    "            fc3w = tf.get_variable('weights', [512*512, 129], initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                   trainable=True)\n",
    "            fc3b = tf.get_variable(\"b\", [129], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            self.fc3l = tf.nn.bias_add(tf.matmul(self.z_l2, fc3w), fc3b)\n",
    "            self.last_layer_parameters += [fc3w, fc3b]\n",
    "            self.parameters += [fc3w, fc3b]\n",
    "    \n",
    "    def load_weights(self, sess):\n",
    "        weights = np.load(self.weight_file)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            removed_layer_variables = ['fc6_W','fc6_b','fc7_W','fc7_b','fc8_W','fc8_b']\n",
    "            if not k in removed_layer_variables:\n",
    "                print(k)\n",
    "                print(\"\",i, k, np.shape(weights[k]))\n",
    "                sess.run(self.parameters[i].assign(weights[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of conv5_3 (?, 7, 7, 512)\n",
      "Shape of phi_I after einsum (?, 512, 512)\n",
      "Shape of phi_I after reshape (?, 262144)\n",
      "Shape of phi_I after division (?, 262144)\n",
      "Shape of y_ssqrt (?, 262144)\n",
      "Shape of z_l2 (?, 262144)\n",
      "VGG network created\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "#sess = tf.InteractiveSession()\n",
    "#with tf.device('/gpu:0'):\n",
    "imgs = tf.placeholder(tf.float32, [None, 112, 112, 3])\n",
    "target = tf.placeholder(\"float\", [None, 129])\n",
    "#print 'Creating graph'\n",
    "vgg = vgg16_train_last(imgs, 'vgg16_weights.npz', sess)\n",
    "print('VGG network created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-b5713e109704>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "conv1_1_W\n",
      " 0 conv1_1_W (3, 3, 3, 64)\n",
      "conv1_1_b\n",
      " 1 conv1_1_b (64,)\n",
      "conv1_2_W\n",
      " 2 conv1_2_W (3, 3, 64, 64)\n",
      "conv1_2_b\n",
      " 3 conv1_2_b (64,)\n",
      "conv2_1_W\n",
      " 4 conv2_1_W (3, 3, 64, 128)\n",
      "conv2_1_b\n",
      " 5 conv2_1_b (128,)\n",
      "conv2_2_W\n",
      " 6 conv2_2_W (3, 3, 128, 128)\n",
      "conv2_2_b\n",
      " 7 conv2_2_b (128,)\n",
      "conv3_1_W\n",
      " 8 conv3_1_W (3, 3, 128, 256)\n",
      "conv3_1_b\n",
      " 9 conv3_1_b (256,)\n",
      "conv3_2_W\n",
      " 10 conv3_2_W (3, 3, 256, 256)\n",
      "conv3_2_b\n",
      " 11 conv3_2_b (256,)\n",
      "conv3_3_W\n",
      " 12 conv3_3_W (3, 3, 256, 256)\n",
      "conv3_3_b\n",
      " 13 conv3_3_b (256,)\n",
      "conv4_1_W\n",
      " 14 conv4_1_W (3, 3, 256, 512)\n",
      "conv4_1_b\n",
      " 15 conv4_1_b (512,)\n",
      "conv4_2_W\n",
      " 16 conv4_2_W (3, 3, 512, 512)\n",
      "conv4_2_b\n",
      " 17 conv4_2_b (512,)\n",
      "conv4_3_W\n",
      " 18 conv4_3_W (3, 3, 512, 512)\n",
      "conv4_3_b\n",
      " 19 conv4_3_b (512,)\n",
      "conv5_1_W\n",
      " 20 conv5_1_W (3, 3, 512, 512)\n",
      "conv5_1_b\n",
      " 21 conv5_1_b (512,)\n",
      "conv5_2_W\n",
      " 22 conv5_2_W (3, 3, 512, 512)\n",
      "conv5_2_b\n",
      " 23 conv5_2_b (512,)\n",
      "conv5_3_W\n",
      " 24 conv5_3_W (3, 3, 512, 512)\n",
      "conv5_3_b\n",
      " 25 conv5_3_b (512,)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=vgg.fc3l, labels=target))\n",
    "learning_rate_wft = tf.placeholder(tf.float32, shape=[])\n",
    "learning_rate_woft = tf.placeholder(tf.float32, shape=[])\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=0.9, momentum=0.9).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(vgg.fc3l,1), tf.argmax(target,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "num_correct_preds = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "vgg.load_weights(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.4613072872161865 seconds\n",
      "Epoch: 001 Step: 000 Loss: 4.8098063\n",
      "Training Accuracy --> 0.0625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.965406656265259 seconds\n",
      "Epoch: 001 Step: 001 Loss: 4.8075533\n",
      "Training Accuracy --> 0.0625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.982403516769409 seconds\n",
      "Epoch: 001 Step: 002 Loss: 4.8091536\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9394121170043945 seconds\n",
      "Epoch: 001 Step: 003 Loss: 4.7831\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0563886165618896 seconds\n",
      "Epoch: 001 Step: 004 Loss: 4.8032656\n",
      "Training Accuracy --> 0.0625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9214158058166504 seconds\n",
      "Epoch: 001 Step: 005 Loss: 4.7932224\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.083383321762085 seconds\n",
      "Epoch: 001 Step: 006 Loss: 4.8263345\n",
      "Training Accuracy --> 0.0\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.8934214115142822 seconds\n",
      "Epoch: 001 Step: 007 Loss: 4.867536\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0283942222595215 seconds\n",
      "Epoch: 001 Step: 008 Loss: 4.8701963\n",
      "Training Accuracy --> 0.0\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.98240327835083 seconds\n",
      "Epoch: 001 Step: 009 Loss: 4.8521953\n",
      "Training Accuracy --> 0.0625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0173964500427246 seconds\n",
      "Epoch: 001 Step: 010 Loss: 4.793726\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.000399589538574 seconds\n",
      "Epoch: 001 Step: 011 Loss: 4.864131\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.97440505027771 seconds\n",
      "Epoch: 001 Step: 012 Loss: 4.816655\n",
      "Training Accuracy --> 0.0\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.896420478820801 seconds\n",
      "Epoch: 001 Step: 013 Loss: 4.702813\n",
      "Training Accuracy --> 0.0625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.903419256210327 seconds\n",
      "Epoch: 001 Step: 014 Loss: 4.8017035\n",
      "Training Accuracy --> 0.0\n",
      "##############################\n",
      "Validation Loss --> 13.961191177368164\n",
      "correct_val_count, total_val_count 7.0 203\n",
      "Validation Data Accuracy --> 3.4482758620689653\n",
      "##############################\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.1663665771484375 seconds\n",
      "Epoch: 002 Step: 000 Loss: 4.6173778\n",
      "Training Accuracy --> 0.0625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.015397071838379 seconds\n",
      "Epoch: 002 Step: 001 Loss: 4.5887003\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.618276357650757 seconds\n",
      "Epoch: 002 Step: 002 Loss: 4.524932\n",
      "Training Accuracy --> 0.09375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9094178676605225 seconds\n",
      "Epoch: 002 Step: 003 Loss: 4.5308485\n",
      "Training Accuracy --> 0.1875\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0883822441101074 seconds\n",
      "Epoch: 002 Step: 004 Loss: 4.633568\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9484102725982666 seconds\n",
      "Epoch: 002 Step: 005 Loss: 4.456903\n",
      "Training Accuracy --> 0.25\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0683860778808594 seconds\n",
      "Epoch: 002 Step: 006 Loss: 4.558128\n",
      "Training Accuracy --> 0.0625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0658817291259766 seconds\n",
      "Epoch: 002 Step: 007 Loss: 4.488899\n",
      "Training Accuracy --> 0.09375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.997999906539917 seconds\n",
      "Epoch: 002 Step: 008 Loss: 4.386526\n",
      "Training Accuracy --> 0.21875\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.187999963760376 seconds\n",
      "Epoch: 002 Step: 009 Loss: 4.547395\n",
      "Training Accuracy --> 0.0625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.13100004196167 seconds\n",
      "Epoch: 002 Step: 010 Loss: 4.427206\n",
      "Training Accuracy --> 0.15625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.61899995803833 seconds\n",
      "Epoch: 002 Step: 011 Loss: 4.58508\n",
      "Training Accuracy --> 0.125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.176999807357788 seconds\n",
      "Epoch: 002 Step: 012 Loss: 4.6341004\n",
      "Training Accuracy --> 0.03125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.369999885559082 seconds\n",
      "Epoch: 002 Step: 013 Loss: 4.377517\n",
      "Training Accuracy --> 0.25\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.2899999618530273 seconds\n",
      "Epoch: 002 Step: 014 Loss: 4.4798098\n",
      "Training Accuracy --> 0.15625\n",
      "##############################\n",
      "Validation Loss --> 13.028599262237549\n",
      "correct_val_count, total_val_count 32.0 203\n",
      "Validation Data Accuracy --> 15.763546798029557\n",
      "##############################\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.2859997749328613 seconds\n",
      "Epoch: 003 Step: 000 Loss: 4.1620975\n",
      "Training Accuracy --> 0.28125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.049999952316284 seconds\n",
      "Epoch: 003 Step: 001 Loss: 4.3439074\n",
      "Training Accuracy --> 0.15625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.2120001316070557 seconds\n",
      "Epoch: 003 Step: 002 Loss: 4.38791\n",
      "Training Accuracy --> 0.09375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0369999408721924 seconds\n",
      "Epoch: 003 Step: 003 Loss: 4.1313486\n",
      "Training Accuracy --> 0.28125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0970003604888916 seconds\n",
      "Epoch: 003 Step: 004 Loss: 4.2365828\n",
      "Training Accuracy --> 0.125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0950002670288086 seconds\n",
      "Epoch: 003 Step: 005 Loss: 4.267198\n",
      "Training Accuracy --> 0.125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.01200008392334 seconds\n",
      "Epoch: 003 Step: 006 Loss: 4.228491\n",
      "Training Accuracy --> 0.09375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0739996433258057 seconds\n",
      "Epoch: 003 Step: 007 Loss: 4.32698\n",
      "Training Accuracy --> 0.1875\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.128000020980835 seconds\n",
      "Epoch: 003 Step: 008 Loss: 4.143969\n",
      "Training Accuracy --> 0.21875\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.2249999046325684 seconds\n",
      "Epoch: 003 Step: 009 Loss: 4.038701\n",
      "Training Accuracy --> 0.34375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0490000247955322 seconds\n",
      "Epoch: 003 Step: 010 Loss: 4.3070836\n",
      "Training Accuracy --> 0.125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.1569998264312744 seconds\n",
      "Epoch: 003 Step: 011 Loss: 4.135964\n",
      "Training Accuracy --> 0.34375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0360000133514404 seconds\n",
      "Epoch: 003 Step: 012 Loss: 4.256236\n",
      "Training Accuracy --> 0.125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.045999765396118 seconds\n",
      "Epoch: 003 Step: 013 Loss: 4.1635923\n",
      "Training Accuracy --> 0.3125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.057999849319458 seconds\n",
      "Epoch: 003 Step: 014 Loss: 4.3488445\n",
      "Training Accuracy --> 0.09375\n",
      "##############################\n",
      "Validation Loss --> 12.158227920532227\n",
      "correct_val_count, total_val_count 67.0 203\n",
      "Validation Data Accuracy --> 33.004926108374384\n",
      "##############################\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.1700000762939453 seconds\n",
      "Epoch: 004 Step: 000 Loss: 4.012653\n",
      "Training Accuracy --> 0.4375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.169999837875366 seconds\n",
      "Epoch: 004 Step: 001 Loss: 3.8186414\n",
      "Training Accuracy --> 0.53125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0180001258850098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004 Step: 002 Loss: 3.8971255\n",
      "Training Accuracy --> 0.53125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.1010000705718994 seconds\n",
      "Epoch: 004 Step: 003 Loss: 4.019802\n",
      "Training Accuracy --> 0.34375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.989000082015991 seconds\n",
      "Epoch: 004 Step: 004 Loss: 3.9846916\n",
      "Training Accuracy --> 0.34375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9049999713897705 seconds\n",
      "Epoch: 004 Step: 005 Loss: 4.0344834\n",
      "Training Accuracy --> 0.375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.886000156402588 seconds\n",
      "Epoch: 004 Step: 006 Loss: 3.7613595\n",
      "Training Accuracy --> 0.46875\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9010000228881836 seconds\n",
      "Epoch: 004 Step: 007 Loss: 3.912314\n",
      "Training Accuracy --> 0.3125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9100000858306885 seconds\n",
      "Epoch: 004 Step: 008 Loss: 3.9797616\n",
      "Training Accuracy --> 0.4375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9070000648498535 seconds\n",
      "Epoch: 004 Step: 009 Loss: 3.9062405\n",
      "Training Accuracy --> 0.375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.8960001468658447 seconds\n",
      "Epoch: 004 Step: 010 Loss: 3.7267883\n",
      "Training Accuracy --> 0.46875\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9800000190734863 seconds\n",
      "Epoch: 004 Step: 011 Loss: 3.8686385\n",
      "Training Accuracy --> 0.5\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.119999885559082 seconds\n",
      "Epoch: 004 Step: 012 Loss: 3.9685893\n",
      "Training Accuracy --> 0.3125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.932999849319458 seconds\n",
      "Epoch: 004 Step: 013 Loss: 3.9061053\n",
      "Training Accuracy --> 0.4375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0139999389648438 seconds\n",
      "Epoch: 004 Step: 014 Loss: 3.9058075\n",
      "Training Accuracy --> 0.34375\n",
      "##############################\n",
      "Validation Loss --> 11.296071290969849\n",
      "correct_val_count, total_val_count 92.0 203\n",
      "Validation Data Accuracy --> 45.320197044334975\n",
      "##############################\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9070000648498535 seconds\n",
      "Epoch: 005 Step: 000 Loss: 3.7170403\n",
      "Training Accuracy --> 0.5625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.8989999294281006 seconds\n",
      "Epoch: 005 Step: 001 Loss: 3.764962\n",
      "Training Accuracy --> 0.5625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9019999504089355 seconds\n",
      "Epoch: 005 Step: 002 Loss: 3.4821699\n",
      "Training Accuracy --> 0.5\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9110002517700195 seconds\n",
      "Epoch: 005 Step: 003 Loss: 3.6203806\n",
      "Training Accuracy --> 0.46875\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0340001583099365 seconds\n",
      "Epoch: 005 Step: 004 Loss: 3.729566\n",
      "Training Accuracy --> 0.40625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0820000171661377 seconds\n",
      "Epoch: 005 Step: 005 Loss: 3.5532308\n",
      "Training Accuracy --> 0.65625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.01200008392334 seconds\n",
      "Epoch: 005 Step: 006 Loss: 3.6893513\n",
      "Training Accuracy --> 0.46875\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.072999954223633 seconds\n",
      "Epoch: 005 Step: 007 Loss: 3.567214\n",
      "Training Accuracy --> 0.5625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.137000322341919 seconds\n",
      "Epoch: 005 Step: 008 Loss: 3.3112817\n",
      "Training Accuracy --> 0.75\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9159998893737793 seconds\n",
      "Epoch: 005 Step: 009 Loss: 3.881462\n",
      "Training Accuracy --> 0.375\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0440001487731934 seconds\n",
      "Epoch: 005 Step: 010 Loss: 3.7118669\n",
      "Training Accuracy --> 0.40625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0480000972747803 seconds\n",
      "Epoch: 005 Step: 011 Loss: 3.4680953\n",
      "Training Accuracy --> 0.40625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0259997844696045 seconds\n",
      "Epoch: 005 Step: 012 Loss: 3.5580764\n",
      "Training Accuracy --> 0.53125\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  3.0980002880096436 seconds\n",
      "Epoch: 005 Step: 013 Loss: 3.692274\n",
      "Training Accuracy --> 0.40625\n",
      "Last layer training, time to run optimizer for batch size: 32 is -->  2.9240000247955322 seconds\n",
      "Epoch: 005 Step: 014 Loss: 3.6552784\n",
      "Training Accuracy --> 0.46875\n",
      "##############################\n",
      "Validation Loss --> 10.452635765075684\n",
      "correct_val_count, total_val_count 122.0 203\n",
      "Validation Data Accuracy --> 60.09852216748769\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "lr = 1.0\n",
    "base_lr = 1.0\n",
    "\n",
    "for epoch in range(5):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(len(X_train)/batch_size)\n",
    "    X_train, Y_train = shuffle(X_train, Y_train)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = X_train[i*batch_size:i*batch_size+batch_size], Y_train[i*batch_size:i*batch_size+batch_size]\n",
    "        batch_xs = random_flip_right_to_left(batch_xs)\n",
    "        start = time.time()\n",
    "        sess.run(optimizer, feed_dict={imgs: batch_xs, target: batch_ys})\n",
    "        print('Last layer training, time to run optimizer for batch size:', batch_size,'is --> ',time.time()-start,'seconds')\n",
    "        cost = sess.run(loss, feed_dict={imgs: batch_xs, target: batch_ys})\n",
    "        print(\"Epoch:\", '%03d' % (epoch+1), \"Step:\", '%03d' % i,\"Loss:\", str(cost))\n",
    "        print(\"Training Accuracy -->\", sess.run(accuracy,feed_dict={imgs: batch_xs, target: batch_ys}))\n",
    "    \n",
    "    val_batch_size = 64\n",
    "    total_val_count = len(X_val)\n",
    "    correct_val_count = 0\n",
    "    val_loss = 0.0\n",
    "    total_val_batch = int(total_val_count/val_batch_size)\n",
    "    for i in range(total_val_batch):\n",
    "        batch_val_x, batch_val_y = X_val[i*val_batch_size:i*val_batch_size+val_batch_size], Y_val[i*val_batch_size:i*val_batch_size+val_batch_size]\n",
    "        val_loss += sess.run(loss, feed_dict={imgs: batch_val_x, target: batch_val_y})\n",
    "\n",
    "        pred = sess.run(num_correct_preds, feed_dict = {imgs: batch_val_x, target: batch_val_y})\n",
    "        correct_val_count+=pred\n",
    "    \n",
    "    print(\"##############################\")\n",
    "    print(\"Validation Loss -->\", val_loss)\n",
    "    print(\"correct_val_count, total_val_count\", correct_val_count, total_val_count)\n",
    "    print(\"Validation Data Accuracy -->\", 100.0*correct_val_count/(1.0*total_val_count))\n",
    "    print(\"##############################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "correct_test_count, total_test_count 120.0 203\n",
      "Test Data Accuracy --> 59.11330049261084\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_test_count = len(X_test)\n",
    "correct_test_count = 0\n",
    "test_batch_size = 10\n",
    "total_test_batch = int(total_test_count/test_batch_size)\n",
    "for i in range(total_test_batch):\n",
    "    batch_test_x, batch_test_y = X_test[i*test_batch_size:i*test_batch_size+test_batch_size], Y_test[i*test_batch_size:i*test_batch_size+test_batch_size]\n",
    "    pred = sess.run(num_correct_preds, feed_dict = {imgs: batch_test_x, target: batch_test_y})\n",
    "    correct_test_count+=pred\n",
    "\n",
    "print(\"##############################\")\n",
    "print(\"correct_test_count, total_test_count\", correct_test_count, total_test_count)\n",
    "print(\"Test Data Accuracy -->\", 100.0*correct_test_count/(1.0*total_test_count))\n",
    "print(\"##############################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Last Layer Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv1_1/Variable:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'conv1_1/Variable_1:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1_2/Variable:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'conv1_2/Variable_1:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2_1/Variable:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'conv2_1/Variable_1:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2_2/Variable:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'conv2_2/Variable_1:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'conv3_1/Variable:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'conv3_1/Variable_1:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'conv3_2/Variable:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'conv3_2/Variable_1:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'conv3_3/Variable:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'conv3_3/Variable_1:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'conv4_1/Variable:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'conv4_1/Variable_1:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'conv4_2/Variable:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'conv4_2/Variable_1:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'conv4_3/Variable:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'conv4_3/Variable_1:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'conv5_1/Variable:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'conv5_1/Variable_1:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'conv5_2/Variable:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'conv5_2/Variable_1:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'conv5_3/Variable:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'conv5_3/Variable_1:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'weights:0' shape=(262144, 129) dtype=float32_ref>\n",
      "Printing Trainable Variables : (262144, 129)\n",
      "<tf.Variable 'b:0' shape=(129,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (129,)\n",
      "Last layer weights saved\n"
     ]
    }
   ],
   "source": [
    "last_layer_weights = []\n",
    "for v in vgg.parameters:\n",
    "    print(v)\n",
    "    if v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n",
    "        print('Printing Trainable Variables :', sess.run(v).shape)\n",
    "        last_layer_weights.append(sess.run(v))\n",
    "np.savez('last_layers_epoch_5.npz',last_layer_weights)\n",
    "print(\"Last layer weights saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16_finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16_finetuning:\n",
    "    def __init__(self, imgs, weights=None, sess=None):\n",
    "        self.images=imgs\n",
    "        self.imgs = imgs\n",
    "        self.last_layer_parameters = []     ## Parameters in this list will be optimized when only last layer is being trained \n",
    "        self.parameters = []                ## Parameters in this list will be optimized when whole BCNN network is finetuned\n",
    "        self.convlayers()                   ## Create Convolutional layers\n",
    "        self.fc_layers()                    ## Create Fully connected layer\n",
    "        self.weight_file = weights          \n",
    "\n",
    "\n",
    "    def convlayers(self):\n",
    "        \n",
    "        # conv1_1\n",
    "        with tf.variable_scope(\"conv1_1\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,3,64], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [64], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.images, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv1_1 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "\n",
    "        # conv1_2\n",
    "        with tf.variable_scope(\"conv1_2\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,64,64], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [64], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.conv1_1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv1_2 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # pool1\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool1')\n",
    "\n",
    "        # conv2_1\n",
    "        with tf.variable_scope(\"conv2_1\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,64,128], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [128], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.pool1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv2_1 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "\n",
    "\n",
    "        # conv2_2\n",
    "        with tf.variable_scope(\"conv2_2\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,128,128], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [128], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.conv2_1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv2_2 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "\n",
    "        # pool2\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool2')\n",
    "\n",
    "        # conv3_1\n",
    "        with tf.variable_scope(\"conv3_1\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,128,256], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [256], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.pool2, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv3_1 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "\n",
    "        # conv3_2\n",
    "        with tf.variable_scope(\"conv3_2\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,256,256], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [256], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.conv3_1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv3_2 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # conv3_3\n",
    "        with tf.variable_scope(\"conv3_3\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,256,256], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [256], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.conv3_2, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv3_3 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "\n",
    "        # pool3\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool3')\n",
    "\n",
    "        # conv4_1\n",
    "        with tf.variable_scope(\"conv4_1\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,256,512], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [512], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.pool3, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv4_1 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "\n",
    "        # conv4_2\n",
    "        with tf.variable_scope(\"conv4_2\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [512], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.conv4_1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv4_2 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "\n",
    "        # conv4_3\n",
    "        with tf.variable_scope(\"conv4_3\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [512], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.conv4_2, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv4_3 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        # pool4\n",
    "        self.pool4 = tf.nn.max_pool(self.conv4_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "        # conv5_1\n",
    "        with tf.variable_scope(\"conv5_1\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [512], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.pool4, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv5_1 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "\n",
    "        # conv5_2\n",
    "        with tf.variable_scope(\"conv5_2\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [512], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.conv5_1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv5_2 = tf.nn.relu(conv + biases)\n",
    "            self.parameters += [weights, biases]\n",
    "            \n",
    "\n",
    "        # conv5_3\n",
    "        with tf.variable_scope(\"conv5_3\"):\n",
    "            weights = tf.get_variable(\"W\", [3,3,512,512], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "             # Create variable named \"biases\".\n",
    "            biases = tf.get_variable(\"b\", [512], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            conv = tf.nn.conv2d(self.conv5_2, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            self.conv5_3 = tf.nn.relu(conv + biases)\n",
    "\n",
    "            self.parameters += [weights, biases]\n",
    "\n",
    "        #self.conv5_3 = tf.transpose(self.conv5_3, perm=[0,3,1,2])       \n",
    "        #self.conv5_3 = tf.reshape(self.conv5_3,[-1,512,36])          \n",
    "        #conv5_3_T = tf.transpose(self.conv5_3, perm=[0,2,1])     \n",
    "        #self.phi_I = tf.matmul(self.conv5_3, conv5_3_T)        \n",
    "\n",
    "        print('Shape of conv5_3', self.conv5_3.get_shape())\n",
    "        self.phi_I = tf.einsum('ijkm,ijkn->imn', self.conv5_3, self.conv5_3)\n",
    "        print('Shape of phi_I after einsum', self.phi_I.get_shape())\n",
    "        self.phi_I = tf.reshape(self.phi_I,[-1,512*512])            \n",
    "        \n",
    "        print('Shape of phi_I after reshape', self.phi_I.get_shape())\n",
    "\n",
    "        self.phi_I = tf.divide(self.phi_I,784.0)  \n",
    "        \n",
    "        print('Shape of phi_I after division', self.phi_I.get_shape())  \n",
    "\n",
    "        self.y_ssqrt = tf.multiply(tf.sign(self.phi_I),tf.sqrt(tf.abs(self.phi_I)+1e-12))       \n",
    "        print('Shape of y_ssqrt', self.y_ssqrt.get_shape())\n",
    "\n",
    "        self.z_l2 = tf.nn.l2_normalize(self.y_ssqrt, dim=1)     \n",
    "        print('Shape of z_l2', self.z_l2.get_shape())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fc_layers(self):\n",
    "\n",
    "        with tf.variable_scope('fc-new') as scope:\n",
    "            fc3w = tf.get_variable('W', [512*512, 129], initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "            #fc3b = tf.Variable(tf.constant(1.0, shape=[100], dtype=tf.float32), name='biases', trainable=True)\n",
    "            fc3b = tf.get_variable(\"b\", [129], initializer=tf.constant_initializer(0.1), trainable=True)\n",
    "            self.fc3l = tf.nn.bias_add(tf.matmul(self.z_l2, fc3w), fc3b)\n",
    "            self.last_layer_parameters += [fc3w, fc3b]\n",
    "\n",
    "    def load_initial_weights(self, session):\n",
    "\n",
    "        '''weight_dict contains weigths of VGG16 layers'''\n",
    "        weights_dict = np.load(self.weight_file, encoding = 'bytes')\n",
    "\n",
    "        \n",
    "        '''Loop over all layer names stored in the weights dict\n",
    "           Load only conv-layers. Skip fc-layers in VGG16'''\n",
    "        vgg_layers = ['conv1_1','conv1_2','conv2_1','conv2_2','conv3_1','conv3_2','conv3_3','conv4_1','conv4_2','conv4_3','conv5_1','conv5_2','conv5_3']\n",
    "        \n",
    "        for op_name in vgg_layers:\n",
    "            with tf.variable_scope(op_name, reuse = True):\n",
    "                \n",
    "              # Loop over list of weights/biases and assign them to their corresponding tf variable\n",
    "                # Biases\n",
    "              \n",
    "              var = tf.get_variable('b', trainable = True)\n",
    "              print('Adding weights to',var.name)\n",
    "              session.run(var.assign(weights_dict[op_name+'_b']))\n",
    "                  \n",
    "            # Weights\n",
    "              var = tf.get_variable('W', trainable = True)\n",
    "              print('Adding weights to',var.name)\n",
    "              session.run(var.assign(weights_dict[op_name+'_W']))\n",
    "\n",
    "        with tf.variable_scope('fc-new', reuse = True):\n",
    "            '''\n",
    "            Load fc-layer weights trained in the first step. \n",
    "            Use file .py to train last layer\n",
    "            '''\n",
    "            last_layer_weights = np.load('last_layers_epoch_5.npz')\n",
    "            print('Last layer weights: last_layers_epoch_5.npz')\n",
    "            var = tf.get_variable('W', trainable = True)\n",
    "            print('Adding weights to',var.name)\n",
    "            session.run(var.assign(last_layer_weights['arr_0'][0]))\n",
    "            var = tf.get_variable('b', trainable = True)\n",
    "            print('Adding weights to',var.name)\n",
    "            session.run(var.assign(last_layer_weights['arr_0'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of conv5_3 (?, 7, 7, 512)\n",
      "Shape of phi_I after einsum (?, 512, 512)\n",
      "Shape of phi_I after reshape (?, 262144)\n",
      "Shape of phi_I after division (?, 262144)\n",
      "Shape of y_ssqrt (?, 262144)\n",
      "WARNING:tensorflow:From <ipython-input-4-d4f49f4d29cc>:189: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "Shape of z_l2 (?, 262144)\n",
      "VGG network created\n",
      "WARNING:tensorflow:From <ipython-input-5-85868b8fc028>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "['conv1_1/W:0', 'conv1_1/b:0', 'conv1_2/W:0', 'conv1_2/b:0', 'conv2_1/W:0', 'conv2_1/b:0', 'conv2_2/W:0', 'conv2_2/b:0', 'conv3_1/W:0', 'conv3_1/b:0', 'conv3_2/W:0', 'conv3_2/b:0', 'conv3_3/W:0', 'conv3_3/b:0', 'conv4_1/W:0', 'conv4_1/b:0', 'conv4_2/W:0', 'conv4_2/b:0', 'conv4_3/W:0', 'conv4_3/b:0', 'conv5_1/W:0', 'conv5_1/b:0', 'conv5_2/W:0', 'conv5_2/b:0', 'conv5_3/W:0', 'conv5_3/b:0']\n",
      "Adding weights to conv1_1/b:0\n",
      "Adding weights to conv1_1/W:0\n",
      "Adding weights to conv1_2/b:0\n",
      "Adding weights to conv1_2/W:0\n",
      "Adding weights to conv2_1/b:0\n",
      "Adding weights to conv2_1/W:0\n",
      "Adding weights to conv2_2/b:0\n",
      "Adding weights to conv2_2/W:0\n",
      "Adding weights to conv3_1/b:0\n",
      "Adding weights to conv3_1/W:0\n",
      "Adding weights to conv3_2/b:0\n",
      "Adding weights to conv3_2/W:0\n",
      "Adding weights to conv3_3/b:0\n",
      "Adding weights to conv3_3/W:0\n",
      "Adding weights to conv4_1/b:0\n",
      "Adding weights to conv4_1/W:0\n",
      "Adding weights to conv4_2/b:0\n",
      "Adding weights to conv4_2/W:0\n",
      "Adding weights to conv4_3/b:0\n",
      "Adding weights to conv4_3/W:0\n",
      "Adding weights to conv5_1/b:0\n",
      "Adding weights to conv5_1/W:0\n",
      "Adding weights to conv5_2/b:0\n",
      "Adding weights to conv5_2/W:0\n",
      "Adding weights to conv5_3/b:0\n",
      "Adding weights to conv5_3/W:0\n",
      "Last layer weights: last_layers_epoch_5.npz\n",
      "Adding weights to fc-new/W:0\n",
      "Adding weights to fc-new/b:0\n",
      "['conv1_1/W:0', 'conv1_1/b:0', 'conv1_2/W:0', 'conv1_2/b:0', 'conv2_1/W:0', 'conv2_1/b:0', 'conv2_2/W:0', 'conv2_2/b:0', 'conv3_1/W:0', 'conv3_1/b:0', 'conv3_2/W:0', 'conv3_2/b:0', 'conv3_3/W:0', 'conv3_3/b:0', 'conv4_1/W:0', 'conv4_1/b:0', 'conv4_2/W:0', 'conv4_2/b:0', 'conv4_3/W:0', 'conv4_3/b:0', 'conv5_1/W:0', 'conv5_1/b:0', 'conv5_2/W:0', 'conv5_2/b:0', 'conv5_3/W:0', 'conv5_3/b:0']\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()     ## Start session to create training graph\n",
    "\n",
    "imgs = tf.placeholder(tf.float32, [None, 112, 112, 3])\n",
    "target = tf.placeholder(\"float\", [None, 129])\n",
    "#print 'Creating graph'\n",
    "vgg = vgg16_finetuning(imgs, 'vgg16_weights.npz', sess)\n",
    "\n",
    "print('VGG network created')\n",
    "    \n",
    "# Defining other ops using Tensorflow\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=vgg.fc3l, labels=target))\n",
    "print([_.name for _ in vgg.parameters])\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=0.001, momentum=0.9).minimize(loss)\n",
    "check_op = tf.add_check_numerics_ops()\n",
    "correct_prediction = tf.equal(tf.argmax(vgg.fc3l,1), tf.argmax(target,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "num_correct_preds = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "vgg.load_initial_weights(sess)\n",
    "print([_.name for _ in vgg.parameters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train finetuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable variables <tf.Variable 'conv1_1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv1_1/b:0' shape=(64,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv1_2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv1_2/b:0' shape=(64,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv2_1/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv2_1/b:0' shape=(128,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv2_2/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv2_2/b:0' shape=(128,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_1/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_1/b:0' shape=(256,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_2/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_2/b:0' shape=(256,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_3/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_3/b:0' shape=(256,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_1/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_1/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_2/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_3/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_1/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_1/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_2/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_3/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'fc-new/W:0' shape=(262144, 129) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'fc-new/b:0' shape=(129,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "for v in tf.trainable_variables():\n",
    "        print(\"Trainable variables\", v)\n",
    "        \n",
    "batch_size = 16\n",
    "lr = 0.001\n",
    "finetune_step = -1\n",
    "validation_accuracy_buffer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full BCNN finetuning, time to run optimizer for batch size 16: 11.992999792098999 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 001 Step: 000 Loss: 3.2198853\n",
      "Training Accuracy --> 0.8125\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 11.009000301361084 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 001 Step: 020 Loss: 3.6173303\n",
      "Training Accuracy --> 0.5\n",
      "##############################\n",
      "Validation Loss --> 68.63584733009338\n",
      "correct_val_count, total_val_count 118.0 203\n",
      "Validation Data Accuracy --> 58.12807881773399\n",
      "##############################\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 10.61299991607666 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 002 Step: 000 Loss: 3.4130616\n",
      "Training Accuracy --> 0.75\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 10.877000093460083 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 002 Step: 020 Loss: 3.2949257\n",
      "Training Accuracy --> 0.6875\n",
      "##############################\n",
      "Validation Loss --> 67.8575131893158\n",
      "correct_val_count, total_val_count 118.0 203\n",
      "Validation Data Accuracy --> 58.12807881773399\n",
      "##############################\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 10.82200026512146 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 003 Step: 000 Loss: 3.3360875\n",
      "Training Accuracy --> 0.6875\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 10.88700008392334 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 003 Step: 020 Loss: 3.3079522\n",
      "Training Accuracy --> 0.75\n",
      "##############################\n",
      "Validation Loss --> 67.29875612258911\n",
      "correct_val_count, total_val_count 122.0 203\n",
      "Validation Data Accuracy --> 60.09852216748769\n",
      "##############################\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 11.03000020980835 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 004 Step: 000 Loss: 3.3144493\n",
      "Training Accuracy --> 0.5625\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 10.70799994468689 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 004 Step: 020 Loss: 3.2708192\n",
      "Training Accuracy --> 0.6875\n",
      "##############################\n",
      "Validation Loss --> 66.80294394493103\n",
      "correct_val_count, total_val_count 125.0 203\n",
      "Validation Data Accuracy --> 61.576354679802954\n",
      "##############################\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 10.82200026512146 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 005 Step: 000 Loss: 3.4130907\n",
      "Training Accuracy --> 0.5\n",
      "Full BCNN finetuning, time to run optimizer for batch size 16: 10.735999822616577 seconds\n",
      "Learning rate:  0.001\n",
      "Fine tuning all BCNN_DD\n",
      "Epoch: 005 Step: 020 Loss: 3.5159285\n",
      "Training Accuracy --> 0.5625\n",
      "##############################\n",
      "Validation Loss --> 66.48347854614258\n",
      "correct_val_count, total_val_count 128.0 203\n",
      "Validation Data Accuracy --> 63.05418719211823\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(len(X_train)/batch_size)\n",
    "    X_train, Y_train = shuffle(X_train, Y_train)\n",
    "\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = X_train[i*batch_size:i*batch_size+batch_size], Y_train[i*batch_size:i*batch_size+batch_size]\n",
    "        batch_xs = random_flip_right_to_left(batch_xs)    \n",
    "        start = time.time()\n",
    "        sess.run([optimizer,check_op], feed_dict={imgs: batch_xs, target: batch_ys})\n",
    "        if i%20==0:\n",
    "            print('Full BCNN finetuning, time to run optimizer for batch size 16:',time.time()-start,'seconds')\n",
    "\n",
    "\n",
    "        cost = sess.run(loss, feed_dict={imgs: batch_xs, target: batch_ys})\n",
    "            \n",
    "        if i % 20 == 0:\n",
    "            print ('Learning rate: ', (str(lr)))\n",
    "            if epoch <= finetune_step:\n",
    "                print(\"Training last layer of BCNN_DD\")\n",
    "            else:\n",
    "                print(\"Fine tuning all BCNN_DD\")\n",
    "\n",
    "            print(\"Epoch:\", '%03d' % (epoch+1), \"Step:\", '%03d' % i,\"Loss:\", str(cost))\n",
    "            print(\"Training Accuracy -->\", accuracy.eval(feed_dict={imgs: batch_xs, target: batch_ys}, session=sess))\n",
    "    val_batch_size = 10\n",
    "    total_val_count = len(X_val)\n",
    "    correct_val_count = 0\n",
    "    val_loss = 0.0\n",
    "    total_val_batch = int(total_val_count/val_batch_size)\n",
    "    for i in range(total_val_batch):\n",
    "        batch_val_x, batch_val_y = X_val[i*val_batch_size:i*val_batch_size+val_batch_size], Y_val[i*val_batch_size:i*val_batch_size+val_batch_size]\n",
    "        val_loss += sess.run(loss, feed_dict={imgs: batch_val_x, target: batch_val_y})\n",
    "\n",
    "        pred = sess.run(num_correct_preds, feed_dict = {imgs: batch_val_x, target: batch_val_y})\n",
    "        correct_val_count+=pred\n",
    "\n",
    "    print(\"##############################\")\n",
    "    print(\"Validation Loss -->\", val_loss)\n",
    "    print(\"correct_val_count, total_val_count\", correct_val_count, total_val_count)\n",
    "    print(\"Validation Data Accuracy -->\", 100.0*correct_val_count/(1.0*total_val_count))\n",
    "    print(\"##############################\")\n",
    "\n",
    "    if epoch>40:\n",
    "\n",
    "        validation_accuracy_buffer.append(100.0*correct_val_count/(1.0*total_val_count))\n",
    "        ## Check if the validation accuracy has stopped increasing\n",
    "        if len(validation_accuracy_buffer)>10:\n",
    "            index_of_max_val_acc = np.argmax(validation_accuracy_buffer)\n",
    "            if index_of_max_val_acc==0:\n",
    "                break\n",
    "            else:\n",
    "                del validation_accuracy_buffer[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv1_1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 3, 64)\n",
      "<tf.Variable 'conv1_1/b:0' shape=(64,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (64,)\n",
      "<tf.Variable 'conv1_2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 64, 64)\n",
      "<tf.Variable 'conv1_2/b:0' shape=(64,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (64,)\n",
      "<tf.Variable 'conv2_1/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 64, 128)\n",
      "<tf.Variable 'conv2_1/b:0' shape=(128,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (128,)\n",
      "<tf.Variable 'conv2_2/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 128, 128)\n",
      "<tf.Variable 'conv2_2/b:0' shape=(128,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (128,)\n",
      "<tf.Variable 'conv3_1/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 128, 256)\n",
      "<tf.Variable 'conv3_1/b:0' shape=(256,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (256,)\n",
      "<tf.Variable 'conv3_2/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 256, 256)\n",
      "<tf.Variable 'conv3_2/b:0' shape=(256,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (256,)\n",
      "<tf.Variable 'conv3_3/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 256, 256)\n",
      "<tf.Variable 'conv3_3/b:0' shape=(256,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (256,)\n",
      "<tf.Variable 'conv4_1/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 256, 512)\n",
      "<tf.Variable 'conv4_1/b:0' shape=(512,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (512,)\n",
      "<tf.Variable 'conv4_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 512, 512)\n",
      "<tf.Variable 'conv4_2/b:0' shape=(512,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (512,)\n",
      "<tf.Variable 'conv4_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 512, 512)\n",
      "<tf.Variable 'conv4_3/b:0' shape=(512,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (512,)\n",
      "<tf.Variable 'conv5_1/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 512, 512)\n",
      "<tf.Variable 'conv5_1/b:0' shape=(512,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (512,)\n",
      "<tf.Variable 'conv5_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 512, 512)\n",
      "<tf.Variable 'conv5_2/b:0' shape=(512,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (512,)\n",
      "<tf.Variable 'conv5_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Printing Trainable Variables : (3, 3, 512, 512)\n",
      "<tf.Variable 'conv5_3/b:0' shape=(512,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (512,)\n",
      "<tf.Variable 'fc-new/W:0' shape=(262144, 129) dtype=float32_ref>\n",
      "Printing Trainable Variables : (262144, 129)\n",
      "<tf.Variable 'fc-new/b:0' shape=(129,) dtype=float32_ref>\n",
      "Printing Trainable Variables : (129,)\n",
      "full layer weights saved\n"
     ]
    }
   ],
   "source": [
    "full_layer_weights = []\n",
    "for v in vgg.parameters:\n",
    "    print(v)\n",
    "    if v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n",
    "        print('Printing Trainable Variables :', sess.run(v).shape)\n",
    "        full_layer_weights.append(sess.run(v))\n",
    "for v in vgg.last_layer_parameters:\n",
    "    print(v)\n",
    "    if v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n",
    "        print('Printing Trainable Variables :', sess.run(v).shape)\n",
    "        full_layer_weights.append(sess.run(v))\n",
    "        \n",
    "np.savez('full_layers_epoch_5.npz',full_layer_weights)\n",
    "print(\"full layer weights saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12800, 96, 96, 3)\n",
      "(12800,)\n"
     ]
    }
   ],
   "source": [
    "test_data = h5py.File('test_96.h5', 'r')\n",
    "X_test, Y_test = test_data['X'], test_data['Y']\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(vgg.fc3l,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27 117  83  63  86  99  74  19   7  83]\n",
      "[  1.00000000e+00   1.00000000e+01   1.00000000e+02   1.00000000e+03\n",
      "   1.00000000e+04   1.00010000e+04   1.00020000e+04   1.00030000e+04\n",
      "   1.00040000e+04   1.00050000e+04]\n",
      "[ 31  80 106 122 117 106  27  96  40 122]\n",
      "[ 10006.  10007.  10008.  10009.   1001.  10010.  10011.  10012.  10013.\n",
      "  10014.]\n",
      "[ 35  78  43  62  94  58  26 101  43  13]\n",
      "[ 10015.  10016.  10017.  10018.  10019.   1002.  10020.  10021.  10022.\n",
      "  10023.]\n",
      "[113   2 111   6  54   8  45  28  94  22]\n",
      "[ 10024.  10025.  10026.  10027.  10028.  10029.   1003.  10030.  10031.\n",
      "  10032.]\n",
      "[ 36   9  17  27  68  29  40 121  31  85]\n",
      "[ 10033.  10034.  10035.  10036.  10037.  10038.  10039.   1004.  10040.\n",
      "  10041.]\n",
      "[ 78  11   2  72  60  90 106  88  14  31]\n",
      "[ 10042.  10043.  10044.  10045.  10046.  10047.  10048.  10049.   1005.\n",
      "  10050.]\n",
      "[ 13  45  74 116  83  67 101 123  79  33]\n",
      "[ 10051.  10052.  10053.  10054.  10055.  10056.  10057.  10058.  10059.\n",
      "   1006.]\n",
      "[  4  56  35  86  37  31  88  29  91 122]\n",
      "[ 10060.  10061.  10062.  10063.  10064.  10065.  10066.  10067.  10068.\n",
      "  10069.]\n",
      "[ 43  16   4  17  31   2 121 114  40 116]\n",
      "[  1007.  10070.  10071.  10072.  10073.  10074.  10075.  10076.  10077.\n",
      "  10078.]\n",
      "[108  58  11  78  13  45  45  46  96 123]\n",
      "[ 10079.   1008.  10080.  10081.  10082.  10083.  10084.  10085.  10086.\n",
      "  10087.]\n",
      "[ 52  81 102 122  24  84  68   1  20  45]\n",
      "[ 10088.  10089.   1009.  10090.  10091.  10092.  10093.  10094.  10095.\n",
      "  10096.]\n",
      "[ 9 53 19 67 63 63 49 86 86 54]\n",
      "[ 10097.  10098.  10099.    101.   1010.  10100.  10101.  10102.  10103.\n",
      "  10104.]\n",
      "[ 28  85 122  74 126 122  79 121 106  68]\n",
      "[ 10105.  10106.  10107.  10108.  10109.   1011.  10110.  10111.  10112.\n",
      "  10113.]\n",
      "[ 45  24  90  78 104  65  45  35   8  26]\n",
      "[ 10114.  10115.  10116.  10117.  10118.  10119.   1012.  10120.  10121.\n",
      "  10122.]\n",
      "[ 27  38  35  85 122  75  89  21  64 115]\n",
      "[ 10123.  10124.  10125.  10126.  10127.  10128.  10129.   1013.  10130.\n",
      "  10131.]\n",
      "[ 63  52  88   4 112  75 108  34  50  89]\n",
      "[ 10132.  10133.  10134.  10135.  10136.  10137.  10138.  10139.   1014.\n",
      "  10140.]\n",
      "[ 86  97  78 122  79 112  57 116 111 111]\n",
      "[ 10141.  10142.  10143.  10144.  10145.  10146.  10147.  10148.  10149.\n",
      "   1015.]\n",
      "[ 80  83   3 107 123 116  96  28  91  39]\n",
      "[ 10150.  10151.  10152.  10153.  10154.  10155.  10156.  10157.  10158.\n",
      "  10159.]\n",
      "[ 20 109  63  68  54 123  74  44  45  16]\n",
      "[  1016.  10160.  10161.  10162.  10163.  10164.  10165.  10166.  10167.\n",
      "  10168.]\n",
      "[ 86 117  56   5  79 107 106  53  87  83]\n",
      "[ 10169.   1017.  10170.  10171.  10172.  10173.  10174.  10175.  10176.\n",
      "  10177.]\n",
      "[128 123  53  79  43  74 106 108  57 106]\n",
      "[ 10178.  10179.   1018.  10180.  10181.  10182.  10183.  10184.  10185.\n",
      "  10186.]\n",
      "[ 78  46  93  58 110  98  16  10  53  16]\n",
      "[ 10187.  10188.  10189.   1019.  10190.  10191.  10192.  10193.  10194.\n",
      "  10195.]\n",
      "[ 83  58  79 128  81 115  20  43  27  17]\n",
      "[ 10196.  10197.  10198.  10199.    102.   1020.  10200.  10201.  10202.\n",
      "  10203.]\n",
      "[  8  13  82 111  72  74 112 127   6 111]\n",
      "[ 10204.  10205.  10206.  10207.  10208.  10209.   1021.  10210.  10211.\n",
      "  10212.]\n",
      "[108  96  16 122  80  37  28 116  79  76]\n",
      "[ 10213.  10214.  10215.  10216.  10217.  10218.  10219.   1022.  10220.\n",
      "  10221.]\n",
      "[124  53  41 117  78  83  14  75  98  38]\n",
      "[ 10222.  10223.  10224.  10225.  10226.  10227.  10228.  10229.   1023.\n",
      "  10230.]\n",
      "[ 54  96   1  17  53  48 121  75  27  54]\n",
      "[ 10231.  10232.  10233.  10234.  10235.  10236.  10237.  10238.  10239.\n",
      "   1024.]\n",
      "[ 79  88 110  53  16  78   3  19  82  35]\n",
      "[ 10240.  10241.  10242.  10243.  10244.  10245.  10246.  10247.  10248.\n",
      "  10249.]\n",
      "[ 13  81  53  14  27 121 108  35  95  76]\n",
      "[  1025.  10250.  10251.  10252.  10253.  10254.  10255.  10256.  10257.\n",
      "  10258.]\n",
      "[109 111  61  70  77  85  83  96   3  48]\n",
      "[ 10259.   1026.  10260.  10261.  10262.  10263.  10264.  10265.  10266.\n",
      "  10267.]\n",
      "[ 27  65  18  68  78 126  83 108  19  54]\n",
      "[ 10268.  10269.   1027.  10270.  10271.  10272.  10273.  10274.  10275.\n",
      "  10276.]\n",
      "[ 65  22  36 116  95 102  86  67 116  90]\n",
      "[ 10277.  10278.  10279.   1028.  10280.  10281.  10282.  10283.  10284.\n",
      "  10285.]\n",
      "[ 48  65  20  10  56  53  68 126 111 108]\n",
      "[ 10286.  10287.  10288.  10289.   1029.  10290.  10291.  10292.  10293.\n",
      "  10294.]\n",
      "[122  20 118 122  61  35  78  17  67   1]\n",
      "[ 10295.  10296.  10297.  10298.  10299.    103.   1030.  10300.  10301.\n",
      "  10302.]\n",
      "[  5 122  62  17 122  11  10 123  45  20]\n",
      "[ 10303.  10304.  10305.  10306.  10307.  10308.  10309.   1031.  10310.\n",
      "  10311.]\n",
      "[ 63 124 128  83 107 122  20  83 104  77]\n",
      "[ 10312.  10313.  10314.  10315.  10316.  10317.  10318.  10319.   1032.\n",
      "  10320.]\n",
      "[120  97  96  48   1   3 116  81  35  23]\n",
      "[ 10321.  10322.  10323.  10324.  10325.  10326.  10327.  10328.  10329.\n",
      "   1033.]\n",
      "[ 83  75 127   7 111  37  18 117 121  54]\n",
      "[ 10330.  10331.  10332.  10333.  10334.  10335.  10336.  10337.  10338.\n",
      "  10339.]\n",
      "[22 28 54 52 35 31  6 50 14 21]\n",
      "[  1034.  10340.  10341.  10342.  10343.  10344.  10345.  10346.  10347.\n",
      "  10348.]\n",
      "[ 74 109  20  65  38  33  43 108  53  46]\n",
      "[ 10349.   1035.  10350.  10351.  10352.  10353.  10354.  10355.  10356.\n",
      "  10357.]\n",
      "[ 40  74  61  10  19  68  54  86 102  94]\n",
      "[ 10358.  10359.   1036.  10360.  10361.  10362.  10363.  10364.  10365.\n",
      "  10366.]\n",
      "[ 76   8  19   3 115  27  54  52  58  20]\n",
      "[ 10367.  10368.  10369.   1037.  10370.  10371.  10372.  10373.  10374.\n",
      "  10375.]\n",
      "[122  99   5  31  45  54  45  29  33  52]\n",
      "[ 10376.  10377.  10378.  10379.   1038.  10380.  10381.  10382.  10383.\n",
      "  10384.]\n",
      "[ 68   3 111  77  74 110  85  61  27  28]\n",
      "[ 10385.  10386.  10387.  10388.  10389.   1039.  10390.  10391.  10392.\n",
      "  10393.]\n",
      "[ 85  74  35  82 106 101  53  95  89 110]\n",
      "[ 10394.  10395.  10396.  10397.  10398.  10399.    104.   1040.  10400.\n",
      "  10401.]\n",
      "[ 74   4 120 116 107 108 108 123  11  35]\n",
      "[ 10402.  10403.  10404.  10405.  10406.  10407.  10408.  10409.   1041.\n",
      "  10410.]\n",
      "[ 56   5  19  95  67 111  54  20   8  61]\n",
      "[ 10411.  10412.  10413.  10414.  10415.  10416.  10417.  10418.  10419.\n",
      "   1042.]\n",
      "[ 45 122  46  85 122 108 121  41 122  30]\n",
      "[ 10420.  10421.  10422.  10423.  10424.  10425.  10426.  10427.  10428.\n",
      "  10429.]\n",
      "[ 49  96  85 101   3  67 116  52  78   5]\n",
      "[  1043.  10430.  10431.  10432.  10433.  10434.  10435.  10436.  10437.\n",
      "  10438.]\n",
      "[ 27  85 127  53  43  84  28  63 122 122]\n",
      "[ 10439.   1044.  10440.  10441.  10442.  10443.  10444.  10445.  10446.\n",
      "  10447.]\n",
      "[ 14  20  51  28 109  83 106  28  90  80]\n",
      "[ 10448.  10449.   1045.  10450.  10451.  10452.  10453.  10454.  10455.\n",
      "  10456.]\n",
      "[ 4 96 45 75 75 96 65  5 35 11]\n",
      "[ 10457.  10458.  10459.   1046.  10460.  10461.  10462.  10463.  10464.\n",
      "  10465.]\n",
      "[ 95  57   3  37  57  52 111 117  45  68]\n",
      "[ 10466.  10467.  10468.  10469.   1047.  10470.  10471.  10472.  10473.\n",
      "  10474.]\n",
      "[  7 121  80  64  62 112  62  54 104  45]\n",
      "[ 10475.  10476.  10477.  10478.  10479.   1048.  10480.  10481.  10482.\n",
      "  10483.]\n",
      "[ 19  79  13  90 123  96  74  94   8  19]\n",
      "[ 10484.  10485.  10486.  10487.  10488.  10489.   1049.  10490.  10491.\n",
      "  10492.]\n",
      "[ 48  94  83  84  11  49  87 122  48  76]\n",
      "[ 10493.  10494.  10495.  10496.  10497.  10498.  10499.    105.   1050.\n",
      "  10500.]\n",
      "[ 83   4  16   7   6  79  45   3  11 123]\n",
      "[ 10501.  10502.  10503.  10504.  10505.  10506.  10507.  10508.  10509.\n",
      "   1051.]\n",
      "[ 20  28  61  83  94  78 123 117 118  74]\n",
      "[ 10510.  10511.  10512.  10513.  10514.  10515.  10516.  10517.  10518.\n",
      "  10519.]\n",
      "[ 41   6  36  27 117  19  96  20  29  63]\n",
      "[  1052.  10520.  10521.  10522.  10523.  10524.  10525.  10526.  10527.\n",
      "  10528.]\n",
      "[80 95 19 39 52 14 28 11  1 72]\n",
      "[ 10529.   1053.  10530.  10531.  10532.  10533.  10534.  10535.  10536.\n",
      "  10537.]\n",
      "[110  74  11  87  50  53 104  78 108  74]\n",
      "[ 10538.  10539.   1054.  10540.  10541.  10542.  10543.  10544.  10545.\n",
      "  10546.]\n",
      "[108   2  98 122  46  68 104  76 120  61]\n",
      "[ 10547.  10548.  10549.   1055.  10550.  10551.  10552.  10553.  10554.\n",
      "  10555.]\n",
      "[ 40  40  78 122  77  35  65  23  74  83]\n",
      "[ 10556.  10557.  10558.  10559.   1056.  10560.  10561.  10562.  10563.\n",
      "  10564.]\n",
      "[ 28  10 122  68  58  54   1  82  96  81]\n",
      "[ 10565.  10566.  10567.  10568.  10569.   1057.  10570.  10571.  10572.\n",
      "  10573.]\n",
      "[ 20   3 114  37  87  58 121 114   8  40]\n",
      "[ 10574.  10575.  10576.  10577.  10578.  10579.   1058.  10580.  10581.\n",
      "  10582.]\n",
      "[ 40  18  75  83  54 112   5  63  14  18]\n",
      "[ 10583.  10584.  10585.  10586.  10587.  10588.  10589.   1059.  10590.\n",
      "  10591.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64 122 115  83  18  74  37 121  13  53]\n",
      "[ 10592.  10593.  10594.  10595.  10596.  10597.  10598.  10599.    106.\n",
      "   1060.]\n",
      "[  3  98 122  80  45 114 117  88  11  48]\n",
      "[ 10600.  10601.  10602.  10603.  10604.  10605.  10606.  10607.  10608.\n",
      "  10609.]\n",
      "[ 95  56  58 109  63  27  19  31  78 128]\n",
      "[  1061.  10610.  10611.  10612.  10613.  10614.  10615.  10616.  10617.\n",
      "  10618.]\n",
      "[ 27   5   4   4  93  54  86 114  31  45]\n",
      "[ 10619.   1062.  10620.  10621.  10622.  10623.  10624.  10625.  10626.\n",
      "  10627.]\n",
      "[ 53   9  39  63  48  33 111  83  27  28]\n",
      "[ 10628.  10629.   1063.  10630.  10631.  10632.  10633.  10634.  10635.\n",
      "  10636.]\n",
      "[  4  80  35  40  53  78   4 103 114  68]\n",
      "[ 10637.  10638.  10639.   1064.  10640.  10641.  10642.  10643.  10644.\n",
      "  10645.]\n",
      "[104 117  19   3  43   5  85  64 109  58]\n",
      "[ 10646.  10647.  10648.  10649.   1065.  10650.  10651.  10652.  10653.\n",
      "  10654.]\n",
      "[91 29 78 62 89 96 87 94 83 40]\n",
      "[ 10655.  10656.  10657.  10658.  10659.   1066.  10660.  10661.  10662.\n",
      "  10663.]\n",
      "[ 65  20  79  13   4 103   8  20  76  14]\n",
      "[ 10664.  10665.  10666.  10667.  10668.  10669.   1067.  10670.  10671.\n",
      "  10672.]\n",
      "[ 44  78 123  41  40  48  78  46  81 114]\n",
      "[ 10673.  10674.  10675.  10676.  10677.  10678.  10679.   1068.  10680.\n",
      "  10681.]\n",
      "[ 56  88  72  54 116  67  84  86 112  52]\n",
      "[ 10682.  10683.  10684.  10685.  10686.  10687.  10688.  10689.   1069.\n",
      "  10690.]\n",
      "[ 54   4  41  17 124 106  54  11  19  83]\n",
      "[ 10691.  10692.  10693.  10694.  10695.  10696.  10697.  10698.  10699.\n",
      "    107.]\n",
      "[ 48  98  19 110  13  79 114  65  74  79]\n",
      "[  1070.  10700.  10701.  10702.  10703.  10704.  10705.  10706.  10707.\n",
      "  10708.]\n",
      "[ 30   8  43 111  17  96  75  34  38  97]\n",
      "[ 10709.   1071.  10710.  10711.  10712.  10713.  10714.  10715.  10716.\n",
      "  10717.]\n",
      "[ 35   4 115  50  35 111  23  13   5 114]\n",
      "[ 10718.  10719.   1072.  10720.  10721.  10722.  10723.  10724.  10725.\n",
      "  10726.]\n",
      "[ 75 111  70 116  67 108   9  44  28 115]\n",
      "[ 10727.  10728.  10729.   1073.  10730.  10731.  10732.  10733.  10734.\n",
      "  10735.]\n",
      "[ 45  81  74 109  13  78  17  80  33  96]\n",
      "[ 10736.  10737.  10738.  10739.   1074.  10740.  10741.  10742.  10743.\n",
      "  10744.]\n",
      "[ 65  99 108  18  34 104 127 123  79 112]\n",
      "[ 10745.  10746.  10747.  10748.  10749.   1075.  10750.  10751.  10752.\n",
      "  10753.]\n",
      "[ 37 114  79  82  23  78  31 116 123  98]\n",
      "[ 10754.  10755.  10756.  10757.  10758.  10759.   1076.  10760.  10761.\n",
      "  10762.]\n",
      "[ 95   3  54  26 103 123   8  13  20 106]\n",
      "[ 10763.  10764.  10765.  10766.  10767.  10768.  10769.   1077.  10770.\n",
      "  10771.]\n",
      "[117  40  74  13 114   5  53 114  95  45]\n",
      "[ 10772.  10773.  10774.  10775.  10776.  10777.  10778.  10779.   1078.\n",
      "  10780.]\n",
      "[ 27  62   6  53  52 121  40  45   4  83]\n",
      "[ 10781.  10782.  10783.  10784.  10785.  10786.  10787.  10788.  10789.\n",
      "   1079.]\n",
      "[24 83 53 48 96 85  7 10 79 44]\n",
      "[ 10790.  10791.  10792.  10793.  10794.  10795.  10796.  10797.  10798.\n",
      "  10799.]\n",
      "[ 87  16  38  84 116  12 117 124  68 123]\n",
      "[   108.   1080.  10800.  10801.  10802.  10803.  10804.  10805.  10806.\n",
      "  10807.]\n",
      "[81  9 83 82 31 83 79 23 16 17]\n",
      "[ 10808.  10809.   1081.  10810.  10811.  10812.  10813.  10814.  10815.\n",
      "  10816.]\n",
      "[  1 116  88 121 106 106 110  18  52   8]\n",
      "[ 10817.  10818.  10819.   1082.  10820.  10821.  10822.  10823.  10824.\n",
      "  10825.]\n",
      "[ 80  83 116 107 121  95 111  58  45 122]\n",
      "[ 10826.  10827.  10828.  10829.   1083.  10830.  10831.  10832.  10833.\n",
      "  10834.]\n",
      "[122   3  77  78 124  58  65   5 117  18]\n",
      "[ 10835.  10836.  10837.  10838.  10839.   1084.  10840.  10841.  10842.\n",
      "  10843.]\n",
      "[ 87 117  74  63  40  74  83   6   3  13]\n",
      "[ 10844.  10845.  10846.  10847.  10848.  10849.   1085.  10850.  10851.\n",
      "  10852.]\n",
      "[ 98  65  35  21 123  40 122 116  74  31]\n",
      "[ 10853.  10854.  10855.  10856.  10857.  10858.  10859.   1086.  10860.\n",
      "  10861.]\n",
      "[108   8  50  28  68 124  28  86  61  43]\n",
      "[ 10862.  10863.  10864.  10865.  10866.  10867.  10868.  10869.   1087.\n",
      "  10870.]\n",
      "[84 79 99 67 96 79 13  5 24 97]\n",
      "[ 10871.  10872.  10873.  10874.  10875.  10876.  10877.  10878.  10879.\n",
      "   1088.]\n",
      "[ 79  26  24 128  78   6  86  62 108  53]\n",
      "[ 10880.  10881.  10882.  10883.  10884.  10885.  10886.  10887.  10888.\n",
      "  10889.]\n",
      "[ 17 114  98  88  52  54  40  99  40  67]\n",
      "[  1089.  10890.  10891.  10892.  10893.  10894.  10895.  10896.  10897.\n",
      "  10898.]\n",
      "[  4   8 106  79  27  19  96  20  38 107]\n",
      "[ 10899.    109.   1090.  10900.  10901.  10902.  10903.  10904.  10905.\n",
      "  10906.]\n",
      "[117  98  40  74 116  80  65  74  67 122]\n",
      "[ 10907.  10908.  10909.   1091.  10910.  10911.  10912.  10913.  10914.\n",
      "  10915.]\n",
      "[110  79 116  83 115  77 111  38  83 117]\n",
      "[ 10916.  10917.  10918.  10919.   1092.  10920.  10921.  10922.  10923.\n",
      "  10924.]\n",
      "[128   5  20  54  78 117  48  20  30  94]\n",
      "[ 10925.  10926.  10927.  10928.  10929.   1093.  10930.  10931.  10932.\n",
      "  10933.]\n",
      "[ 95 107  83   5  65 104  58  86 122 117]\n",
      "[ 10934.  10935.  10936.  10937.  10938.  10939.   1094.  10940.  10941.\n",
      "  10942.]\n",
      "[  4 122  54 127   5 104  28   8  50  73]\n",
      "[ 10943.  10944.  10945.  10946.  10947.  10948.  10949.   1095.  10950.\n",
      "  10951.]\n",
      "[34 81 33 83 45 87 41 79 95 62]\n",
      "[ 10952.  10953.  10954.  10955.  10956.  10957.  10958.  10959.   1096.\n",
      "  10960.]\n",
      "[117  70  20  17 124 101  68  40 111  96]\n",
      "[ 10961.  10962.  10963.  10964.  10965.  10966.  10967.  10968.  10969.\n",
      "   1097.]\n",
      "[20 21 44 18 39 63 14 44 19 62]\n",
      "[ 10970.  10971.  10972.  10973.  10974.  10975.  10976.  10977.  10978.\n",
      "  10979.]\n",
      "[ 16  41  19  50 108  62  19  38  84  94]\n",
      "[  1098.  10980.  10981.  10982.  10983.  10984.  10985.  10986.  10987.\n",
      "  10988.]\n",
      "[ 58  94   1   1 110 108  27  29 126  83]\n",
      "[ 10989.   1099.  10990.  10991.  10992.  10993.  10994.  10995.  10996.\n",
      "  10997.]\n",
      "[ 79 120  10  98  83  96  52  28  11  79]\n",
      "[  1.09980000e+04   1.09990000e+04   1.10000000e+01   1.10000000e+02\n",
      "   1.10000000e+03   1.10000000e+04   1.10010000e+04   1.10020000e+04\n",
      "   1.10030000e+04   1.10040000e+04]\n",
      "[111  16  53  91  96   9   4  49  53  66]\n",
      "[ 11005.  11006.  11007.  11008.  11009.   1101.  11010.  11011.  11012.\n",
      "  11013.]\n",
      "[ 44  83   3 123  58  38  85 107 110  83]\n",
      "[ 11014.  11015.  11016.  11017.  11018.  11019.   1102.  11020.  11021.\n",
      "  11022.]\n",
      "[ 73  31   5  19  98  45 102 110  44  97]\n",
      "[ 11023.  11024.  11025.  11026.  11027.  11028.  11029.   1103.  11030.\n",
      "  11031.]\n",
      "[ 58 116  67  35  53 106  68  64   5 111]\n",
      "[ 11032.  11033.  11034.  11035.  11036.  11037.  11038.  11039.   1104.\n",
      "  11040.]\n",
      "[41 35 16 21 21 95 98  5 64 17]\n",
      "[ 11041.  11042.  11043.  11044.  11045.  11046.  11047.  11048.  11049.\n",
      "   1105.]\n",
      "[117  19 109  19  85  74 108  78   8  30]\n",
      "[ 11050.  11051.  11052.  11053.  11054.  11055.  11056.  11057.  11058.\n",
      "  11059.]\n",
      "[ 37  33  54  40   5  70  68  26 123  78]\n",
      "[  1106.  11060.  11061.  11062.  11063.  11064.  11065.  11066.  11067.\n",
      "  11068.]\n",
      "[120  54  63  80  80  78 110 104  56  87]\n",
      "[ 11069.   1107.  11070.  11071.  11072.  11073.  11074.  11075.  11076.\n",
      "  11077.]\n",
      "[ 88 124  83  35  45  83  81  85  95  27]\n",
      "[ 11078.  11079.   1108.  11080.  11081.  11082.  11083.  11084.  11085.\n",
      "  11086.]\n",
      "[ 49  93  90 122 111  85  74  83  20 123]\n",
      "[ 11087.  11088.  11089.   1109.  11090.  11091.  11092.  11093.  11094.\n",
      "  11095.]\n",
      "[ 31  88  54  84  83 121  54  17  27  28]\n",
      "[ 11096.  11097.  11098.  11099.    111.   1110.  11100.  11101.  11102.\n",
      "  11103.]\n",
      "[ 53  77  68  82 106  96  94  22  86   1]\n",
      "[ 11104.  11105.  11106.  11107.  11108.  11109.   1111.  11110.  11111.\n",
      "  11112.]\n",
      "[ 83  83   3   9 106 102 106  13  87  74]\n",
      "[ 11113.  11114.  11115.  11116.  11117.  11118.  11119.   1112.  11120.\n",
      "  11121.]\n",
      "[102  96  43   9  23  17  83  95  10   9]\n",
      "[ 11122.  11123.  11124.  11125.  11126.  11127.  11128.  11129.   1113.\n",
      "  11130.]\n",
      "[ 59  83  17  36  19  74 107  44  14  96]\n",
      "[ 11131.  11132.  11133.  11134.  11135.  11136.  11137.  11138.  11139.\n",
      "   1114.]\n",
      "[  4  31  14  87  90   1  95  79  84 110]\n",
      "[ 11140.  11141.  11142.  11143.  11144.  11145.  11146.  11147.  11148.\n",
      "  11149.]\n",
      "[124   9  43 116  17  54  53 127 121  75]\n",
      "[  1115.  11150.  11151.  11152.  11153.  11154.  11155.  11156.  11157.\n",
      "  11158.]\n",
      "[ 28 123   1   8  20  13  83 101  95  61]\n",
      "[ 11159.   1116.  11160.  11161.  11162.  11163.  11164.  11165.  11166.\n",
      "  11167.]\n",
      "[108  83  28 115 120   5 121 116   1  98]\n",
      "[ 11168.  11169.   1117.  11170.  11171.  11172.  11173.  11174.  11175.\n",
      "  11176.]\n",
      "[19 50 24 16 38 95 23 27 10 45]\n",
      "[ 11177.  11178.  11179.   1118.  11180.  11181.  11182.  11183.  11184.\n",
      "  11185.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108 122  13  54  28  83   8  79  85 122]\n",
      "[ 11186.  11187.  11188.  11189.   1119.  11190.  11191.  11192.  11193.\n",
      "  11194.]\n",
      "[ 96  37 126  68  67 106  19 106 115  46]\n",
      "[ 11195.  11196.  11197.  11198.  11199.    112.   1120.  11200.  11201.\n",
      "  11202.]\n",
      "[ 27  22   7  43  68  64 117 114 122  14]\n",
      "[ 11203.  11204.  11205.  11206.  11207.  11208.  11209.   1121.  11210.\n",
      "  11211.]\n",
      "[  1 109  54 117  89  20  54  83 123   7]\n",
      "[ 11212.  11213.  11214.  11215.  11216.  11217.  11218.  11219.   1122.\n",
      "  11220.]\n",
      "[  8 101  54  93  44  27  75 109 116  82]\n",
      "[ 11221.  11222.  11223.  11224.  11225.  11226.  11227.  11228.  11229.\n",
      "   1123.]\n",
      "[ 80  96  74  54  31  86 103 121  40  58]\n",
      "[ 11230.  11231.  11232.  11233.  11234.  11235.  11236.  11237.  11238.\n",
      "  11239.]\n",
      "[127   9  90  54 110 110 123  74  89  74]\n",
      "[  1124.  11240.  11241.  11242.  11243.  11244.  11245.  11246.  11247.\n",
      "  11248.]\n",
      "[ 79   8  19  83   4  74  23  23 126  27]\n",
      "[ 11249.   1125.  11250.  11251.  11252.  11253.  11254.  11255.  11256.\n",
      "  11257.]\n",
      "[ 63   8  13 106 110  69   4  11 107  76]\n",
      "[ 11258.  11259.   1126.  11260.  11261.  11262.  11263.  11264.  11265.\n",
      "  11266.]\n",
      "[ 56  19 111  10  49 106  86  46  58  79]\n",
      "[ 11267.  11268.  11269.   1127.  11270.  11271.  11272.  11273.  11274.\n",
      "  11275.]\n",
      "[ 87  83  67  19  37 121  74  30  16   5]\n",
      "[ 11276.  11277.  11278.  11279.   1128.  11280.  11281.  11282.  11283.\n",
      "  11284.]\n",
      "[ 11  82  95 111   9  36  95  67  40  54]\n",
      "[ 11285.  11286.  11287.  11288.  11289.   1129.  11290.  11291.  11292.\n",
      "  11293.]\n",
      "[ 19  83  83  85 122 111  16  96  19  16]\n",
      "[ 11294.  11295.  11296.  11297.  11298.  11299.    113.   1130.  11300.\n",
      "  11301.]\n",
      "[ 4 11 87  8 70 27 35 98 96 79]\n",
      "[ 11302.  11303.  11304.  11305.  11306.  11307.  11308.  11309.   1131.\n",
      "  11310.]\n",
      "[ 90 114 124  90  95 122  53 106  93  24]\n",
      "[ 11311.  11312.  11313.  11314.  11315.  11316.  11317.  11318.  11319.\n",
      "   1132.]\n",
      "[  9  49 103   9  83  80 107  87  89  83]\n",
      "[ 11320.  11321.  11322.  11323.  11324.  11325.  11326.  11327.  11328.\n",
      "  11329.]\n",
      "[ 24   8  38 117   9  68  10  61  48  77]\n",
      "[  1133.  11330.  11331.  11332.  11333.  11334.  11335.  11336.  11337.\n",
      "  11338.]\n",
      "[ 77   9  84  78  39  85 108  62  13  77]\n",
      "[ 11339.   1134.  11340.  11341.  11342.  11343.  11344.  11345.  11346.\n",
      "  11347.]\n",
      "[ 66  79  79   3  83  52 122  34   1  38]\n",
      "[ 11348.  11349.   1135.  11350.  11351.  11352.  11353.  11354.  11355.\n",
      "  11356.]\n",
      "[ 20  83  19  28   3  35  74  31 114   3]\n",
      "[ 11357.  11358.  11359.   1136.  11360.  11361.  11362.  11363.  11364.\n",
      "  11365.]\n",
      "[ 85   8  34  77 110  29 122 116  40  24]\n",
      "[ 11366.  11367.  11368.  11369.   1137.  11370.  11371.  11372.  11373.\n",
      "  11374.]\n",
      "[ 52   7   7 116  20  40 126  18  28 107]\n",
      "[ 11375.  11376.  11377.  11378.  11379.   1138.  11380.  11381.  11382.\n",
      "  11383.]\n",
      "[122  77  75 104  13  28  87  74  51  19]\n",
      "[ 11384.  11385.  11386.  11387.  11388.  11389.   1139.  11390.  11391.\n",
      "  11392.]\n",
      "[ 57  85  31  96 101 101  43  98 111  27]\n",
      "[ 11393.  11394.  11395.  11396.  11397.  11398.  11399.    114.   1140.\n",
      "  11400.]\n",
      "[109  74  72   8   9  66  99  52  30 116]\n",
      "[ 11401.  11402.  11403.  11404.  11405.  11406.  11407.  11408.  11409.\n",
      "   1141.]\n",
      "[ 9 16 17 65 30 27 17 86 88 87]\n",
      "[ 11410.  11411.  11412.  11413.  11414.  11415.  11416.  11417.  11418.\n",
      "  11419.]\n",
      "[ 99 110  14 111   7  28  54  95 111  65]\n",
      "[  1142.  11420.  11421.  11422.  11423.  11424.  11425.  11426.  11427.\n",
      "  11428.]\n",
      "[ 38  22 124   8  68  14  30  43  74  46]\n",
      "[ 11429.   1143.  11430.  11431.  11432.  11433.  11434.  11435.  11436.\n",
      "  11437.]\n",
      "[109  74  19 122  77  78  10  78  80  11]\n",
      "[ 11438.  11439.   1144.  11440.  11441.  11442.  11443.  11444.  11445.\n",
      "  11446.]\n",
      "[ 36 110  53  83  40  23  10  49  28  11]\n",
      "[ 11447.  11448.  11449.   1145.  11450.  11451.  11452.  11453.  11454.\n",
      "  11455.]\n",
      "[ 82  80  85 125  75 112  96   5   8  96]\n",
      "[ 11456.  11457.  11458.  11459.   1146.  11460.  11461.  11462.  11463.\n",
      "  11464.]\n",
      "[  3   9  55 122  79 108  83 106  66  62]\n",
      "[ 11465.  11466.  11467.  11468.  11469.   1147.  11470.  11471.  11472.\n",
      "  11473.]\n",
      "[ 76  20  93  93  90 111   9   7   4  72]\n",
      "[ 11474.  11475.  11476.  11477.  11478.  11479.   1148.  11480.  11481.\n",
      "  11482.]\n",
      "[ 19   7  96  87  68  43 107 114  14  87]\n",
      "[ 11483.  11484.  11485.  11486.  11487.  11488.  11489.   1149.  11490.\n",
      "  11491.]\n",
      "[  8  43 117 122   1  52  44  77  40  97]\n",
      "[ 11492.  11493.  11494.  11495.  11496.  11497.  11498.  11499.    115.\n",
      "   1150.]\n",
      "[117  95 122  79 111  65  16 116  54  58]\n",
      "[ 11500.  11501.  11502.  11503.  11504.  11505.  11506.  11507.  11508.\n",
      "  11509.]\n",
      "[ 61  11  63  81  85  98 101  62  54  94]\n",
      "[  1151.  11510.  11511.  11512.  11513.  11514.  11515.  11516.  11517.\n",
      "  11518.]\n",
      "[ 17  20  50   8  38  62  78  10 122  94]\n",
      "[ 11519.   1152.  11520.  11521.  11522.  11523.  11524.  11525.  11526.\n",
      "  11527.]\n",
      "[ 64  83  28  10  20  93  78 109  38   8]\n",
      "[ 11528.  11529.   1153.  11530.  11531.  11532.  11533.  11534.  11535.\n",
      "  11536.]\n",
      "[114   3  87  96  65  13  87  11  88  63]\n",
      "[ 11537.  11538.  11539.   1154.  11540.  11541.  11542.  11543.  11544.\n",
      "  11545.]\n",
      "[ 10  76  20  43  96 122  96 123  95  65]\n",
      "[ 11546.  11547.  11548.  11549.   1155.  11550.  11551.  11552.  11553.\n",
      "  11554.]\n",
      "[ 30  11 101  47  83  31  79 124 115  87]\n",
      "[ 11555.  11556.  11557.  11558.  11559.   1156.  11560.  11561.  11562.\n",
      "  11563.]\n",
      "[ 41  58  68 106  67  65  74  66 123  87]\n",
      "[ 11564.  11565.  11566.  11567.  11568.  11569.   1157.  11570.  11571.\n",
      "  11572.]\n",
      "[ 86   8 124  44  83  45  46  77  40  56]\n",
      "[ 11573.  11574.  11575.  11576.  11577.  11578.  11579.   1158.  11580.\n",
      "  11581.]\n",
      "[115  23  75  87 101   8  93 110 114 123]\n",
      "[ 11582.  11583.  11584.  11585.  11586.  11587.  11588.  11589.   1159.\n",
      "  11590.]\n",
      "[122   7 115  31 107  49 116  57  52  90]\n",
      "[ 11591.  11592.  11593.  11594.  11595.  11596.  11597.  11598.  11599.\n",
      "    116.]\n",
      "[107  63  36 111 116  79   7  11 127  19]\n",
      "[  1160.  11600.  11601.  11602.  11603.  11604.  11605.  11606.  11607.\n",
      "  11608.]\n",
      "[  6 111  11   3  23  16 117 108 107  75]\n",
      "[ 11609.   1161.  11610.  11611.  11612.  11613.  11614.  11615.  11616.\n",
      "  11617.]\n",
      "[74 74 28 78 85  4 74 67  7 10]\n",
      "[ 11618.  11619.   1162.  11620.  11621.  11622.  11623.  11624.  11625.\n",
      "  11626.]\n",
      "[127 102 122  45  77  84 108  67  20  94]\n",
      "[ 11627.  11628.  11629.   1163.  11630.  11631.  11632.  11633.  11634.\n",
      "  11635.]\n",
      "[ 94  56  38  85  67  41 101  83 108  78]\n",
      "[ 11636.  11637.  11638.  11639.   1164.  11640.  11641.  11642.  11643.\n",
      "  11644.]\n",
      "[128   7  45  86  54 111  96  54   3  74]\n",
      "[ 11645.  11646.  11647.  11648.  11649.   1165.  11650.  11651.  11652.\n",
      "  11653.]\n",
      "[ 61  95 116 121  19  38  94   7 124 127]\n",
      "[ 11654.  11655.  11656.  11657.  11658.  11659.   1166.  11660.  11661.\n",
      "  11662.]\n",
      "[ 67  90  68 122  16   8  13  97  84  19]\n",
      "[ 11663.  11664.  11665.  11666.  11667.  11668.  11669.   1167.  11670.\n",
      "  11671.]\n",
      "[106  49  75 107  96  46   1  88  78   8]\n",
      "[ 11672.  11673.  11674.  11675.  11676.  11677.  11678.  11679.   1168.\n",
      "  11680.]\n",
      "[ 30 124  88  52 109  78   7  68  14  75]\n",
      "[ 11681.  11682.  11683.  11684.  11685.  11686.  11687.  11688.  11689.\n",
      "   1169.]\n",
      "[ 83  19 113  83 122  13  74  94  85 117]\n",
      "[ 11690.  11691.  11692.  11693.  11694.  11695.  11696.  11697.  11698.\n",
      "  11699.]\n",
      "[65 53 64 45 84 14 17 57 26 19]\n",
      "[   117.   1170.  11700.  11701.  11702.  11703.  11704.  11705.  11706.\n",
      "  11707.]\n",
      "[ 38  55  54  22  50  97  87 122  16  21]\n",
      "[ 11708.  11709.   1171.  11710.  11711.  11712.  11713.  11714.  11715.\n",
      "  11716.]\n",
      "[ 74  19  36 102  24  21  96  31   9 110]\n",
      "[ 11717.  11718.  11719.   1172.  11720.  11721.  11722.  11723.  11724.\n",
      "  11725.]\n",
      "[124 114  44  18  54  85   2  68 122  29]\n",
      "[ 11726.  11727.  11728.  11729.   1173.  11730.  11731.  11732.  11733.\n",
      "  11734.]\n",
      "[ 96 127  19  14 106  65  40   6   1  33]\n",
      "[ 11735.  11736.  11737.  11738.  11739.   1174.  11740.  11741.  11742.\n",
      "  11743.]\n",
      "[ 83  20 107  79  45 122 117 109  33 111]\n",
      "[ 11744.  11745.  11746.  11747.  11748.  11749.   1175.  11750.  11751.\n",
      "  11752.]\n",
      "[ 90  14  74 106  37  65  75  97  79  49]\n",
      "[ 11753.  11754.  11755.  11756.  11757.  11758.  11759.   1176.  11760.\n",
      "  11761.]\n",
      "[  9  86  52  92  19  77 117  44  68 104]\n",
      "[ 11762.  11763.  11764.  11765.  11766.  11767.  11768.  11769.   1177.\n",
      "  11770.]\n",
      "[ 34  55  27  84  74 117   7  85  11  19]\n",
      "[ 11771.  11772.  11773.  11774.  11775.  11776.  11777.  11778.  11779.\n",
      "   1178.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 45  89  44  83  67  36   5  96 106  79]\n",
      "[ 11780.  11781.  11782.  11783.  11784.  11785.  11786.  11787.  11788.\n",
      "  11789.]\n",
      "[  1 104 110  83  96 123 121  80   9  67]\n",
      "[  1179.  11790.  11791.  11792.  11793.  11794.  11795.  11796.  11797.\n",
      "  11798.]\n",
      "[117  19 101  45  39  75 122   5 122  88]\n",
      "[ 11799.    118.   1180.  11800.  11801.  11802.  11803.  11804.  11805.\n",
      "  11806.]\n",
      "[ 65  28  87  40  27   4 117  52  95  93]\n",
      "[ 11807.  11808.  11809.   1181.  11810.  11811.  11812.  11813.  11814.\n",
      "  11815.]\n",
      "[  1  19  65   5  85  82  44  39 123  38]\n",
      "[ 11816.  11817.  11818.  11819.   1182.  11820.  11821.  11822.  11823.\n",
      "  11824.]\n",
      "[ 57  44 111  27  39  76  35 110 116  35]\n",
      "[ 11825.  11826.  11827.  11828.  11829.   1183.  11830.  11831.  11832.\n",
      "  11833.]\n",
      "[ 35  19  27  31  86  76   5 109   8 117]\n",
      "[ 11834.  11835.  11836.  11837.  11838.  11839.   1184.  11840.  11841.\n",
      "  11842.]\n",
      "[ 84 123 108  49  36  85  43 111  98  66]\n",
      "[ 11843.  11844.  11845.  11846.  11847.  11848.  11849.   1185.  11850.\n",
      "  11851.]\n",
      "[102  83 123  94 116 106  81  76  54   5]\n",
      "[ 11852.  11853.  11854.  11855.  11856.  11857.  11858.  11859.   1186.\n",
      "  11860.]\n",
      "[ 77  78 122 112  58 107  39 123  57   9]\n",
      "[ 11861.  11862.  11863.  11864.  11865.  11866.  11867.  11868.  11869.\n",
      "   1187.]\n",
      "[ 86  68 123  95 117 111  35  53  92  46]\n",
      "[ 11870.  11871.  11872.  11873.  11874.  11875.  11876.  11877.  11878.\n",
      "  11879.]\n",
      "[ 63 126 108  38 126  80   4 116  38  34]\n",
      "[  1188.  11880.  11881.  11882.  11883.  11884.  11885.  11886.  11887.\n",
      "  11888.]\n",
      "[ 31  52  90  82  68  97 121  80  79  49]\n",
      "[ 11889.   1189.  11890.  11891.  11892.  11893.  11894.  11895.  11896.\n",
      "  11897.]\n",
      "[117  77  20  13  99  24  77  82  58  28]\n",
      "[ 11898.  11899.    119.   1190.  11900.  11901.  11902.  11903.  11904.\n",
      "  11905.]\n",
      "[ 83  40  19 102  65  44  39  63  94  27]\n",
      "[ 11906.  11907.  11908.  11909.   1191.  11910.  11911.  11912.  11913.\n",
      "  11914.]\n",
      "[ 39   8 106   8 101  38 111  17  98  19]\n",
      "[ 11915.  11916.  11917.  11918.  11919.   1192.  11920.  11921.  11922.\n",
      "  11923.]\n",
      "[117  10  18  95 116  14 104  38  40  22]\n",
      "[ 11924.  11925.  11926.  11927.  11928.  11929.   1193.  11930.  11931.\n",
      "  11932.]\n",
      "[ 68  39  34  53  78  80  18  35  63 107]\n",
      "[ 11933.  11934.  11935.  11936.  11937.  11938.  11939.   1194.  11940.\n",
      "  11941.]\n",
      "[ 41  68  49  95  63  80  34 120  65  72]\n",
      "[ 11942.  11943.  11944.  11945.  11946.  11947.  11948.  11949.   1195.\n",
      "  11950.]\n",
      "[ 55  13   9  61  30  58  28  86 106 112]\n",
      "[ 11951.  11952.  11953.  11954.  11955.  11956.  11957.  11958.  11959.\n",
      "   1196.]\n",
      "[ 87   8 107 122 121  14   3  62  78  30]\n",
      "[ 11960.  11961.  11962.  11963.  11964.  11965.  11966.  11967.  11968.\n",
      "  11969.]\n",
      "[ 24   9  62   8  22  98 111  54  90  17]\n",
      "[  1197.  11970.  11971.  11972.  11973.  11974.  11975.  11976.  11977.\n",
      "  11978.]\n",
      "[ 18   4  28 106 116  40  75   8 117   4]\n",
      "[ 11979.   1198.  11980.  11981.  11982.  11983.  11984.  11985.  11986.\n",
      "  11987.]\n",
      "[ 94  84  43  68  77 102 128  79  20 126]\n",
      "[ 11988.  11989.   1199.  11990.  11991.  11992.  11993.  11994.  11995.\n",
      "  11996.]\n",
      "[ 58 116   5  19   4  20  62  83  79 110]\n",
      "[  1.19970000e+04   1.19980000e+04   1.19990000e+04   1.20000000e+01\n",
      "   1.20000000e+02   1.20000000e+03   1.20000000e+04   1.20010000e+04\n",
      "   1.20020000e+04   1.20030000e+04]\n",
      "[ 52  58  95  43  14  38   9 116  20  83]\n",
      "[ 12004.  12005.  12006.  12007.  12008.  12009.   1201.  12010.  12011.\n",
      "  12012.]\n",
      "[ 93  19  62  35 117  13  20  89 101  95]\n",
      "[ 12013.  12014.  12015.  12016.  12017.  12018.  12019.   1202.  12020.\n",
      "  12021.]\n",
      "[  2  45 104  85  58  89 122  20 108 104]\n",
      "[ 12022.  12023.  12024.  12025.  12026.  12027.  12028.  12029.   1203.\n",
      "  12030.]\n",
      "[ 16  67 108  87  74 115  82   3 122  14]\n",
      "[ 12031.  12032.  12033.  12034.  12035.  12036.  12037.  12038.  12039.\n",
      "   1204.]\n",
      "[ 90  53  27 101  71  52  45  96  19  53]\n",
      "[ 12040.  12041.  12042.  12043.  12044.  12045.  12046.  12047.  12048.\n",
      "  12049.]\n",
      "[ 53  45  54  27 104  13  74 108  65  83]\n",
      "[  1205.  12050.  12051.  12052.  12053.  12054.  12055.  12056.  12057.\n",
      "  12058.]\n",
      "[113  77  66  81  53   3  28  43 110 115]\n",
      "[ 12059.   1206.  12060.  12061.  12062.  12063.  12064.  12065.  12066.\n",
      "  12067.]\n",
      "[ 85  79  67 116  28 123  27   6  78   1]\n",
      "[ 12068.  12069.   1207.  12070.  12071.  12072.  12073.  12074.  12075.\n",
      "  12076.]\n",
      "[116  28 106  87  78  49  87  57  45  54]\n",
      "[ 12077.  12078.  12079.   1208.  12080.  12081.  12082.  12083.  12084.\n",
      "  12085.]\n",
      "[117  74  78 111  45  45  74 117  72  26]\n",
      "[ 12086.  12087.  12088.  12089.   1209.  12090.  12091.  12092.  12093.\n",
      "  12094.]\n",
      "[ 35   1  52  26 111  38  63  54 122  31]\n",
      "[ 12095.  12096.  12097.  12098.  12099.    121.   1210.  12100.  12101.\n",
      "  12102.]\n",
      "[  1  98 117  83  46   7  53 109   5  83]\n",
      "[ 12103.  12104.  12105.  12106.  12107.  12108.  12109.   1211.  12110.\n",
      "  12111.]\n",
      "[ 75  13  16 101  27 113  95  26  53  45]\n",
      "[ 12112.  12113.  12114.  12115.  12116.  12117.  12118.  12119.   1212.\n",
      "  12120.]\n",
      "[ 68  78  40  16  54 122  10  13  14  80]\n",
      "[ 12121.  12122.  12123.  12124.  12125.  12126.  12127.  12128.  12129.\n",
      "   1213.]\n",
      "[  8   9  68  67 117 108  61  79 116 117]\n",
      "[ 12130.  12131.  12132.  12133.  12134.  12135.  12136.  12137.  12138.\n",
      "  12139.]\n",
      "[ 95 106 116  21  19  18  95   5 127 112]\n",
      "[  1214.  12140.  12141.  12142.  12143.  12144.  12145.  12146.  12147.\n",
      "  12148.]\n",
      "[ 79 122  13  99  83  88  87  97 124   6]\n",
      "[ 12149.   1215.  12150.  12151.  12152.  12153.  12154.  12155.  12156.\n",
      "  12157.]\n",
      "[104 128  18   9 123  87 126 122  20  56]\n",
      "[ 12158.  12159.   1216.  12160.  12161.  12162.  12163.  12164.  12165.\n",
      "  12166.]\n",
      "[ 30 107  63  95  11 116  76 109 101  20]\n",
      "[ 12167.  12168.  12169.   1217.  12170.  12171.  12172.  12173.  12174.\n",
      "  12175.]\n",
      "[ 82   3  93  74  10   3  53  83  75 122]\n",
      "[ 12176.  12177.  12178.  12179.   1218.  12180.  12181.  12182.  12183.\n",
      "  12184.]\n",
      "[115  79  82  21  39  35  49  65  52 124]\n",
      "[ 12185.  12186.  12187.  12188.  12189.   1219.  12190.  12191.  12192.\n",
      "  12193.]\n",
      "[ 58   9  87   7  84   4  83  44   7 110]\n",
      "[ 12194.  12195.  12196.  12197.  12198.  12199.    122.   1220.  12200.\n",
      "  12201.]\n",
      "[114   3  49 111  16  20  17  79 116 123]\n",
      "[ 12202.  12203.  12204.  12205.  12206.  12207.  12208.  12209.   1221.\n",
      "  12210.]\n",
      "[ 85  28  52  78  54  28  22 127   1  86]\n",
      "[ 12211.  12212.  12213.  12214.  12215.  12216.  12217.  12218.  12219.\n",
      "   1222.]\n",
      "[ 27 122  10  77  41  96  43  53  30  10]\n",
      "[ 12220.  12221.  12222.  12223.  12224.  12225.  12226.  12227.  12228.\n",
      "  12229.]\n",
      "[  7 104  77  19  34  11  14   7 113  19]\n",
      "[  1223.  12230.  12231.  12232.  12233.  12234.  12235.  12236.  12237.\n",
      "  12238.]\n",
      "[ 50  31  75  45  41 111 109  93 109 117]\n",
      "[ 12239.   1224.  12240.  12241.  12242.  12243.  12244.  12245.  12246.\n",
      "  12247.]\n",
      "[ 57  67  94  65  44   8 106   1 110  83]\n",
      "[ 12248.  12249.   1225.  12250.  12251.  12252.  12253.  12254.  12255.\n",
      "  12256.]\n",
      "[ 53  48  58  78  81  45  45 109  54  21]\n",
      "[ 12257.  12258.  12259.   1226.  12260.  12261.  12262.  12263.  12264.\n",
      "  12265.]\n",
      "[ 95  54  45  82 122  27 110  21   9   1]\n",
      "[ 12266.  12267.  12268.  12269.   1227.  12270.  12271.  12272.  12273.\n",
      "  12274.]\n",
      "[ 86   1 112  93   4 124  16  67  39  54]\n",
      "[ 12275.  12276.  12277.  12278.  12279.   1228.  12280.  12281.  12282.\n",
      "  12283.]\n",
      "[ 62  95  29 112 115 122 126  97  53  28]\n",
      "[ 12284.  12285.  12286.  12287.  12288.  12289.   1229.  12290.  12291.\n",
      "  12292.]\n",
      "[ 85  52  63  44  96   3   7  96 110  56]\n",
      "[ 12293.  12294.  12295.  12296.  12297.  12298.  12299.    123.   1230.\n",
      "  12300.]\n",
      "[ 57   4  45  54  40 109  79 121 122  80]\n",
      "[ 12301.  12302.  12303.  12304.  12305.  12306.  12307.  12308.  12309.\n",
      "   1231.]\n",
      "[ 87 109  28 123 104  79  10  53  83  68]\n",
      "[ 12310.  12311.  12312.  12313.  12314.  12315.  12316.  12317.  12318.\n",
      "  12319.]\n",
      "[27  5 53 18 27  1 13 97 10 56]\n",
      "[  1232.  12320.  12321.  12322.  12323.  12324.  12325.  12326.  12327.\n",
      "  12328.]\n",
      "[ 95  13  38  35  19 107 122  52  53  22]\n",
      "[ 12329.   1233.  12330.  12331.  12332.  12333.  12334.  12335.  12336.\n",
      "  12337.]\n",
      "[ 99  21  22 108 108   4  19  28  63  63]\n",
      "[ 12338.  12339.   1234.  12340.  12341.  12342.  12343.  12344.  12345.\n",
      "  12346.]\n",
      "[ 35  31  44 122  72  20  68  40  41  28]\n",
      "[ 12347.  12348.  12349.   1235.  12350.  12351.  12352.  12353.  12354.\n",
      "  12355.]\n",
      "[  4  83  98  63 110  99  54  48  79 123]\n",
      "[ 12356.  12357.  12358.  12359.   1236.  12360.  12361.  12362.  12363.\n",
      "  12364.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24  79  78  50   3  95 108  86  26  75]\n",
      "[ 12365.  12366.  12367.  12368.  12369.   1237.  12370.  12371.  12372.\n",
      "  12373.]\n",
      "[ 5 38  9 38 27 81 83 79 10 28]\n",
      "[ 12374.  12375.  12376.  12377.  12378.  12379.   1238.  12380.  12381.\n",
      "  12382.]\n",
      "[ 13  84  81 117  85  54  93  98  85  78]\n",
      "[ 12383.  12384.  12385.  12386.  12387.  12388.  12389.   1239.  12390.\n",
      "  12391.]\n",
      "[106 107  62 101  60  81  45   4  75  98]\n",
      "[ 12392.  12393.  12394.  12395.  12396.  12397.  12398.  12399.    124.\n",
      "   1240.]\n",
      "[ 20  95 111 108  73  54   7 122  53 106]\n",
      "[ 12400.  12401.  12402.  12403.  12404.  12405.  12406.  12407.  12408.\n",
      "  12409.]\n",
      "[107  17  94  97  84  95  90 107 101  63]\n",
      "[  1241.  12410.  12411.  12412.  12413.  12414.  12415.  12416.  12417.\n",
      "  12418.]\n",
      "[72 19 14 11 88 29 83 68 28 68]\n",
      "[ 12419.   1242.  12420.  12421.  12422.  12423.  12424.  12425.  12426.\n",
      "  12427.]\n",
      "[123   4  28  83 113  18 122  87 122  37]\n",
      "[ 12428.  12429.   1243.  12430.  12431.  12432.  12433.  12434.  12435.\n",
      "  12436.]\n",
      "[ 54  54  93  79  54  94  78 117 112 128]\n",
      "[ 12437.  12438.  12439.   1244.  12440.  12441.  12442.  12443.  12444.\n",
      "  12445.]\n",
      "[ 35  94  89  34  13 110  70  68  22 107]\n",
      "[ 12446.  12447.  12448.  12449.   1245.  12450.  12451.  12452.  12453.\n",
      "  12454.]\n",
      "[112  87  62   4   1 106  31  95  96  38]\n",
      "[ 12455.  12456.  12457.  12458.  12459.   1246.  12460.  12461.  12462.\n",
      "  12463.]\n",
      "[  7  61  83  35  71  85  96  80 117  17]\n",
      "[ 12464.  12465.  12466.  12467.  12468.  12469.   1247.  12470.  12471.\n",
      "  12472.]\n",
      "[ 11  95 114   3  50  63  20  50  67   4]\n",
      "[ 12473.  12474.  12475.  12476.  12477.  12478.  12479.   1248.  12480.\n",
      "  12481.]\n",
      "[ 10 123  28  40  38 107 122  75  67 108]\n",
      "[ 12482.  12483.  12484.  12485.  12486.  12487.  12488.  12489.   1249.\n",
      "  12490.]\n",
      "[ 78  20  43  44  68  19 122  67  96  48]\n",
      "[ 12491.  12492.  12493.  12494.  12495.  12496.  12497.  12498.  12499.\n",
      "    125.]\n",
      "[109  28  46  58  65 113  67  76  57  43]\n",
      "[  1250.  12500.  12501.  12502.  12503.  12504.  12505.  12506.  12507.\n",
      "  12508.]\n",
      "[106  83   3  80 116 123  67 104  73  50]\n",
      "[ 12509.   1251.  12510.  12511.  12512.  12513.  12514.  12515.  12516.\n",
      "  12517.]\n",
      "[ 11  13  99  44   8  73  58 122  65 128]\n",
      "[ 12518.  12519.   1252.  12520.  12521.  12522.  12523.  12524.  12525.\n",
      "  12526.]\n",
      "[ 56 111   8  50  67  76 110  40  85  63]\n",
      "[ 12527.  12528.  12529.   1253.  12530.  12531.  12532.  12533.  12534.\n",
      "  12535.]\n",
      "[ 21 122  80 116 117  83  27  72  79  83]\n",
      "[ 12536.  12537.  12538.  12539.   1254.  12540.  12541.  12542.  12543.\n",
      "  12544.]\n",
      "[ 80  89  20  80  41  45  85   8 109  79]\n",
      "[ 12545.  12546.  12547.  12548.  12549.   1255.  12550.  12551.  12552.\n",
      "  12553.]\n",
      "[ 28  54  90 110  28   8  63  19  49  53]\n",
      "[ 12554.  12555.  12556.  12557.  12558.  12559.   1256.  12560.  12561.\n",
      "  12562.]\n",
      "[ 38 101  80  14  80  84  27  11  67  94]\n",
      "[ 12563.  12564.  12565.  12566.  12567.  12568.  12569.   1257.  12570.\n",
      "  12571.]\n",
      "[ 85 116  11  95  52  78  74  19 115  52]\n",
      "[ 12572.  12573.  12574.  12575.  12576.  12577.  12578.  12579.   1258.\n",
      "  12580.]\n",
      "[ 85 116  22  44  24  83  34  37  83  95]\n",
      "[ 12581.  12582.  12583.  12584.  12585.  12586.  12587.  12588.  12589.\n",
      "   1259.]\n",
      "[ 93  64 107  84  54  17  85 108  63  48]\n",
      "[ 12590.  12591.  12592.  12593.  12594.  12595.  12596.  12597.  12598.\n",
      "  12599.]\n",
      "[ 27 101   6  43  86  67 114  79 120 104]\n",
      "[   126.   1260.  12600.  12601.  12602.  12603.  12604.  12605.  12606.\n",
      "  12607.]\n",
      "[ 93 107   4  67  53 122   1  27  17 123]\n",
      "[ 12608.  12609.   1261.  12610.  12611.  12612.  12613.  12614.  12615.\n",
      "  12616.]\n",
      "[102  19  82 127 111  16  77 104 109  79]\n",
      "[ 12617.  12618.  12619.   1262.  12620.  12621.  12622.  12623.  12624.\n",
      "  12625.]\n",
      "[ 28  44  67 116   3  96 106  79  53  88]\n",
      "[ 12626.  12627.  12628.  12629.   1263.  12630.  12631.  12632.  12633.\n",
      "  12634.]\n",
      "[ 74 112 114  83  48  81  49  66  88  49]\n",
      "[ 12635.  12636.  12637.  12638.  12639.   1264.  12640.  12641.  12642.\n",
      "  12643.]\n",
      "[ 17  13  53  35  95  83  79  40  43 111]\n",
      "[ 12644.  12645.  12646.  12647.  12648.  12649.   1265.  12650.  12651.\n",
      "  12652.]\n",
      "[ 83 110   8  10  29  11  38  20  31 103]\n",
      "[ 12653.  12654.  12655.  12656.  12657.  12658.  12659.   1266.  12660.\n",
      "  12661.]\n",
      "[  9  58  20  67  78  19  30 122 122  43]\n",
      "[ 12662.  12663.  12664.  12665.  12666.  12667.  12668.  12669.   1267.\n",
      "  12670.]\n",
      "[74 27 35 16 35  8  9 43  8 79]\n",
      "[ 12671.  12672.  12673.  12674.  12675.  12676.  12677.  12678.  12679.\n",
      "   1268.]\n",
      "[ 53   3  16  16 111  54  87  34  43  61]\n",
      "[ 12680.  12681.  12682.  12683.  12684.  12685.  12686.  12687.  12688.\n",
      "  12689.]\n",
      "[ 94  98  19 111  49  99  56  45 109  11]\n",
      "[  1269.  12690.  12691.  12692.  12693.  12694.  12695.  12696.  12697.\n",
      "  12698.]\n",
      "[ 54  85  74 123  68  35  85 112 107 117]\n",
      "[ 12699.    127.   1270.  12700.  12701.  12702.  12703.  12704.  12705.\n",
      "  12706.]\n",
      "[108  24  26  80  28 104  41  36 107  97]\n",
      "[ 12707.  12708.  12709.   1271.  12710.  12711.  12712.  12713.  12714.\n",
      "  12715.]\n",
      "[ 84  67 117 126  98  27   8 101 116  62]\n",
      "[ 12716.  12717.  12718.  12719.   1272.  12720.  12721.  12722.  12723.\n",
      "  12724.]\n",
      "[ 46  28  84  85  65  76  82  58 128  40]\n",
      "[ 12725.  12726.  12727.  12728.  12729.   1273.  12730.  12731.  12732.\n",
      "  12733.]\n",
      "[ 95  17  74  84 111  74  56 117  84 111]\n",
      "[ 12734.  12735.  12736.  12737.  12738.  12739.   1274.  12740.  12741.\n",
      "  12742.]\n",
      "[117  46  99 107  78  20  46 110  28  77]\n",
      "[ 12743.  12744.  12745.  12746.  12747.  12748.  12749.   1275.  12750.\n",
      "  12751.]\n",
      "[ 78  58 123  60 128  62  44 117  96  15]\n",
      "[ 12752.  12753.  12754.  12755.  12756.  12757.  12758.  12759.   1276.\n",
      "  12760.]\n",
      "[ 95 110  74  60 102 116  52 127 106  75]\n",
      "[ 12761.  12762.  12763.  12764.  12765.  12766.  12767.  12768.  12769.\n",
      "   1277.]\n",
      "[ 58   3  86 127  96  11  66   5  94  18]\n",
      "[ 12770.  12771.  12772.  12773.  12774.  12775.  12776.  12777.  12778.\n",
      "  12779.]\n",
      "[19 17  4 90 36  5 99 45 20 94]\n",
      "[  1278.  12780.  12781.  12782.  12783.  12784.  12785.  12786.  12787.\n",
      "  12788.]\n",
      "[ 29  80  20  27  74  82 111  20  93  65]\n",
      "[ 12789.   1279.  12790.  12791.  12792.  12793.  12794.  12795.  12796.\n",
      "  12797.]\n",
      "[ 58   9  75 122  50 124  80  56  68 123]\n",
      "[ 12798.  12799.    128.   1280.  12800.   1281.   1282.   1283.   1284.\n",
      "   1285.]\n",
      "[ 93 128  96   9 126  46 111 102  31  20]\n",
      "[ 1286.  1287.  1288.  1289.   129.  1290.  1291.  1292.  1293.  1294.]\n",
      "[ 66  11 111  86  23  27  58  48  76  10]\n",
      "[ 1295.  1296.  1297.  1298.  1299.    13.   130.  1300.  1301.  1302.]\n",
      "[ 19 101  11 117  28  16  45 116  37  43]\n",
      "[ 1303.  1304.  1305.  1306.  1307.  1308.  1309.   131.  1310.  1311.]\n",
      "[ 28  83  28  95 124  11  95  31  24  27]\n",
      "[ 1312.  1313.  1314.  1315.  1316.  1317.  1318.  1319.   132.  1320.]\n",
      "[ 98  84  96 115 121  19 117  40  50  14]\n",
      "[ 1321.  1322.  1323.  1324.  1325.  1326.  1327.  1328.  1329.   133.]\n",
      "[ 94   8  28  83  53 114 107  38  20 123]\n",
      "[ 1330.  1331.  1332.  1333.  1334.  1335.  1336.  1337.  1338.  1339.]\n",
      "[ 44 110  40  74  78  85   1  74  82 120]\n",
      "[  134.  1340.  1341.  1342.  1343.  1344.  1345.  1346.  1347.  1348.]\n",
      "[ 23  76  54  67  20 127  83  44  54  35]\n",
      "[ 1349.   135.  1350.  1351.  1352.  1353.  1354.  1355.  1356.  1357.]\n",
      "[ 98 126  96  78   9  95  96  83  83  83]\n",
      "[ 1358.  1359.   136.  1360.  1361.  1362.  1363.  1364.  1365.  1366.]\n",
      "[116  62 117  80  77 117   6 114 117  11]\n",
      "[ 1367.  1368.  1369.   137.  1370.  1371.  1372.  1373.  1374.  1375.]\n",
      "[ 2 89 38 31 52  7 17 83 56 54]\n",
      "[ 1376.  1377.  1378.  1379.   138.  1380.  1381.  1382.  1383.  1384.]\n",
      "[ 52 123   3  49  38  27   7 117  14  78]\n",
      "[ 1385.  1386.  1387.  1388.  1389.   139.  1390.  1391.  1392.  1393.]\n",
      "[ 88 122 117 110  74 109  62   9  81  86]\n",
      "[ 1394.  1395.  1396.  1397.  1398.  1399.    14.   140.  1400.  1401.]\n",
      "[ 52  65 107 108  50  19  45 116  77 109]\n",
      "[ 1402.  1403.  1404.  1405.  1406.  1407.  1408.  1409.   141.  1410.]\n",
      "[ 85   8 110  53  19  80  22 121  96   9]\n",
      "[ 1411.  1412.  1413.  1414.  1415.  1416.  1417.  1418.  1419.   142.]\n",
      "[123 111   5  74 121 122  35  45 122  78]\n",
      "[ 1420.  1421.  1422.  1423.  1424.  1425.  1426.  1427.  1428.  1429.]\n",
      "[ 20  54   8  60   9  78  13 116  78  19]\n",
      "[  143.  1430.  1431.  1432.  1433.  1434.  1435.  1436.  1437.  1438.]\n",
      "[101 108  40  98  32   3   9  10  67  45]\n",
      "[ 1439.   144.  1440.  1441.  1442.  1443.  1444.  1445.  1446.  1447.]\n",
      "[ 45 123   3  98 109 123  78   7   3  94]\n",
      "[ 1448.  1449.   145.  1450.  1451.  1452.  1453.  1454.  1455.  1456.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24 116  93 122  68  23 122  63  89  35]\n",
      "[ 1457.  1458.  1459.   146.  1460.  1461.  1462.  1463.  1464.  1465.]\n",
      "[ 16 109  14  96  45 111  77  84  86  94]\n",
      "[ 1466.  1467.  1468.  1469.   147.  1470.  1471.  1472.  1473.  1474.]\n",
      "[ 78  28   3  11 127  62  93  31  66  56]\n",
      "[ 1475.  1476.  1477.  1478.  1479.   148.  1480.  1481.  1482.  1483.]\n",
      "[ 87  10   3 117  56  65   9  54  35 106]\n",
      "[ 1484.  1485.  1486.  1487.  1488.  1489.   149.  1490.  1491.  1492.]\n",
      "[ 61 115  63  22  74   8 101  31  75  17]\n",
      "[ 1493.  1494.  1495.  1496.  1497.  1498.  1499.    15.   150.  1500.]\n",
      "[ 83  54 114  10   1  21  69  39  82   6]\n",
      "[ 1501.  1502.  1503.  1504.  1505.  1506.  1507.  1508.  1509.   151.]\n",
      "[ 48 110  97  19  98  19  85  40   3 116]\n",
      "[ 1510.  1511.  1512.  1513.  1514.  1515.  1516.  1517.  1518.  1519.]\n",
      "[31 68  5 52 15 11 94 62  4 74]\n",
      "[  152.  1520.  1521.  1522.  1523.  1524.  1525.  1526.  1527.  1528.]\n",
      "[ 94 127  81 114  64  53  65  98 108  14]\n",
      "[ 1529.   153.  1530.  1531.  1532.  1533.  1534.  1535.  1536.  1537.]\n",
      "[17 31 65 78 84 10 30 28 85 27]\n",
      "[ 1538.  1539.   154.  1540.  1541.  1542.  1543.  1544.  1545.  1546.]\n",
      "[ 35  11  36  13  14  50 116 117 106  44]\n",
      "[ 1547.  1548.  1549.   155.  1550.  1551.  1552.  1553.  1554.  1555.]\n",
      "[  2  75  58  17  51  20  86 127  95 125]\n",
      "[ 1556.  1557.  1558.  1559.   156.  1560.  1561.  1562.  1563.  1564.]\n",
      "[ 44 121 108  76  40 103  14  96  74  49]\n",
      "[ 1565.  1566.  1567.  1568.  1569.   157.  1570.  1571.  1572.  1573.]\n",
      "[ 43  16  19  83 122  88  98  31  90  77]\n",
      "[ 1574.  1575.  1576.  1577.  1578.  1579.   158.  1580.  1581.  1582.]\n",
      "[ 16 127  58  77   9  65  83  83 117  28]\n",
      "[ 1583.  1584.  1585.  1586.  1587.  1588.  1589.   159.  1590.  1591.]\n",
      "[ 50 115   4  21  35 111  53  29  75  96]\n",
      "[ 1592.  1593.  1594.  1595.  1596.  1597.  1598.  1599.    16.   160.]\n",
      "[ 80 122 116 123  94  17 104  74  76  22]\n",
      "[ 1600.  1601.  1602.  1603.  1604.  1605.  1606.  1607.  1608.  1609.]\n",
      "[ 17  63 110  36  86 122  30  68  87  16]\n",
      "[  161.  1610.  1611.  1612.  1613.  1614.  1615.  1616.  1617.  1618.]\n",
      "[ 19  53  50  10  83  41 110  64  13  17]\n",
      "[ 1619.   162.  1620.  1621.  1622.  1623.  1624.  1625.  1626.  1627.]\n",
      "[ 28 103   9   5   5  16  65  49  89  94]\n",
      "[ 1628.  1629.   163.  1630.  1631.  1632.  1633.  1634.  1635.  1636.]\n",
      "[ 37 115  38 112  58  72  53  99   1   8]\n",
      "[ 1637.  1638.  1639.   164.  1640.  1641.  1642.  1643.  1644.  1645.]\n",
      "[128  61  95  28  74  87  38  98 117  99]\n",
      "[ 1646.  1647.  1648.  1649.   165.  1650.  1651.  1652.  1653.  1654.]\n",
      "[ 95  20  75 106  95   8 128  79  19 101]\n",
      "[ 1655.  1656.  1657.  1658.  1659.   166.  1660.  1661.  1662.  1663.]\n",
      "[ 95  30  55  97 117  20  77 124  93 117]\n",
      "[ 1664.  1665.  1666.  1667.  1668.  1669.   167.  1670.  1671.  1672.]\n",
      "[96 92 39 20 72 78 77  7 37 11]\n",
      "[ 1673.  1674.  1675.  1676.  1677.  1678.  1679.   168.  1680.  1681.]\n",
      "[77 40 53 95 78 82 67  8 62 28]\n",
      "[ 1682.  1683.  1684.  1685.  1686.  1687.  1688.  1689.   169.  1690.]\n",
      "[73 20 56  3 53 97 31 79 84  6]\n",
      "[ 1691.  1692.  1693.  1694.  1695.  1696.  1697.  1698.  1699.    17.]\n",
      "[ 40 110  10 116  39  83  76  76 123  17]\n",
      "[  170.  1700.  1701.  1702.  1703.  1704.  1705.  1706.  1707.  1708.]\n",
      "[108 107  68 108  27  86 108  93  83  86]\n",
      "[ 1709.   171.  1710.  1711.  1712.  1713.  1714.  1715.  1716.  1717.]\n",
      "[  9 107  67  86 123  84  75 120  53  19]\n",
      "[ 1718.  1719.   172.  1720.  1721.  1722.  1723.  1724.  1725.  1726.]\n",
      "[ 83 120  40  48  72   8  35  53  75 103]\n",
      "[ 1727.  1728.  1729.   173.  1730.  1731.  1732.  1733.  1734.  1735.]\n",
      "[ 53  46  58 121  85 110   8  29  98  19]\n",
      "[ 1736.  1737.  1738.  1739.   174.  1740.  1741.  1742.  1743.  1744.]\n",
      "[ 83  24  53  41 123  11 108  93 113  45]\n",
      "[ 1745.  1746.  1747.  1748.  1749.   175.  1750.  1751.  1752.  1753.]\n",
      "[126 117  74  72  14   4  17 127 128 126]\n",
      "[ 1754.  1755.  1756.  1757.  1758.  1759.   176.  1760.  1761.  1762.]\n",
      "[  9 106  19   5 110  78  37  45  40  20]\n",
      "[ 1763.  1764.  1765.  1766.  1767.  1768.  1769.   177.  1770.  1771.]\n",
      "[ 39  68 107  77  84  85  10  52 110 126]\n",
      "[ 1772.  1773.  1774.  1775.  1776.  1777.  1778.  1779.   178.  1780.]\n",
      "[ 73  35  87 116 108  74  46   8  95  16]\n",
      "[ 1781.  1782.  1783.  1784.  1785.  1786.  1787.  1788.  1789.   179.]\n",
      "[ 74 126   3   1  68  49 108  85 127 128]\n",
      "[ 1790.  1791.  1792.  1793.  1794.  1795.  1796.  1797.  1798.  1799.]\n",
      "[ 40  61  53  99 116  49  89  63  78  26]\n",
      "[   18.   180.  1800.  1801.  1802.  1803.  1804.  1805.  1806.  1807.]\n",
      "[ 20  22  56  16  54 115 120  20  36  78]\n",
      "[ 1808.  1809.   181.  1810.  1811.  1812.  1813.  1814.  1815.  1816.]\n",
      "[ 58 111  98  45 117   5   5  35  40  85]\n",
      "[ 1817.  1818.  1819.   182.  1820.  1821.  1822.  1823.  1824.  1825.]\n",
      "[62 95 95 54 52  9  7 56 83 31]\n",
      "[ 1826.  1827.  1828.  1829.   183.  1830.  1831.  1832.  1833.  1834.]\n",
      "[  5  85  94  40   3  28  53  23  46 123]\n",
      "[ 1835.  1836.  1837.  1838.  1839.   184.  1840.  1841.  1842.  1843.]\n",
      "[17 24 21 88  8 78 64 18 82 83]\n",
      "[ 1844.  1845.  1846.  1847.  1848.  1849.   185.  1850.  1851.  1852.]\n",
      "[ 31  72  20 116  54  63 104 128  94 104]\n",
      "[ 1853.  1854.  1855.  1856.  1857.  1858.  1859.   186.  1860.  1861.]\n",
      "[ 67   9  93 106  14  30  45  94 114  44]\n",
      "[ 1862.  1863.  1864.  1865.  1866.  1867.  1868.  1869.   187.  1870.]\n",
      "[ 83  74  38  30  18 107   6 106  24  87]\n",
      "[ 1871.  1872.  1873.  1874.  1875.  1876.  1877.  1878.  1879.   188.]\n",
      "[ 48  80   6  11 123  74   8  44 106 117]\n",
      "[ 1880.  1881.  1882.  1883.  1884.  1885.  1886.  1887.  1888.  1889.]\n",
      "[ 53 103  11 120  99  20  52  79  68  20]\n",
      "[  189.  1890.  1891.  1892.  1893.  1894.  1895.  1896.  1897.  1898.]\n",
      "[ 68 104  77  45  23 117   4  85   8 126]\n",
      "[ 1899.    19.   190.  1900.  1901.  1902.  1903.  1904.  1905.  1906.]\n",
      "[101 118  52  77 127  35  59  11  75 117]\n",
      "[ 1907.  1908.  1909.   191.  1910.  1911.  1912.  1913.  1914.  1915.]\n",
      "[117 108  40 106  37  53  54  62  72  35]\n",
      "[ 1916.  1917.  1918.  1919.   192.  1920.  1921.  1922.  1923.  1924.]\n",
      "[27 33 91 86 31 19 68 58  5 95]\n",
      "[ 1925.  1926.  1927.  1928.  1929.   193.  1930.  1931.  1932.  1933.]\n",
      "[ 82   1  17  74  16 106 104 107  95 112]\n",
      "[ 1934.  1935.  1936.  1937.  1938.  1939.   194.  1940.  1941.  1942.]\n",
      "[ 48   3 117  52  34  52  82  74 124 117]\n",
      "[ 1943.  1944.  1945.  1946.  1947.  1948.  1949.   195.  1950.  1951.]\n",
      "[ 96  76  95  28   3 127  19   3 111  49]\n",
      "[ 1952.  1953.  1954.  1955.  1956.  1957.  1958.  1959.   196.  1960.]\n",
      "[ 52  63 128  22  17  75   4  96  84  85]\n",
      "[ 1961.  1962.  1963.  1964.  1965.  1966.  1967.  1968.  1969.   197.]\n",
      "[ 10  96  30  62   3 106  35  75  65 122]\n",
      "[ 1970.  1971.  1972.  1973.  1974.  1975.  1976.  1977.  1978.  1979.]\n",
      "[ 94 127   1  40  79  79  74  10  27  86]\n",
      "[  198.  1980.  1981.  1982.  1983.  1984.  1985.  1986.  1987.  1988.]\n",
      "[ 90 104  58  94  28   5 116  81  37  91]\n",
      "[ 1989.   199.  1990.  1991.  1992.  1993.  1994.  1995.  1996.  1997.]\n",
      "[ 94  14  78  49 117  72  64 112  44 102]\n",
      "[  1.99800000e+03   1.99900000e+03   2.00000000e+00   2.00000000e+01\n",
      "   2.00000000e+02   2.00000000e+03   2.00100000e+03   2.00200000e+03\n",
      "   2.00300000e+03   2.00400000e+03]\n",
      "[ 10  62  54  79  50  74  68  11  65 123]\n",
      "[ 2005.  2006.  2007.  2008.  2009.   201.  2010.  2011.  2012.  2013.]\n",
      "[ 73  67 121 108  38  28  13  67 108   4]\n",
      "[ 2014.  2015.  2016.  2017.  2018.  2019.   202.  2020.  2021.  2022.]\n",
      "[ 19  37  54  77 110 122  24  85  81  54]\n",
      "[ 2023.  2024.  2025.  2026.  2027.  2028.  2029.   203.  2030.  2031.]\n",
      "[110  44  40 127 116 111  40  74 122 127]\n",
      "[ 2032.  2033.  2034.  2035.  2036.  2037.  2038.  2039.   204.  2040.]\n",
      "[116  38  83  95 123  31  43 101  47  17]\n",
      "[ 2041.  2042.  2043.  2044.  2045.  2046.  2047.  2048.  2049.   205.]\n",
      "[ 18  85  19  44  40  19  13  68 123 122]\n",
      "[ 2050.  2051.  2052.  2053.  2054.  2055.  2056.  2057.  2058.  2059.]\n",
      "[ 93  84   2  63 120   6 111  85   3  67]\n",
      "[  206.  2060.  2061.  2062.  2063.  2064.  2065.  2066.  2067.  2068.]\n",
      "[ 99  49  96  17 128  18  16 104  17  43]\n",
      "[ 2069.   207.  2070.  2071.  2072.  2073.  2074.  2075.  2076.  2077.]\n",
      "[  3  26  85 111  16 116  45  81  96 111]\n",
      "[ 2078.  2079.   208.  2080.  2081.  2082.  2083.  2084.  2085.  2086.]\n",
      "[ 27  28  13 107  83  46  77  74 124  40]\n",
      "[ 2087.  2088.  2089.   209.  2090.  2091.  2092.  2093.  2094.  2095.]\n",
      "[123  67 109  53  11  85  97  97 112 109]\n",
      "[ 2096.  2097.  2098.  2099.    21.   210.  2100.  2101.  2102.  2103.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 74  54 128  83  86  35  74  10  53  14]\n",
      "[ 2104.  2105.  2106.  2107.  2108.  2109.   211.  2110.  2111.  2112.]\n",
      "[ 35  85  82  83  85 117  50  54  74  52]\n",
      "[ 2113.  2114.  2115.  2116.  2117.  2118.  2119.   212.  2120.  2121.]\n",
      "[126  77  19  96  20  13  44 122  74 101]\n",
      "[ 2122.  2123.  2124.  2125.  2126.  2127.  2128.  2129.   213.  2130.]\n",
      "[27 83 83 58 72 20 38 19 96 45]\n",
      "[ 2131.  2132.  2133.  2134.  2135.  2136.  2137.  2138.  2139.   214.]\n",
      "[ 83  31  26  28  28  83  65  86  22 121]\n",
      "[ 2140.  2141.  2142.  2143.  2144.  2145.  2146.  2147.  2148.  2149.]\n",
      "[ 79  10  86  84   9  98  53 122  86  11]\n",
      "[  215.  2150.  2151.  2152.  2153.  2154.  2155.  2156.  2157.  2158.]\n",
      "[ 40   8  76  58  53  95  67  33  56 104]\n",
      "[ 2159.   216.  2160.  2161.  2162.  2163.  2164.  2165.  2166.  2167.]\n",
      "[123  50  40   1 106  45  20  31 124  20]\n",
      "[ 2168.  2169.   217.  2170.  2171.  2172.  2173.  2174.  2175.  2176.]\n",
      "[ 67 108  52 111  87   8  19  53  56  28]\n",
      "[ 2177.  2178.  2179.   218.  2180.  2181.  2182.  2183.  2184.  2185.]\n",
      "[38 40 35  7 79 22 79 43 65 35]\n",
      "[ 2186.  2187.  2188.  2189.   219.  2190.  2191.  2192.  2193.  2194.]\n",
      "[ 16  49  22  28  77  78  56  78 108  86]\n",
      "[ 2195.  2196.  2197.  2198.  2199.    22.   220.  2200.  2201.  2202.]\n",
      "[106  85  23   4 117 107 108 122  48  58]\n",
      "[ 2203.  2204.  2205.  2206.  2207.  2208.  2209.   221.  2210.  2211.]\n",
      "[ 58  38 121  68  85 128  49   4  18  20]\n",
      "[ 2212.  2213.  2214.  2215.  2216.  2217.  2218.  2219.   222.  2220.]\n",
      "[ 96  79 101 107  96 111 122  11 111  95]\n",
      "[ 2221.  2222.  2223.  2224.  2225.  2226.  2227.  2228.  2229.   223.]\n",
      "[ 74  63   4  17  48   1   9  82 116  85]\n",
      "[ 2230.  2231.  2232.  2233.  2234.  2235.  2236.  2237.  2238.  2239.]\n",
      "[ 63   8  37  28  46  85  24 117  87  53]\n",
      "[  224.  2240.  2241.  2242.  2243.  2244.  2245.  2246.  2247.  2248.]\n",
      "[ 96  58 111  46  27 104  17   8  53   9]\n",
      "[ 2249.   225.  2250.  2251.  2252.  2253.  2254.  2255.  2256.  2257.]\n",
      "[ 36  66  77  40 117  78  83 127  40  19]\n",
      "[ 2258.  2259.   226.  2260.  2261.  2262.  2263.  2264.  2265.  2266.]\n",
      "[ 33  22 109   9 108  35  40  68  76  98]\n",
      "[ 2267.  2268.  2269.   227.  2270.  2271.  2272.  2273.  2274.  2275.]\n",
      "[ 85  33  19  97  58  85  34  66  76 121]\n",
      "[ 2276.  2277.  2278.  2279.   228.  2280.  2281.  2282.  2283.  2284.]\n",
      "[ 34  27  67  19  49  78  40 116  66  19]\n",
      "[ 2285.  2286.  2287.  2288.  2289.   229.  2290.  2291.  2292.  2293.]\n",
      "[ 63  63   3  14  76  61 108  90  19  19]\n",
      "[ 2294.  2295.  2296.  2297.  2298.  2299.    23.   230.  2300.  2301.]\n",
      "[  8  24 112  65  20  38  56  27  19 111]\n",
      "[ 2302.  2303.  2304.  2305.  2306.  2307.  2308.  2309.   231.  2310.]\n",
      "[116   8  76  79  43  38  16   4  69  20]\n",
      "[ 2311.  2312.  2313.  2314.  2315.  2316.  2317.  2318.  2319.   232.]\n",
      "[109 117  86  96   9  83  44  86   2 123]\n",
      "[ 2320.  2321.  2322.  2323.  2324.  2325.  2326.  2327.  2328.  2329.]\n",
      "[115  27  30  94  94  29 126  58  11  94]\n",
      "[  233.  2330.  2331.  2332.  2333.  2334.  2335.  2336.  2337.  2338.]\n",
      "[127  20  52  44  27 116  98  19  48  83]\n",
      "[ 2339.   234.  2340.  2341.  2342.  2343.  2344.  2345.  2346.  2347.]\n",
      "[ 88 107  23  41  83  14  78  79  17  53]\n",
      "[ 2348.  2349.   235.  2350.  2351.  2352.  2353.  2354.  2355.  2356.]\n",
      "[  4   1  74  83  68 122  52  35 107  36]\n",
      "[ 2357.  2358.  2359.   236.  2360.  2361.  2362.  2363.  2364.  2365.]\n",
      "[ 97  13  53 107  28 114   8  21  48  83]\n",
      "[ 2366.  2367.  2368.  2369.   237.  2370.  2371.  2372.  2373.  2374.]\n",
      "[ 27 115  28  14  77  85  79  17  47  46]\n",
      "[ 2375.  2376.  2377.  2378.  2379.   238.  2380.  2381.  2382.  2383.]\n",
      "[ 82  73  35  83 122   3  68  79  16   3]\n",
      "[ 2384.  2385.  2386.  2387.  2388.  2389.   239.  2390.  2391.  2392.]\n",
      "[122  96  11  50   7 106  65  63  96   5]\n",
      "[ 2393.  2394.  2395.  2396.  2397.  2398.  2399.    24.   240.  2400.]\n",
      "[ 11  78 124  87  96  45  78 111  13   9]\n",
      "[ 2401.  2402.  2403.  2404.  2405.  2406.  2407.  2408.  2409.   241.]\n",
      "[ 41  36 120 120  19 117   4  62  96  14]\n",
      "[ 2410.  2411.  2412.  2413.  2414.  2415.  2416.  2417.  2418.  2419.]\n",
      "[31 72 20 72 41 40 89 75 49 44]\n",
      "[  242.  2420.  2421.  2422.  2423.  2424.  2425.  2426.  2427.  2428.]\n",
      "[120  54  74 127  52  44 107  14 120  74]\n",
      "[ 2429.   243.  2430.  2431.  2432.  2433.  2434.  2435.  2436.  2437.]\n",
      "[111  68  67  74 122 108  27  17  74  86]\n",
      "[ 2438.  2439.   244.  2440.  2441.  2442.  2443.  2444.  2445.  2446.]\n",
      "[111 107  96  78  58   9  86  99  88  16]\n",
      "[ 2447.  2448.  2449.   245.  2450.  2451.  2452.  2453.  2454.  2455.]\n",
      "[  7 110 107 128 115  66 107   9  19  44]\n",
      "[ 2456.  2457.  2458.  2459.   246.  2460.  2461.  2462.  2463.  2464.]\n",
      "[ 21  52  94  10  58  74 116  38   9  72]\n",
      "[ 2465.  2466.  2467.  2468.  2469.   247.  2470.  2471.  2472.  2473.]\n",
      "[ 20  86  31  10  84   9  16 101  48  81]\n",
      "[ 2474.  2475.  2476.  2477.  2478.  2479.   248.  2480.  2481.  2482.]\n",
      "[ 52 112  88   1  87 128  83 111 111  85]\n",
      "[ 2483.  2484.  2485.  2486.  2487.  2488.  2489.   249.  2490.  2491.]\n",
      "[ 62  62 116  26   8 111  54 116  67  38]\n",
      "[ 2492.  2493.  2494.  2495.  2496.  2497.  2498.  2499.    25.   250.]\n",
      "[ 82   1  43 123  38  35  78  79  78  21]\n",
      "[ 2500.  2501.  2502.  2503.  2504.  2505.  2506.  2507.  2508.  2509.]\n",
      "[ 45 104  29 101  40 119  95  72  34  78]\n",
      "[  251.  2510.  2511.  2512.  2513.  2514.  2515.  2516.  2517.  2518.]\n",
      "[ 64 110  67  98  85  77 116 106 112  78]\n",
      "[ 2519.   252.  2520.  2521.  2522.  2523.  2524.  2525.  2526.  2527.]\n",
      "[  9  99 121   3  20  95  45  67  48  68]\n",
      "[ 2528.  2529.   253.  2530.  2531.  2532.  2533.  2534.  2535.  2536.]\n",
      "[ 79 126  74 122  62  78  27  28  78  40]\n",
      "[ 2537.  2538.  2539.   254.  2540.  2541.  2542.  2543.  2544.  2545.]\n",
      "[ 52 106  97  39  35  88  46  68 107  33]\n",
      "[ 2546.  2547.  2548.  2549.   255.  2550.  2551.  2552.  2553.  2554.]\n",
      "[ 96  33  47  74  99 110   5   8  35 122]\n",
      "[ 2555.  2556.  2557.  2558.  2559.   256.  2560.  2561.  2562.  2563.]\n",
      "[ 86 121   8  53  10 107 114  67 124   8]\n",
      "[ 2564.  2565.  2566.  2567.  2568.  2569.   257.  2570.  2571.  2572.]\n",
      "[124  13  35  86  78  34 108 114  88  33]\n",
      "[ 2573.  2574.  2575.  2576.  2577.  2578.  2579.   258.  2580.  2581.]\n",
      "[114 106  40  19  46  20 117  83 108  10]\n",
      "[ 2582.  2583.  2584.  2585.  2586.  2587.  2588.  2589.   259.  2590.]\n",
      "[  1  43  17 106  28   8  17  78 122  93]\n",
      "[ 2591.  2592.  2593.  2594.  2595.  2596.  2597.  2598.  2599.    26.]\n",
      "[ 33   4  11  79  87  40  86 123  37  83]\n",
      "[  260.  2600.  2601.  2602.  2603.  2604.  2605.  2606.  2607.  2608.]\n",
      "[ 54  74  11  82  72  41  86  41  19 116]\n",
      "[ 2609.   261.  2610.  2611.  2612.  2613.  2614.  2615.  2616.  2617.]\n",
      "[ 80  34 111   2   1  74  75  83  94  76]\n",
      "[ 2618.  2619.   262.  2620.  2621.  2622.  2623.  2624.  2625.  2626.]\n",
      "[95  8 16 54 39 74 10 87 58 28]\n",
      "[ 2627.  2628.  2629.   263.  2630.  2631.  2632.  2633.  2634.  2635.]\n",
      "[ 38  68  77  28   8  65   4   7 107  27]\n",
      "[ 2636.  2637.  2638.  2639.   264.  2640.  2641.  2642.  2643.  2644.]\n",
      "[ 65   8  62  84  13  19 107  94  52  58]\n",
      "[ 2645.  2646.  2647.  2648.  2649.   265.  2650.  2651.  2652.  2653.]\n",
      "[ 95 112 120   7  43  77  96  19 107 115]\n",
      "[ 2654.  2655.  2656.  2657.  2658.  2659.   266.  2660.  2661.  2662.]\n",
      "[ 31 115  35  95  74 112   3   5 112  26]\n",
      "[ 2663.  2664.  2665.  2666.  2667.  2668.  2669.   267.  2670.  2671.]\n",
      "[ 10  17 108  45  38  10  19 116  19  74]\n",
      "[ 2672.  2673.  2674.  2675.  2676.  2677.  2678.  2679.   268.  2680.]\n",
      "[117  83  78  79  76  19   8   5 102  53]\n",
      "[ 2681.  2682.  2683.  2684.  2685.  2686.  2687.  2688.  2689.   269.]\n",
      "[128  67  85   5   1  73  45  99  67  14]\n",
      "[ 2690.  2691.  2692.  2693.  2694.  2695.  2696.  2697.  2698.  2699.]\n",
      "[ 54  35  65  22 106  83 111  74  61 104]\n",
      "[   27.   270.  2700.  2701.  2702.  2703.  2704.  2705.  2706.  2707.]\n",
      "[17 96 54 39 27 74 53 83 74 94]\n",
      "[ 2708.  2709.   271.  2710.  2711.  2712.  2713.  2714.  2715.  2716.]\n",
      "[121  16   4  30  31  40 110  83   5   3]\n",
      "[ 2717.  2718.  2719.   272.  2720.  2721.  2722.  2723.  2724.  2725.]\n",
      "[ 19  13 117   1 107 115  77  76 106  83]\n",
      "[ 2726.  2727.  2728.  2729.   273.  2730.  2731.  2732.  2733.  2734.]\n",
      "[ 83  79  67  58  19   8  45 123  83  99]\n",
      "[ 2735.  2736.  2737.  2738.  2739.   274.  2740.  2741.  2742.  2743.]\n",
      "[ 22  56  38  85  72 122  28  98  20 114]\n",
      "[ 2744.  2745.  2746.  2747.  2748.  2749.   275.  2750.  2751.  2752.]\n",
      "[ 94  53 117  54  28  20  52  85  39   9]\n",
      "[ 2753.  2754.  2755.  2756.  2757.  2758.  2759.   276.  2760.  2761.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 84   7  79  57  95  45   5  68  23 108]\n",
      "[ 2762.  2763.  2764.  2765.  2766.  2767.  2768.  2769.   277.  2770.]\n",
      "[120 104  80  48  14  38 116  84 123 116]\n",
      "[ 2771.  2772.  2773.  2774.  2775.  2776.  2777.  2778.  2779.   278.]\n",
      "[ 53  11 113  67  54  87  19  31  99  43]\n",
      "[ 2780.  2781.  2782.  2783.  2784.  2785.  2786.  2787.  2788.  2789.]\n",
      "[  8  54  40  83  74  54 116   8  85  74]\n",
      "[  279.  2790.  2791.  2792.  2793.  2794.  2795.  2796.  2797.  2798.]\n",
      "[20 45 68  8 89 28  4 83 94 58]\n",
      "[ 2799.    28.   280.  2800.  2801.  2802.  2803.  2804.  2805.  2806.]\n",
      "[74 45 74 68 78 74 86 83 77 28]\n",
      "[ 2807.  2808.  2809.   281.  2810.  2811.  2812.  2813.  2814.  2815.]\n",
      "[ 39 122  86  58  22  79 108  13   1  49]\n",
      "[ 2816.  2817.  2818.  2819.   282.  2820.  2821.  2822.  2823.  2824.]\n",
      "[ 72  10  40 123  19  99  67  94  74  43]\n",
      "[ 2825.  2826.  2827.  2828.  2829.   283.  2830.  2831.  2832.  2833.]\n",
      "[117 114  10  19  58  37 122 108  20 126]\n",
      "[ 2834.  2835.  2836.  2837.  2838.  2839.   284.  2840.  2841.  2842.]\n",
      "[117  20 110  79  10 117  76 117  86 122]\n",
      "[ 2843.  2844.  2845.  2846.  2847.  2848.  2849.   285.  2850.  2851.]\n",
      "[ 18  72   4  25 115  96 106  94  52  26]\n",
      "[ 2852.  2853.  2854.  2855.  2856.  2857.  2858.  2859.   286.  2860.]\n",
      "[107 122  74  35  80 128  19 111  64  40]\n",
      "[ 2861.  2862.  2863.  2864.  2865.  2866.  2867.  2868.  2869.   287.]\n",
      "[ 11   8  11 107  74 123  38  75 121  98]\n",
      "[ 2870.  2871.  2872.  2873.  2874.  2875.  2876.  2877.  2878.  2879.]\n",
      "[78 85 19 94  5 11 53 40 83 28]\n",
      "[  288.  2880.  2881.  2882.  2883.  2884.  2885.  2886.  2887.  2888.]\n",
      "[120  19  20 109  94  62  45  20  19 107]\n",
      "[ 2889.   289.  2890.  2891.  2892.  2893.  2894.  2895.  2896.  2897.]\n",
      "[101  68  68  52   8   4  81  99 114  54]\n",
      "[ 2898.  2899.    29.   290.  2900.  2901.  2902.  2903.  2904.  2905.]\n",
      "[45  8 54 82 79 61 96  8 87 94]\n",
      "[ 2906.  2907.  2908.  2909.   291.  2910.  2911.  2912.  2913.  2914.]\n",
      "[ 17 117  83 122  38 118  82 122  82 116]\n",
      "[ 2915.  2916.  2917.  2918.  2919.   292.  2920.  2921.  2922.  2923.]\n",
      "[ 68  27 117 110 102 113  84  78  18  45]\n",
      "[ 2924.  2925.  2926.  2927.  2928.  2929.   293.  2930.  2931.  2932.]\n",
      "[ 99  89 127  75 122  85 107  28  82 127]\n",
      "[ 2933.  2934.  2935.  2936.  2937.  2938.  2939.   294.  2940.  2941.]\n",
      "[ 18  16  96  90  74  79   3   3 121  83]\n",
      "[ 2942.  2943.  2944.  2945.  2946.  2947.  2948.  2949.   295.  2950.]\n",
      "[ 94  79  48  94  78 113  81  52  74  35]\n",
      "[ 2951.  2952.  2953.  2954.  2955.  2956.  2957.  2958.  2959.   296.]\n",
      "[ 20  68 101  10  79  35   5  19 118  96]\n",
      "[ 2960.  2961.  2962.  2963.  2964.  2965.  2966.  2967.  2968.  2969.]\n",
      "[ 35  53  28  86   6  78 111   8  22  11]\n",
      "[  297.  2970.  2971.  2972.  2973.  2974.  2975.  2976.  2977.  2978.]\n",
      "[ 94  18  41 122   6 107  83  79  65  64]\n",
      "[ 2979.   298.  2980.  2981.  2982.  2983.  2984.  2985.  2986.  2987.]\n",
      "[ 78 115  95 123 111  96  52  68  38  44]\n",
      "[ 2988.  2989.   299.  2990.  2991.  2992.  2993.  2994.  2995.  2996.]\n",
      "[ 54   5  88  80  60  43 101  67  35  96]\n",
      "[  2.99700000e+03   2.99800000e+03   2.99900000e+03   3.00000000e+00\n",
      "   3.00000000e+01   3.00000000e+02   3.00000000e+03   3.00100000e+03\n",
      "   3.00200000e+03   3.00300000e+03]\n",
      "[ 70  85 116  37  73 121  40  45 117  46]\n",
      "[ 3004.  3005.  3006.  3007.  3008.  3009.   301.  3010.  3011.  3012.]\n",
      "[ 22  82  19   4 108 104  68  88  53   9]\n",
      "[ 3013.  3014.  3015.  3016.  3017.  3018.  3019.   302.  3020.  3021.]\n",
      "[127  85  44  83 116 124  17 109  77  96]\n",
      "[ 3022.  3023.  3024.  3025.  3026.  3027.  3028.  3029.   303.  3030.]\n",
      "[  1 123  78  98  27 117  43 117 122 108]\n",
      "[ 3031.  3032.  3033.  3034.  3035.  3036.  3037.  3038.  3039.   304.]\n",
      "[  3 108  74   5  74 107 117  94  79  22]\n",
      "[ 3040.  3041.  3042.  3043.  3044.  3045.  3046.  3047.  3048.  3049.]\n",
      "[ 36 106 124  41  49  44   4  13  20  85]\n",
      "[  305.  3050.  3051.  3052.  3053.  3054.  3055.  3056.  3057.  3058.]\n",
      "[ 97 109  26  75  20  50  78  13  23  74]\n",
      "[ 3059.   306.  3060.  3061.  3062.  3063.  3064.  3065.  3066.  3067.]\n",
      "[ 83 108  45  99 113  34  46 102  23  54]\n",
      "[ 3068.  3069.   307.  3070.  3071.  3072.  3073.  3074.  3075.  3076.]\n",
      "[122  43  33 107  38  62  21  63 126 121]\n",
      "[ 3077.  3078.  3079.   308.  3080.  3081.  3082.  3083.  3084.  3085.]\n",
      "[ 27  18  13 108  41  46  21  52  40  96]\n",
      "[ 3086.  3087.  3088.  3089.   309.  3090.  3091.  3092.  3093.  3094.]\n",
      "[22 50 65 38 52 77 87 62 78 27]\n",
      "[ 3095.  3096.  3097.  3098.  3099.    31.   310.  3100.  3101.  3102.]\n",
      "[ 63  83  70 109  20 122 111  81  18   1]\n",
      "[ 3103.  3104.  3105.  3106.  3107.  3108.  3109.   311.  3110.  3111.]\n",
      "[121  52 106  56  74  83  94 123  97  86]\n",
      "[ 3112.  3113.  3114.  3115.  3116.  3117.  3118.  3119.   312.  3120.]\n",
      "[ 82  39  80  95  95  19 121  74  54  83]\n",
      "[ 3121.  3122.  3123.  3124.  3125.  3126.  3127.  3128.  3129.   313.]\n",
      "[98 83 74 96 63 96 43 41 68 10]\n",
      "[ 3130.  3131.  3132.  3133.  3134.  3135.  3136.  3137.  3138.  3139.]\n",
      "[  9 109  40   5  84  36 111  28 121  65]\n",
      "[  314.  3140.  3141.  3142.  3143.  3144.  3145.  3146.  3147.  3148.]\n",
      "[118  76  62  77  84  21  62  80 121  87]\n",
      "[ 3149.   315.  3150.  3151.  3152.  3153.  3154.  3155.  3156.  3157.]\n",
      "[113  76  84  10  20  53  68  28  46  86]\n",
      "[ 3158.  3159.   316.  3160.  3161.  3162.  3163.  3164.  3165.  3166.]\n",
      "[ 64 112  83 127 117  39  74 126  83 121]\n",
      "[ 3167.  3168.  3169.   317.  3170.  3171.  3172.  3173.  3174.  3175.]\n",
      "[111  52  36 116  38  49 122   7  85 114]\n",
      "[ 3176.  3177.  3178.  3179.   318.  3180.  3181.  3182.  3183.  3184.]\n",
      "[122  84  37  67 120  29  39   1  83  43]\n",
      "[ 3185.  3186.  3187.  3188.  3189.   319.  3190.  3191.  3192.  3193.]\n",
      "[74 52 52 58 10 28 94 61 41 74]\n",
      "[ 3194.  3195.  3196.  3197.  3198.  3199.    32.   320.  3200.  3201.]\n",
      "[121  10  62  78  94  50  87  54  41 111]\n",
      "[ 3202.  3203.  3204.  3205.  3206.  3207.  3208.  3209.   321.  3210.]\n",
      "[ 63  63  70  74  97  90  19 107  72  28]\n",
      "[ 3211.  3212.  3213.  3214.  3215.  3216.  3217.  3218.  3219.   322.]\n",
      "[ 83 106  31 117  24  43 120  96  20  20]\n",
      "[ 3220.  3221.  3222.  3223.  3224.  3225.  3226.  3227.  3228.  3229.]\n",
      "[ 53 122 101 110  93  94  65  80   3  35]\n",
      "[  323.  3230.  3231.  3232.  3233.  3234.  3235.  3236.  3237.  3238.]\n",
      "[ 61  68  58 116  65  35 107  40  88  50]\n",
      "[ 3239.   324.  3240.  3241.  3242.  3243.  3244.  3245.  3246.  3247.]\n",
      "[127  20  41  28  67   3  34 110  83  22]\n",
      "[ 3248.  3249.   325.  3250.  3251.  3252.  3253.  3254.  3255.  3256.]\n",
      "[ 18  19 123  68  75  52  52   8  45  29]\n",
      "[ 3257.  3258.  3259.   326.  3260.  3261.  3262.  3263.  3264.  3265.]\n",
      "[ 11  95  31  20  28  63  20  49 116  57]\n",
      "[ 3266.  3267.  3268.  3269.   327.  3270.  3271.  3272.  3273.  3274.]\n",
      "[96 18 85 95 11 17  8 38 91 74]\n",
      "[ 3275.  3276.  3277.  3278.  3279.   328.  3280.  3281.  3282.  3283.]\n",
      "[ 67  38 108  94  81 120   3  54   8   7]\n",
      "[ 3284.  3285.  3286.  3287.  3288.  3289.   329.  3290.  3291.  3292.]\n",
      "[ 63  79  35  83   9  16 101  65  56  65]\n",
      "[ 3293.  3294.  3295.  3296.  3297.  3298.  3299.    33.   330.  3300.]\n",
      "[ 83  38  39 102  93  95  93 115  35  88]\n",
      "[ 3301.  3302.  3303.  3304.  3305.  3306.  3307.  3308.  3309.   331.]\n",
      "[  9 108  95   9 121   8  77 106  11  61]\n",
      "[ 3310.  3311.  3312.  3313.  3314.  3315.  3316.  3317.  3318.  3319.]\n",
      "[ 83  11  78  61 111  94 110 121  92  35]\n",
      "[  332.  3320.  3321.  3322.  3323.  3324.  3325.  3326.  3327.  3328.]\n",
      "[112  65   1  22 114  22  48  77  86  70]\n",
      "[ 3329.   333.  3330.  3331.  3332.  3333.  3334.  3335.  3336.  3337.]\n",
      "[ 93   7 111  28   1   7  21 123 117  48]\n",
      "[ 3338.  3339.   334.  3340.  3341.  3342.  3343.  3344.  3345.  3346.]\n",
      "[ 67  40   8  40  14   7  75 108 111  22]\n",
      "[ 3347.  3348.  3349.   335.  3350.  3351.  3352.  3353.  3354.  3355.]\n",
      "[ 73 127  49  74  44  68 122  75  54  77]\n",
      "[ 3356.  3357.  3358.  3359.   336.  3360.  3361.  3362.  3363.  3364.]\n",
      "[117  54  49  38  54  26 123  94  66   1]\n",
      "[ 3365.  3366.  3367.  3368.  3369.   337.  3370.  3371.  3372.  3373.]\n",
      "[95 16 40 82 72  5 16  3 87 27]\n",
      "[ 3374.  3375.  3376.  3377.  3378.  3379.   338.  3380.  3381.  3382.]\n",
      "[ 83  86 103  54  96  29 104  74 113  74]\n",
      "[ 3383.  3384.  3385.  3386.  3387.  3388.  3389.   339.  3390.  3391.]\n",
      "[ 54   8 114  20  53 108  38  13 122  97]\n",
      "[ 3392.  3393.  3394.  3395.  3396.  3397.  3398.  3399.    34.   340.]\n",
      "[ 41  16  19  50 101  31  28  11  54  38]\n",
      "[ 3400.  3401.  3402.  3403.  3404.  3405.  3406.  3407.  3408.  3409.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108  74 126  63 116 101 116  83  95  45]\n",
      "[  341.  3410.  3411.  3412.  3413.  3414.  3415.  3416.  3417.  3418.]\n",
      "[ 19  83  27   8 122  54 104  35  83 126]\n",
      "[ 3419.   342.  3420.  3421.  3422.  3423.  3424.  3425.  3426.  3427.]\n",
      "[118  87  56  38 102  67 117 106  28  31]\n",
      "[ 3428.  3429.   343.  3430.  3431.  3432.  3433.  3434.  3435.  3436.]\n",
      "[ 83  28  19  54 127  68 111   4  53  94]\n",
      "[ 3437.  3438.  3439.   344.  3440.  3441.  3442.  3443.  3444.  3445.]\n",
      "[28 99 53  4 54 95 96 14 27 57]\n",
      "[ 3446.  3447.  3448.  3449.   345.  3450.  3451.  3452.  3453.  3454.]\n",
      "[ 54  94  94  78  74  39 107  11 125  54]\n",
      "[ 3455.  3456.  3457.  3458.  3459.   346.  3460.  3461.  3462.  3463.]\n",
      "[  3  21  22  86 123  11  96  58  22  19]\n",
      "[ 3464.  3465.  3466.  3467.  3468.  3469.   347.  3470.  3471.  3472.]\n",
      "[106  94 106  20  98   4  80  19  24  78]\n",
      "[ 3473.  3474.  3475.  3476.  3477.  3478.  3479.   348.  3480.  3481.]\n",
      "[ 10 115  45  31  44  23  19  23  16  18]\n",
      "[ 3482.  3483.  3484.  3485.  3486.  3487.  3488.  3489.   349.  3490.]\n",
      "[ 74  58 128  53   1 108  38 104  54  74]\n",
      "[ 3491.  3492.  3493.  3494.  3495.  3496.  3497.  3498.  3499.    35.]\n",
      "[ 78  38  71  36  85   8  98  41  69 107]\n",
      "[  350.  3500.  3501.  3502.  3503.  3504.  3505.  3506.  3507.  3508.]\n",
      "[ 81  37  54  97 114  61  37  42 109  38]\n",
      "[ 3509.   351.  3510.  3511.  3512.  3513.  3514.  3515.  3516.  3517.]\n",
      "[ 96  78 128  16  98 123  85  83  80   3]\n",
      "[ 3518.  3519.   352.  3520.  3521.  3522.  3523.  3524.  3525.  3526.]\n",
      "[ 33 104  17  56  74 111  26  17  85  99]\n",
      "[ 3527.  3528.  3529.   353.  3530.  3531.  3532.  3533.  3534.  3535.]\n",
      "[ 62 116  88  63  49  79   8  45  19 112]\n",
      "[ 3536.  3537.  3538.  3539.   354.  3540.  3541.  3542.  3543.  3544.]\n",
      "[ 46  70   3   3 110  37  35 106  54  65]\n",
      "[ 3545.  3546.  3547.  3548.  3549.   355.  3550.  3551.  3552.  3553.]\n",
      "[ 77  81  48  89  54 109  10  78  83  27]\n",
      "[ 3554.  3555.  3556.  3557.  3558.  3559.   356.  3560.  3561.  3562.]\n",
      "[117  22  65  19  91  85  96   6  35   8]\n",
      "[ 3563.  3564.  3565.  3566.  3567.  3568.  3569.   357.  3570.  3571.]\n",
      "[  8  75  83 117  16  96  14 116  18  31]\n",
      "[ 3572.  3573.  3574.  3575.  3576.  3577.  3578.  3579.   358.  3580.]\n",
      "[ 5 50 19 74 77 85 21 49 87 85]\n",
      "[ 3581.  3582.  3583.  3584.  3585.  3586.  3587.  3588.  3589.   359.]\n",
      "[  4  27 108 117 121  46  97   8  35 104]\n",
      "[ 3590.  3591.  3592.  3593.  3594.  3595.  3596.  3597.  3598.  3599.]\n",
      "[ 67  54  58 122 122  43  83  95  11  78]\n",
      "[   36.   360.  3600.  3601.  3602.  3603.  3604.  3605.  3606.  3607.]\n",
      "[ 68  19  91  48 123  96  68  99 124  79]\n",
      "[ 3608.  3609.   361.  3610.  3611.  3612.  3613.  3614.  3615.  3616.]\n",
      "[106  87   3 112  44 108  76  52  14 122]\n",
      "[ 3617.  3618.  3619.   362.  3620.  3621.  3622.  3623.  3624.  3625.]\n",
      "[111   1  19  79  24  28  54  90  11   3]\n",
      "[ 3626.  3627.  3628.  3629.   363.  3630.  3631.  3632.  3633.  3634.]\n",
      "[ 87  45 106  27  79  40  33  63   6  93]\n",
      "[ 3635.  3636.  3637.  3638.  3639.   364.  3640.  3641.  3642.  3643.]\n",
      "[ 17  75   4 111 121  79  65  65  16  53]\n",
      "[ 3644.  3645.  3646.  3647.  3648.  3649.   365.  3650.  3651.  3652.]\n",
      "[108  28 123   5  20  68  64  19  54  85]\n",
      "[ 3653.  3654.  3655.  3656.  3657.  3658.  3659.   366.  3660.  3661.]\n",
      "[ 14  43   4 123 112  67   8  45  86  83]\n",
      "[ 3662.  3663.  3664.  3665.  3666.  3667.  3668.  3669.   367.  3670.]\n",
      "[35 22 89 24 61 75 74 44 99 40]\n",
      "[ 3671.  3672.  3673.  3674.  3675.  3676.  3677.  3678.  3679.   368.]\n",
      "[ 40  13  45  28  27 109   4  74  54  94]\n",
      "[ 3680.  3681.  3682.  3683.  3684.  3685.  3686.  3687.  3688.  3689.]\n",
      "[ 31  95  83  95 128   3  96  54 111 108]\n",
      "[  369.  3690.  3691.  3692.  3693.  3694.  3695.  3696.  3697.  3698.]\n",
      "[ 80  46  38  44  20  75  94  46 109 101]\n",
      "[ 3699.    37.   370.  3700.  3701.  3702.  3703.  3704.  3705.  3706.]\n",
      "[111  23 124  31 116  45  95 112  85  18]\n",
      "[ 3707.  3708.  3709.   371.  3710.  3711.  3712.  3713.  3714.  3715.]\n",
      "[ 93  86  68 121  85  63  11  72 104  23]\n",
      "[ 3716.  3717.  3718.  3719.   372.  3720.  3721.  3722.  3723.  3724.]\n",
      "[ 83 113 121  97  45  87  40  54  94 122]\n",
      "[ 3725.  3726.  3727.  3728.  3729.   373.  3730.  3731.  3732.  3733.]\n",
      "[ 86  38  10 115  89  20 108  76  95  36]\n",
      "[ 3734.  3735.  3736.  3737.  3738.  3739.   374.  3740.  3741.  3742.]\n",
      "[128  74  58  58  33  56 117  28  91  28]\n",
      "[ 3743.  3744.  3745.  3746.  3747.  3748.  3749.   375.  3750.  3751.]\n",
      "[ 84  58 106  38  74   4  18 127  62  50]\n",
      "[ 3752.  3753.  3754.  3755.  3756.  3757.  3758.  3759.   376.  3760.]\n",
      "[ 68  21   8  85  46 110 122  43 117   5]\n",
      "[ 3761.  3762.  3763.  3764.  3765.  3766.  3767.  3768.  3769.   377.]\n",
      "[ 45   4 126  96  67  78  67  52  32  13]\n",
      "[ 3770.  3771.  3772.  3773.  3774.  3775.  3776.  3777.  3778.  3779.]\n",
      "[ 34 127  83  82  87 110  62  80 109  74]\n",
      "[  378.  3780.  3781.  3782.  3783.  3784.  3785.  3786.  3787.  3788.]\n",
      "[ 47  40 106 111 109  10  33  44   3  95]\n",
      "[ 3789.   379.  3790.  3791.  3792.  3793.  3794.  3795.  3796.  3797.]\n",
      "[ 11 114  83 106  20  38  80  75 108  19]\n",
      "[ 3798.  3799.    38.   380.  3800.  3801.  3802.  3803.  3804.  3805.]\n",
      "[ 44  96 107   1  17  73  38  74  10 117]\n",
      "[ 3806.  3807.  3808.  3809.   381.  3810.  3811.  3812.  3813.  3814.]\n",
      "[  2  54  13  53 108  85  84  75  80  40]\n",
      "[ 3815.  3816.  3817.  3818.  3819.   382.  3820.  3821.  3822.  3823.]\n",
      "[ 35  84  29  74 111  90  65  29   1  75]\n",
      "[ 3824.  3825.  3826.  3827.  3828.  3829.   383.  3830.  3831.  3832.]\n",
      "[ 74   4  24  24  35  35  99 116  27  74]\n",
      "[ 3833.  3834.  3835.  3836.  3837.  3838.  3839.   384.  3840.  3841.]\n",
      "[108 117  98 106  62 111  87  13  17  85]\n",
      "[ 3842.  3843.  3844.  3845.  3846.  3847.  3848.  3849.   385.  3850.]\n",
      "[ 35  29 102  76  54 104 117  16  19  82]\n",
      "[ 3851.  3852.  3853.  3854.  3855.  3856.  3857.  3858.  3859.   386.]\n",
      "[111  27 111  52  88   9  79  94 117  81]\n",
      "[ 3860.  3861.  3862.  3863.  3864.  3865.  3866.  3867.  3868.  3869.]\n",
      "[ 96 124  27  97   8  94   3  64  29  49]\n",
      "[  387.  3870.  3871.  3872.  3873.  3874.  3875.  3876.  3877.  3878.]\n",
      "[ 45  87  68  38  85  83 108  54  87 114]\n",
      "[ 3879.   388.  3880.  3881.  3882.  3883.  3884.  3885.  3886.  3887.]\n",
      "[ 67 104 108   6  13  94  22  74  58 106]\n",
      "[ 3888.  3889.   389.  3890.  3891.  3892.  3893.  3894.  3895.  3896.]\n",
      "[ 68   4  67  91 111 105  38  88  80   3]\n",
      "[ 3897.  3898.  3899.    39.   390.  3900.  3901.  3902.  3903.  3904.]\n",
      "[114  13  35  95  52  95 114   8 102  74]\n",
      "[ 3905.  3906.  3907.  3908.  3909.   391.  3910.  3911.  3912.  3913.]\n",
      "[ 17  90  13  27 109  40   5 122 106   7]\n",
      "[ 3914.  3915.  3916.  3917.  3918.  3919.   392.  3920.  3921.  3922.]\n",
      "[ 31  78  63  95 108  45  84  67  48  85]\n",
      "[ 3923.  3924.  3925.  3926.  3927.  3928.  3929.   393.  3930.  3931.]\n",
      "[  8 122  29  40  65  79  40   8  51  86]\n",
      "[ 3932.  3933.  3934.  3935.  3936.  3937.  3938.  3939.   394.  3940.]\n",
      "[ 20  56 122  62  96  82  68  44  67   3]\n",
      "[ 3941.  3942.  3943.  3944.  3945.  3946.  3947.  3948.  3949.   395.]\n",
      "[ 86  80 109 120  44  36  74  95  28   7]\n",
      "[ 3950.  3951.  3952.  3953.  3954.  3955.  3956.  3957.  3958.  3959.]\n",
      "[ 61  83  75  87  87  61  43  20  28 110]\n",
      "[  396.  3960.  3961.  3962.  3963.  3964.  3965.  3966.  3967.  3968.]\n",
      "[ 86  74  14  37 103 108 117  14  73  14]\n",
      "[ 3969.   397.  3970.  3971.  3972.  3973.  3974.  3975.  3976.  3977.]\n",
      "[ 75 101  74  28 109  93  80  79  10   4]\n",
      "[ 3978.  3979.   398.  3980.  3981.  3982.  3983.  3984.  3985.  3986.]\n",
      "[  3 123  56  48 121  37  10  83  19  57]\n",
      "[ 3987.  3988.  3989.   399.  3990.  3991.  3992.  3993.  3994.  3995.]\n",
      "[ 83  75 106  20  54  21 116   4  78  29]\n",
      "[  3.99600000e+03   3.99700000e+03   3.99800000e+03   3.99900000e+03\n",
      "   4.00000000e+00   4.00000000e+01   4.00000000e+02   4.00000000e+03\n",
      "   4.00100000e+03   4.00200000e+03]\n",
      "[ 82 115  96  98  51  36   8 111  94  11]\n",
      "[ 4003.  4004.  4005.  4006.  4007.  4008.  4009.   401.  4010.  4011.]\n",
      "[ 38 111   3 111  86  27   7  45  31  54]\n",
      "[ 4012.  4013.  4014.  4015.  4016.  4017.  4018.  4019.   402.  4020.]\n",
      "[103  11   8  45  68  95  83  97  53  45]\n",
      "[ 4021.  4022.  4023.  4024.  4025.  4026.  4027.  4028.  4029.   403.]\n",
      "[ 63  78 124  29 120  41  35  96  52 110]\n",
      "[ 4030.  4031.  4032.  4033.  4034.  4035.  4036.  4037.  4038.  4039.]\n",
      "[ 58 110 116   3  63  40  33 111  63  39]\n",
      "[  404.  4040.  4041.  4042.  4043.  4044.  4045.  4046.  4047.  4048.]\n",
      "[ 95  88 122  80  78 110  68 127   6  67]\n",
      "[ 4049.   405.  4050.  4051.  4052.  4053.  4054.  4055.  4056.  4057.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 80  99  24  83  57  86 122  23  18 122]\n",
      "[ 4058.  4059.   406.  4060.  4061.  4062.  4063.  4064.  4065.  4066.]\n",
      "[ 73  67  40   8  86 116 128  68  68  19]\n",
      "[ 4067.  4068.  4069.   407.  4070.  4071.  4072.  4073.  4074.  4075.]\n",
      "[ 94 127   1  14  68  45   8  64 120  52]\n",
      "[ 4076.  4077.  4078.  4079.   408.  4080.  4081.  4082.  4083.  4084.]\n",
      "[ 63  62  73  83  74  19  18 110  44  75]\n",
      "[ 4085.  4086.  4087.  4088.  4089.   409.  4090.  4091.  4092.  4093.]\n",
      "[ 88 121  74  16  17  14 122  40  26  78]\n",
      "[ 4094.  4095.  4096.  4097.  4098.  4099.    41.   410.  4100.  4101.]\n",
      "[ 66  63  78 118 121 124  53  50  85   1]\n",
      "[ 4102.  4103.  4104.  4105.  4106.  4107.  4108.  4109.   411.  4110.]\n",
      "[90 52 84  9 14 18  8 65 46 44]\n",
      "[ 4111.  4112.  4113.  4114.  4115.  4116.  4117.  4118.  4119.   412.]\n",
      "[ 28  85  73  40  40 108 111  14 104  48]\n",
      "[ 4120.  4121.  4122.  4123.  4124.  4125.  4126.  4127.  4128.  4129.]\n",
      "[ 80   8  18   1  80  34 109  49  72 102]\n",
      "[  413.  4130.  4131.  4132.  4133.  4134.  4135.  4136.  4137.  4138.]\n",
      "[ 26  80  14  58 117 107  10  11  98   3]\n",
      "[ 4139.   414.  4140.  4141.  4142.  4143.  4144.  4145.  4146.  4147.]\n",
      "[106  11   8  19  77  60  20  72   5  78]\n",
      "[ 4148.  4149.   415.  4150.  4151.  4152.  4153.  4154.  4155.  4156.]\n",
      "[ 54  95  95  58 108  95  64  57 110  95]\n",
      "[ 4157.  4158.  4159.   416.  4160.  4161.  4162.  4163.  4164.  4165.]\n",
      "[ 21  83  11  68  55  85  62  34  53 124]\n",
      "[ 4166.  4167.  4168.  4169.   417.  4170.  4171.  4172.  4173.  4174.]\n",
      "[ 83  90  78  74  43 121  53   3  35  53]\n",
      "[ 4175.  4176.  4177.  4178.  4179.   418.  4180.  4181.  4182.  4183.]\n",
      "[ 68  78  13  96   5  37  96 123  20  78]\n",
      "[ 4184.  4185.  4186.  4187.  4188.  4189.   419.  4190.  4191.  4192.]\n",
      "[  8 107  78 124 100 109 117 108 122  85]\n",
      "[ 4193.  4194.  4195.  4196.  4197.  4198.  4199.    42.   420.  4200.]\n",
      "[77 93 38  8 74 40 58  2  6 17]\n",
      "[ 4201.  4202.  4203.  4204.  4205.  4206.  4207.  4208.  4209.   421.]\n",
      "[99 89 24 58 58 86  6 77 65 74]\n",
      "[ 4210.  4211.  4212.  4213.  4214.  4215.  4216.  4217.  4218.  4219.]\n",
      "[ 57 117  28  53  19  85  20  98   9 128]\n",
      "[  422.  4220.  4221.  4222.  4223.  4224.  4225.  4226.  4227.  4228.]\n",
      "[ 96  66  16  98  83  48 108 109   5 106]\n",
      "[ 4229.   423.  4230.  4231.  4232.  4233.  4234.  4235.  4236.  4237.]\n",
      "[ 50  83  86  18  22  43  35  16 114  82]\n",
      "[ 4238.  4239.   424.  4240.  4241.  4242.  4243.  4244.  4245.  4246.]\n",
      "[ 18  54  80  83  22  65 107  54 115   3]\n",
      "[ 4247.  4248.  4249.   425.  4250.  4251.  4252.  4253.  4254.  4255.]\n",
      "[ 75 111  27  41   4 121  62  83   5 101]\n",
      "[ 4256.  4257.  4258.  4259.   426.  4260.  4261.  4262.  4263.  4264.]\n",
      "[87 46 80 27 35 54 45 45 38 27]\n",
      "[ 4265.  4266.  4267.  4268.  4269.   427.  4270.  4271.  4272.  4273.]\n",
      "[ 20  58 106  51  17 116 122  94 121  61]\n",
      "[ 4274.  4275.  4276.  4277.  4278.  4279.   428.  4280.  4281.  4282.]\n",
      "[ 35 108  83  54  95  44 111 123   5 118]\n",
      "[ 4283.  4284.  4285.  4286.  4287.  4288.  4289.   429.  4290.  4291.]\n",
      "[112  53  19  30  82  67  19  66  89  45]\n",
      "[ 4292.  4293.  4294.  4295.  4296.  4297.  4298.  4299.    43.   430.]\n",
      "[ 31 101  93 120   8  36 128  88 110 120]\n",
      "[ 4300.  4301.  4302.  4303.  4304.  4305.  4306.  4307.  4308.  4309.]\n",
      "[11 54 31 20 14 90 31 41 54 86]\n",
      "[  431.  4310.  4311.  4312.  4313.  4314.  4315.  4316.  4317.  4318.]\n",
      "[117 106  62 111  28  86  64 128  14  67]\n",
      "[ 4319.   432.  4320.  4321.  4322.  4323.  4324.  4325.  4326.  4327.]\n",
      "[106  54  16  68 109  78  85  68 107  88]\n",
      "[ 4328.  4329.   433.  4330.  4331.  4332.  4333.  4334.  4335.  4336.]\n",
      "[114 120  96 106  18  13  57  53  20  54]\n",
      "[ 4337.  4338.  4339.   434.  4340.  4341.  4342.  4343.  4344.  4345.]\n",
      "[ 37  85  80  83  86 109  53  80  20  83]\n",
      "[ 4346.  4347.  4348.  4349.   435.  4350.  4351.  4352.  4353.  4354.]\n",
      "[ 94 106  24  18  97  79 122  74  75  27]\n",
      "[ 4355.  4356.  4357.  4358.  4359.   436.  4360.  4361.  4362.  4363.]\n",
      "[117  11  45  52 121 108 116  19  54   2]\n",
      "[ 4364.  4365.  4366.  4367.  4368.  4369.   437.  4370.  4371.  4372.]\n",
      "[75 87 23 74 99 65 53 27 75 19]\n",
      "[ 4373.  4374.  4375.  4376.  4377.  4378.  4379.   438.  4380.  4381.]\n",
      "[ 96  95  83  65  43  14 111  67  74  75]\n",
      "[ 4382.  4383.  4384.  4385.  4386.  4387.  4388.  4389.   439.  4390.]\n",
      "[ 5 48 40  7 90 54 82 17  3 85]\n",
      "[ 4391.  4392.  4393.  4394.  4395.  4396.  4397.  4398.  4399.    44.]\n",
      "[ 68  35  93  67 121  78  50  19  78 122]\n",
      "[  440.  4400.  4401.  4402.  4403.  4404.  4405.  4406.  4407.  4408.]\n",
      "[121  97  65  65 110  76  23  78  11  14]\n",
      "[ 4409.   441.  4410.  4411.  4412.  4413.  4414.  4415.  4416.  4417.]\n",
      "[36 75 67 19  9 78 83 41 88 74]\n",
      "[ 4418.  4419.   442.  4420.  4421.  4422.  4423.  4424.  4425.  4426.]\n",
      "[ 97 110  63 107  57 127  96  54  78  40]\n",
      "[ 4427.  4428.  4429.   443.  4430.  4431.  4432.  4433.  4434.  4435.]\n",
      "[ 35   4  90  89  23  79  85 101  67  85]\n",
      "[ 4436.  4437.  4438.  4439.   444.  4440.  4441.  4442.  4443.  4444.]\n",
      "[  5  29 115  11  98  67  13 106  56  38]\n",
      "[ 4445.  4446.  4447.  4448.  4449.   445.  4450.  4451.  4452.  4453.]\n",
      "[106  97  28  38  23 101  54  37  74 115]\n",
      "[ 4454.  4455.  4456.  4457.  4458.  4459.   446.  4460.  4461.  4462.]\n",
      "[ 83   8 104  54  74  65  91  38  55   7]\n",
      "[ 4463.  4464.  4465.  4466.  4467.  4468.  4469.   447.  4470.  4471.]\n",
      "[111 126 122  28   5  48  50  19  10  77]\n",
      "[ 4472.  4473.  4474.  4475.  4476.  4477.  4478.  4479.   448.  4480.]\n",
      "[ 79   1  53  29 107   1  13  90  68 119]\n",
      "[ 4481.  4482.  4483.  4484.  4485.  4486.  4487.  4488.  4489.   449.]\n",
      "[ 79  63  90 121  41  62  78 116  41  46]\n",
      "[ 4490.  4491.  4492.  4493.  4494.  4495.  4496.  4497.  4498.  4499.]\n",
      "[ 97 121   7  30  77  37 115  96 123  60]\n",
      "[   45.   450.  4500.  4501.  4502.  4503.  4504.  4505.  4506.  4507.]\n",
      "[ 67  62  73  67 110  14  53  14  20  95]\n",
      "[ 4508.  4509.   451.  4510.  4511.  4512.  4513.  4514.  4515.  4516.]\n",
      "[ 75  36  31  98  35  80  79  80  83 110]\n",
      "[ 4517.  4518.  4519.   452.  4520.  4521.  4522.  4523.  4524.  4525.]\n",
      "[ 93  28  83  86  63 116  45  83 107  41]\n",
      "[ 4526.  4527.  4528.  4529.   453.  4530.  4531.  4532.  4533.  4534.]\n",
      "[115  99  72 117 106  91  78  40  19  48]\n",
      "[ 4535.  4536.  4537.  4538.  4539.   454.  4540.  4541.  4542.  4543.]\n",
      "[18 46 84 93 18 78 23 19  4 83]\n",
      "[ 4544.  4545.  4546.  4547.  4548.  4549.   455.  4550.  4551.  4552.]\n",
      "[117  35  54  11  97  45  27 121  49  77]\n",
      "[ 4553.  4554.  4555.  4556.  4557.  4558.  4559.   456.  4560.  4561.]\n",
      "[ 13  44  20   9  53  78  88  28 128  11]\n",
      "[ 4562.  4563.  4564.  4565.  4566.  4567.  4568.  4569.   457.  4570.]\n",
      "[ 96  95 109 113  20  74  52  50  97 117]\n",
      "[ 4571.  4572.  4573.  4574.  4575.  4576.  4577.  4578.  4579.   458.]\n",
      "[ 29  27 122  83  28  96  20  27  63  28]\n",
      "[ 4580.  4581.  4582.  4583.  4584.  4585.  4586.  4587.  4588.  4589.]\n",
      "[110 117   8  40 113 123  76  74  78   3]\n",
      "[  459.  4590.  4591.  4592.  4593.  4594.  4595.  4596.  4597.  4598.]\n",
      "[ 35  95 108 108  83  83  96  68 114 110]\n",
      "[ 4599.    46.   460.  4600.  4601.  4602.  4603.  4604.  4605.  4606.]\n",
      "[33 19 65 89  4 40 67  8 80 49]\n",
      "[ 4607.  4608.  4609.   461.  4610.  4611.  4612.  4613.  4614.  4615.]\n",
      "[  4 111  10  27   1  28  33 109  87   4]\n",
      "[ 4616.  4617.  4618.  4619.   462.  4620.  4621.  4622.  4623.  4624.]\n",
      "[85  4 86 52 93 46 16 54 54 85]\n",
      "[ 4625.  4626.  4627.  4628.  4629.   463.  4630.  4631.  4632.  4633.]\n",
      "[101  86  98  11  74  76  85  38  85  61]\n",
      "[ 4634.  4635.  4636.  4637.  4638.  4639.   464.  4640.  4641.  4642.]\n",
      "[ 5  7  3 77  6  5 77 61 22 95]\n",
      "[ 4643.  4644.  4645.  4646.  4647.  4648.  4649.   465.  4650.  4651.]\n",
      "[ 29  85   1   7  49 111   8  19  98  85]\n",
      "[ 4652.  4653.  4654.  4655.  4656.  4657.  4658.  4659.   466.  4660.]\n",
      "[ 94  27   7  19  87  20  34  62 116  13]\n",
      "[ 4661.  4662.  4663.  4664.  4665.  4666.  4667.  4668.  4669.   467.]\n",
      "[ 74  10  96  38  62   8  71  87 118 106]\n",
      "[ 4670.  4671.  4672.  4673.  4674.  4675.  4676.  4677.  4678.  4679.]\n",
      "[ 31  45 122   8  96  54  20  17  40   1]\n",
      "[  468.  4680.  4681.  4682.  4683.  4684.  4685.  4686.  4687.  4688.]\n",
      "[117  80   7  24  53  96 114  83  27  85]\n",
      "[ 4689.   469.  4690.  4691.  4692.  4693.  4694.  4695.  4696.  4697.]\n",
      "[ 20  68  76  65 122  20  19  29  19  78]\n",
      "[ 4698.  4699.    47.   470.  4700.  4701.  4702.  4703.  4704.  4705.]\n",
      "[ 87  78  79  36  46  58  80  45  67 111]\n",
      "[ 4706.  4707.  4708.  4709.   471.  4710.  4711.  4712.  4713.  4714.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27  49  36  85  73 122 115  54   8  94]\n",
      "[ 4715.  4716.  4717.  4718.  4719.   472.  4720.  4721.  4722.  4723.]\n",
      "[58 13 21 17  4 80 45  3 49 79]\n",
      "[ 4724.  4725.  4726.  4727.  4728.  4729.   473.  4730.  4731.  4732.]\n",
      "[ 62  27   5   5   6 108  97  49  74  46]\n",
      "[ 4733.  4734.  4735.  4736.  4737.  4738.  4739.   474.  4740.  4741.]\n",
      "[  6 116 111  10 127 126   8  21 125  84]\n",
      "[ 4742.  4743.  4744.  4745.  4746.  4747.  4748.  4749.   475.  4750.]\n",
      "[  8 117  85  18  19  61  85   8  78  57]\n",
      "[ 4751.  4752.  4753.  4754.  4755.  4756.  4757.  4758.  4759.   476.]\n",
      "[82 61 44 84 86 40 45 96 31 67]\n",
      "[ 4760.  4761.  4762.  4763.  4764.  4765.  4766.  4767.  4768.  4769.]\n",
      "[ 36  62 102  68  38 108  76 123  64  28]\n",
      "[  477.  4770.  4771.  4772.  4773.  4774.  4775.  4776.  4777.  4778.]\n",
      "[124  61  95  38  40   8 104  75 107   9]\n",
      "[ 4779.   478.  4780.  4781.  4782.  4783.  4784.  4785.  4786.  4787.]\n",
      "[ 27 106   7  36  49  78  88 123 104  75]\n",
      "[ 4788.  4789.   479.  4790.  4791.  4792.  4793.  4794.  4795.  4796.]\n",
      "[48  7 31  4 49 96  8 46 35 19]\n",
      "[ 4797.  4798.  4799.    48.   480.  4800.  4801.  4802.  4803.  4804.]\n",
      "[ 58  56  28 111 107  54  83  93 116 122]\n",
      "[ 4805.  4806.  4807.  4808.  4809.   481.  4810.  4811.  4812.  4813.]\n",
      "[ 66   4  52   8 117  68  73 122  10  35]\n",
      "[ 4814.  4815.  4816.  4817.  4818.  4819.   482.  4820.  4821.  4822.]\n",
      "[ 99 108  83  83 117 107 104 123  35  28]\n",
      "[ 4823.  4824.  4825.  4826.  4827.  4828.  4829.   483.  4830.  4831.]\n",
      "[  6   5  84  87  80 117  18  83  27  24]\n",
      "[ 4832.  4833.  4834.  4835.  4836.  4837.  4838.  4839.   484.  4840.]\n",
      "[  3 101  80  98 126  35  27 110  83  51]\n",
      "[ 4841.  4842.  4843.  4844.  4845.  4846.  4847.  4848.  4849.   485.]\n",
      "[116  86  53 106  63  40 123   7  69  96]\n",
      "[ 4850.  4851.  4852.  4853.  4854.  4855.  4856.  4857.  4858.  4859.]\n",
      "[ 83 120  40  17  83   7  62  28 112  10]\n",
      "[  486.  4860.  4861.  4862.  4863.  4864.  4865.  4866.  4867.  4868.]\n",
      "[123 102  45  74  67  83 108   5  19  31]\n",
      "[ 4869.   487.  4870.  4871.  4872.  4873.  4874.  4875.  4876.  4877.]\n",
      "[111 111  68 127 116  82  74  74 107  62]\n",
      "[ 4878.  4879.   488.  4880.  4881.  4882.  4883.  4884.  4885.  4886.]\n",
      "[ 49  62  48  74 111  83  21  96 122 106]\n",
      "[ 4887.  4888.  4889.   489.  4890.  4891.  4892.  4893.  4894.  4895.]\n",
      "[ 27  74  76 115  65  17  20 122  28  83]\n",
      "[ 4896.  4897.  4898.  4899.    49.   490.  4900.  4901.  4902.  4903.]\n",
      "[ 53  93  67   8  78  65  17 123  11  94]\n",
      "[ 4904.  4905.  4906.  4907.  4908.  4909.   491.  4910.  4911.  4912.]\n",
      "[ 93 121  62  39  94  83  74 117  46  84]\n",
      "[ 4913.  4914.  4915.  4916.  4917.  4918.  4919.   492.  4920.  4921.]\n",
      "[ 58  58 107  10   9 117 106  90  64   8]\n",
      "[ 4922.  4923.  4924.  4925.  4926.  4927.  4928.  4929.   493.  4930.]\n",
      "[107   6 117  83  88  90  11  54 114  78]\n",
      "[ 4931.  4932.  4933.  4934.  4935.  4936.  4937.  4938.  4939.   494.]\n",
      "[110 112  35  94  87  84  46  74  56  97]\n",
      "[ 4940.  4941.  4942.  4943.  4944.  4945.  4946.  4947.  4948.  4949.]\n",
      "[119 101 116  21 104  21  22  20  79 116]\n",
      "[  495.  4950.  4951.  4952.  4953.  4954.  4955.  4956.  4957.  4958.]\n",
      "[123  99  13   8  11 111  11 123 122  88]\n",
      "[ 4959.   496.  4960.  4961.  4962.  4963.  4964.  4965.  4966.  4967.]\n",
      "[ 93   5 122  20  60  93  38  49 110  97]\n",
      "[ 4968.  4969.   497.  4970.  4971.  4972.  4973.  4974.  4975.  4976.]\n",
      "[ 54   6  58  89 108  83  74  20  68  94]\n",
      "[ 4977.  4978.  4979.   498.  4980.  4981.  4982.  4983.  4984.  4985.]\n",
      "[ 16 127   9  72  52  19  49 111  72  20]\n",
      "[ 4986.  4987.  4988.  4989.   499.  4990.  4991.  4992.  4993.  4994.]\n",
      "[ 86   5  74 122   9  19  96  13  85  83]\n",
      "[  4.99500000e+03   4.99600000e+03   4.99700000e+03   4.99800000e+03\n",
      "   4.99900000e+03   5.00000000e+00   5.00000000e+01   5.00000000e+02\n",
      "   5.00000000e+03   5.00100000e+03]\n",
      "[ 66 114 126 111  52 106  80  28  43  80]\n",
      "[ 5002.  5003.  5004.  5005.  5006.  5007.  5008.  5009.   501.  5010.]\n",
      "[101  68  83 121  61  94  31   8  48  80]\n",
      "[ 5011.  5012.  5013.  5014.  5015.  5016.  5017.  5018.  5019.   502.]\n",
      "[ 3 83 94 48 14 96 79 67 49 74]\n",
      "[ 5020.  5021.  5022.  5023.  5024.  5025.  5026.  5027.  5028.  5029.]\n",
      "[  9 116  17  53  14  33 104  90  35 108]\n",
      "[  503.  5030.  5031.  5032.  5033.  5034.  5035.  5036.  5037.  5038.]\n",
      "[111  77  10  38  27  96  72  83  86 121]\n",
      "[ 5039.   504.  5040.  5041.  5042.  5043.  5044.  5045.  5046.  5047.]\n",
      "[  4  74  27  48  75  90  45 122  86 101]\n",
      "[ 5048.  5049.   505.  5050.  5051.  5052.  5053.  5054.  5055.  5056.]\n",
      "[ 90 108 113 126   5  62  46  83 122  21]\n",
      "[ 5057.  5058.  5059.   506.  5060.  5061.  5062.  5063.  5064.  5065.]\n",
      "[ 94  76  75 111  94  19  78  87  33   8]\n",
      "[ 5066.  5067.  5068.  5069.   507.  5070.  5071.  5072.  5073.  5074.]\n",
      "[106 102   8  14 113  94  52  79 107  50]\n",
      "[ 5075.  5076.  5077.  5078.  5079.   508.  5080.  5081.  5082.  5083.]\n",
      "[ 83  13 111 111  88  65  77  83  96  99]\n",
      "[ 5084.  5085.  5086.  5087.  5088.  5089.   509.  5090.  5091.  5092.]\n",
      "[124  23  44  96   3  79  68  74  45  91]\n",
      "[ 5093.  5094.  5095.  5096.  5097.  5098.  5099.    51.   510.  5100.]\n",
      "[ 67  22  83  95  79  67  46  74  41 122]\n",
      "[ 5101.  5102.  5103.  5104.  5105.  5106.  5107.  5108.  5109.   511.]\n",
      "[ 35  99  67  74  79  77 116  80  38   3]\n",
      "[ 5110.  5111.  5112.  5113.  5114.  5115.  5116.  5117.  5118.  5119.]\n",
      "[108 122  54 116 122  49   4  63 108 107]\n",
      "[  512.  5120.  5121.  5122.  5123.  5124.  5125.  5126.  5127.  5128.]\n",
      "[ 84  44  54  27  83 108  81 106  75  20]\n",
      "[ 5129.   513.  5130.  5131.  5132.  5133.  5134.  5135.  5136.  5137.]\n",
      "[ 27  79  19  13 117  63  18 124  27 122]\n",
      "[ 5138.  5139.   514.  5140.  5141.  5142.  5143.  5144.  5145.  5146.]\n",
      "[ 27  18  63  97  36  81  14  87 101  41]\n",
      "[ 5147.  5148.  5149.   515.  5150.  5151.  5152.  5153.  5154.  5155.]\n",
      "[ 68  72  39  86 111 109  19   4  53  52]\n",
      "[ 5156.  5157.  5158.  5159.   516.  5160.  5161.  5162.  5163.  5164.]\n",
      "[ 38  28 111  30 117 122  27  45  64  19]\n",
      "[ 5165.  5166.  5167.  5168.  5169.   517.  5170.  5171.  5172.  5173.]\n",
      "[ 27  74  93  83  48  44 123  49 121   3]\n",
      "[ 5174.  5175.  5176.  5177.  5178.  5179.   518.  5180.  5181.  5182.]\n",
      "[ 58  96  20  78 116 106  20 107   4  23]\n",
      "[ 5183.  5184.  5185.  5186.  5187.  5188.  5189.   519.  5190.  5191.]\n",
      "[ 13   4 108  95 117  81 112 103  68  63]\n",
      "[ 5192.  5193.  5194.  5195.  5196.  5197.  5198.  5199.    52.   520.]\n",
      "[ 62  75  80   9  87 123  54   9 106  95]\n",
      "[ 5200.  5201.  5202.  5203.  5204.  5205.  5206.  5207.  5208.  5209.]\n",
      "[123  58  36  76  53   2  74  77 117  53]\n",
      "[  521.  5210.  5211.  5212.  5213.  5214.  5215.  5216.  5217.  5218.]\n",
      "[54 43 52 46 54  4  3 40 61 54]\n",
      "[ 5219.   522.  5220.  5221.  5222.  5223.  5224.  5225.  5226.  5227.]\n",
      "[58  4 79 13 82 36 94 50 26 78]\n",
      "[ 5228.  5229.   523.  5230.  5231.  5232.  5233.  5234.  5235.  5236.]\n",
      "[ 58  36  31 101  58 101  49  18  41  10]\n",
      "[ 5237.  5238.  5239.   524.  5240.  5241.  5242.  5243.  5244.  5245.]\n",
      "[ 38  45  19  83 120  40 107  79  55  84]\n",
      "[ 5246.  5247.  5248.  5249.   525.  5250.  5251.  5252.  5253.  5254.]\n",
      "[ 52  43  35 106  83  52  28  13 122  60]\n",
      "[ 5255.  5256.  5257.  5258.  5259.   526.  5260.  5261.  5262.  5263.]\n",
      "[  3  17  99  45  95  22 122  40  52  10]\n",
      "[ 5264.  5265.  5266.  5267.  5268.  5269.   527.  5270.  5271.  5272.]\n",
      "[ 93 110  28  45  20  27  19 104  63  88]\n",
      "[ 5273.  5274.  5275.  5276.  5277.  5278.  5279.   528.  5280.  5281.]\n",
      "[ 56  53  96  87   8  65   9  21  96 110]\n",
      "[ 5282.  5283.  5284.  5285.  5286.  5287.  5288.  5289.   529.  5290.]\n",
      "[ 48  35  22 122   7  50   4 108  85   5]\n",
      "[ 5291.  5292.  5293.  5294.  5295.  5296.  5297.  5298.  5299.    53.]\n",
      "[ 33 120  83  78   2  49  90 122 116 123]\n",
      "[  530.  5300.  5301.  5302.  5303.  5304.  5305.  5306.  5307.  5308.]\n",
      "[108  49 117  81   5  61  85 113  64 107]\n",
      "[ 5309.   531.  5310.  5311.  5312.  5313.  5314.  5315.  5316.  5317.]\n",
      "[ 13  23   8  43  26 122  22  86  85 109]\n",
      "[ 5318.  5319.   532.  5320.  5321.  5322.  5323.  5324.  5325.  5326.]\n",
      "[ 72  80 106  45 113 106 120  20  68  76]\n",
      "[ 5327.  5328.  5329.   533.  5330.  5331.  5332.  5333.  5334.  5335.]\n",
      "[127 122  99   8  19  30  80  46  86  70]\n",
      "[ 5336.  5337.  5338.  5339.   534.  5340.  5341.  5342.  5343.  5344.]\n",
      "[ 78  79  90 110 106 107  96  95 123 118]\n",
      "[ 5345.  5346.  5347.  5348.  5349.   535.  5350.  5351.  5352.  5353.]\n",
      "[ 58  38  57  79 111  61  40  84 104  65]\n",
      "[ 5354.  5355.  5356.  5357.  5358.  5359.   536.  5360.  5361.  5362.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1  48  99  86   1  97  19 117  27  74]\n",
      "[ 5363.  5364.  5365.  5366.  5367.  5368.  5369.   537.  5370.  5371.]\n",
      "[116  94  17  96  45  40  45  13  95 112]\n",
      "[ 5372.  5373.  5374.  5375.  5376.  5377.  5378.  5379.   538.  5380.]\n",
      "[104 123  11  17 122  96  82 108 101  58]\n",
      "[ 5381.  5382.  5383.  5384.  5385.  5386.  5387.  5388.  5389.   539.]\n",
      "[117 116  11 116  48  97 107  85 111  49]\n",
      "[ 5390.  5391.  5392.  5393.  5394.  5395.  5396.  5397.  5398.  5399.]\n",
      "[21 74 14 37 58 58 48 35 65 46]\n",
      "[   54.   540.  5400.  5401.  5402.  5403.  5404.  5405.  5406.  5407.]\n",
      "[101  68  52   8 102  77   4  99  96   9]\n",
      "[ 5408.  5409.   541.  5410.  5411.  5412.  5413.  5414.  5415.  5416.]\n",
      "[ 87   5  67  83 122 111 128  20  96  46]\n",
      "[ 5417.  5418.  5419.   542.  5420.  5421.  5422.  5423.  5424.  5425.]\n",
      "[108 101 117  88  14  75 102  58  66   8]\n",
      "[ 5426.  5427.  5428.  5429.   543.  5430.  5431.  5432.  5433.  5434.]\n",
      "[102   7  58  80  93   1  39  53  96  58]\n",
      "[ 5435.  5436.  5437.  5438.  5439.   544.  5440.  5441.  5442.  5443.]\n",
      "[106  83 101  65  70  98  78 122  95 115]\n",
      "[ 5444.  5445.  5446.  5447.  5448.  5449.   545.  5450.  5451.  5452.]\n",
      "[116 106 111 121  29  27 110  13  35  33]\n",
      "[ 5453.  5454.  5455.  5456.  5457.  5458.  5459.   546.  5460.  5461.]\n",
      "[ 45  53  83 117  37 117 117  87 116  17]\n",
      "[ 5462.  5463.  5464.  5465.  5466.  5467.  5468.  5469.   547.  5470.]\n",
      "[111  81  73  83  54  86  45 102  96  82]\n",
      "[ 5471.  5472.  5473.  5474.  5475.  5476.  5477.  5478.  5479.   548.]\n",
      "[ 63  83   7  65 116  68 108  58  11  37]\n",
      "[ 5480.  5481.  5482.  5483.  5484.  5485.  5486.  5487.  5488.  5489.]\n",
      "[ 28  62  53  28  75  82  19 117  42  45]\n",
      "[  549.  5490.  5491.  5492.  5493.  5494.  5495.  5496.  5497.  5498.]\n",
      "[96  1 83 75 45 84 40  9 31 67]\n",
      "[ 5499.    55.   550.  5500.  5501.  5502.  5503.  5504.  5505.  5506.]\n",
      "[ 88  19  19 124  36  41  10 111  40  98]\n",
      "[ 5507.  5508.  5509.   551.  5510.  5511.  5512.  5513.  5514.  5515.]\n",
      "[ 79   8 108  96  73 122  33  82  68  11]\n",
      "[ 5516.  5517.  5518.  5519.   552.  5520.  5521.  5522.  5523.  5524.]\n",
      "[123  86  98  78 108 121  28  75  85   1]\n",
      "[ 5525.  5526.  5527.  5528.  5529.   553.  5530.  5531.  5532.  5533.]\n",
      "[ 40 109  17   5 110 121  86  98  54  78]\n",
      "[ 5534.  5535.  5536.  5537.  5538.  5539.   554.  5540.  5541.  5542.]\n",
      "[ 62 117 117  40  13 122 122  65  20  38]\n",
      "[ 5543.  5544.  5545.  5546.  5547.  5548.  5549.   555.  5550.  5551.]\n",
      "[123  95  68  54 121  96  19  78 128  41]\n",
      "[ 5552.  5553.  5554.  5555.  5556.  5557.  5558.  5559.   556.  5560.]\n",
      "[  1 108  72  58 123   9 127 107  68  49]\n",
      "[ 5561.  5562.  5563.  5564.  5565.  5566.  5567.  5568.  5569.   557.]\n",
      "[107  43  88  45  41   1  29  85  39 109]\n",
      "[ 5570.  5571.  5572.  5573.  5574.  5575.  5576.  5577.  5578.  5579.]\n",
      "[  1 111  71  74 123  76  10 117  68  11]\n",
      "[  558.  5580.  5581.  5582.  5583.  5584.  5585.  5586.  5587.  5588.]\n",
      "[ 17   6 106  67 102  64  95  83  29  65]\n",
      "[ 5589.   559.  5590.  5591.  5592.  5593.  5594.  5595.  5596.  5597.]\n",
      "[111  28   7  40  29 111  24 107  74  74]\n",
      "[ 5598.  5599.    56.   560.  5600.  5601.  5602.  5603.  5604.  5605.]\n",
      "[ 60  27  35 109  18  37 116  31 123  83]\n",
      "[ 5606.  5607.  5608.  5609.   561.  5610.  5611.  5612.  5613.  5614.]\n",
      "[ 68  94  68 123  19  64   7 122  20  41]\n",
      "[ 5615.  5616.  5617.  5618.  5619.   562.  5620.  5621.  5622.  5623.]\n",
      "[ 17  80  78  35  75  23  68 124  96  79]\n",
      "[ 5624.  5625.  5626.  5627.  5628.  5629.   563.  5630.  5631.  5632.]\n",
      "[  3  87 109  14 109 116  96  85  74 111]\n",
      "[ 5633.  5634.  5635.  5636.  5637.  5638.  5639.   564.  5640.  5641.]\n",
      "[ 65 106 126  68 111  87  87 122  77  83]\n",
      "[ 5642.  5643.  5644.  5645.  5646.  5647.  5648.  5649.   565.  5650.]\n",
      "[  1  24 123  83   5  70  19  35 122  14]\n",
      "[ 5651.  5652.  5653.  5654.  5655.  5656.  5657.  5658.  5659.   566.]\n",
      "[120 120  65  67  62 106  13  74  24  10]\n",
      "[ 5660.  5661.  5662.  5663.  5664.  5665.  5666.  5667.  5668.  5669.]\n",
      "[122   5   5  90  24  20  65  43 116  61]\n",
      "[  567.  5670.  5671.  5672.  5673.  5674.  5675.  5676.  5677.  5678.]\n",
      "[ 36 108  18  34  95  43  13  27 122 121]\n",
      "[ 5679.   568.  5680.  5681.  5682.  5683.  5684.  5685.  5686.  5687.]\n",
      "[ 24  49  18 110  77  38 122  64  75  72]\n",
      "[ 5688.  5689.   569.  5690.  5691.  5692.  5693.  5694.  5695.  5696.]\n",
      "[97 87 78 34 93 27 35 83 58 60]\n",
      "[ 5697.  5698.  5699.    57.   570.  5700.  5701.  5702.  5703.  5704.]\n",
      "[ 78  17 101  85   7   9   5  83  78  79]\n",
      "[ 5705.  5706.  5707.  5708.  5709.   571.  5710.  5711.  5712.  5713.]\n",
      "[ 90 104  72  93  54  50 121  53  18 106]\n",
      "[ 5714.  5715.  5716.  5717.  5718.  5719.   572.  5720.  5721.  5722.]\n",
      "[37 17 27  5  8 20 27 39 27 85]\n",
      "[ 5723.  5724.  5725.  5726.  5727.  5728.  5729.   573.  5730.  5731.]\n",
      "[123  96  38  16 116  95  19  33  37   4]\n",
      "[ 5732.  5733.  5734.  5735.  5736.  5737.  5738.  5739.   574.  5740.]\n",
      "[ 27  72 123  95  67 110 108  49 110  94]\n",
      "[ 5741.  5742.  5743.  5744.  5745.  5746.  5747.  5748.  5749.   575.]\n",
      "[ 90  27  35 112  29  40   8 111  38  14]\n",
      "[ 5750.  5751.  5752.  5753.  5754.  5755.  5756.  5757.  5758.  5759.]\n",
      "[ 94  19 111  52  19  21  13 123  45 112]\n",
      "[  576.  5760.  5761.  5762.  5763.  5764.  5765.  5766.  5767.  5768.]\n",
      "[ 79  30  78   9  84  36 122  20 116  84]\n",
      "[ 5769.   577.  5770.  5771.  5772.  5773.  5774.  5775.  5776.  5777.]\n",
      "[54  1  7 78 88 78 54 45 12 38]\n",
      "[ 5778.  5779.   578.  5780.  5781.  5782.  5783.  5784.  5785.  5786.]\n",
      "[123 108  68  54 122  41  93  83  31  11]\n",
      "[ 5787.  5788.  5789.   579.  5790.  5791.  5792.  5793.  5794.  5795.]\n",
      "[119   5  45  13  49  48  39  20  63  98]\n",
      "[ 5796.  5797.  5798.  5799.    58.   580.  5800.  5801.  5802.  5803.]\n",
      "[ 43 106  85 117  16  80  83  86  81  95]\n",
      "[ 5804.  5805.  5806.  5807.  5808.  5809.   581.  5810.  5811.  5812.]\n",
      "[ 47  22  74  21  75 102  65  19  18   9]\n",
      "[ 5813.  5814.  5815.  5816.  5817.  5818.  5819.   582.  5820.  5821.]\n",
      "[109 110 127  96 101  43  78  89  10  35]\n",
      "[ 5822.  5823.  5824.  5825.  5826.  5827.  5828.  5829.   583.  5830.]\n",
      "[ 20 122  17 102  83  54  19  83  97  83]\n",
      "[ 5831.  5832.  5833.  5834.  5835.  5836.  5837.  5838.  5839.   584.]\n",
      "[ 93  83  75   9  87  18  27  35 122 106]\n",
      "[ 5840.  5841.  5842.  5843.  5844.  5845.  5846.  5847.  5848.  5849.]\n",
      "[96 99 27 94 52 97  7 19 96 71]\n",
      "[  585.  5850.  5851.  5852.  5853.  5854.  5855.  5856.  5857.  5858.]\n",
      "[45  3 86 18 76 98 83 98 77 27]\n",
      "[ 5859.   586.  5860.  5861.  5862.  5863.  5864.  5865.  5866.  5867.]\n",
      "[ 31  96  45 101  74  78 110  17  39  52]\n",
      "[ 5868.  5869.   587.  5870.  5871.  5872.  5873.  5874.  5875.  5876.]\n",
      "[ 18  43  96  37  97   8 104  56 111 110]\n",
      "[ 5877.  5878.  5879.   588.  5880.  5881.  5882.  5883.  5884.  5885.]\n",
      "[103   1  61  40 108  65  40 107  83 123]\n",
      "[ 5886.  5887.  5888.  5889.   589.  5890.  5891.  5892.  5893.  5894.]\n",
      "[ 65  28 117  48  53  19 117   4  58   9]\n",
      "[ 5895.  5896.  5897.  5898.  5899.    59.   590.  5900.  5901.  5902.]\n",
      "[ 78  17 117   1  96  63 122 102   9  44]\n",
      "[ 5903.  5904.  5905.  5906.  5907.  5908.  5909.   591.  5910.  5911.]\n",
      "[112  27  13  62  77  75  54  64  24  20]\n",
      "[ 5912.  5913.  5914.  5915.  5916.  5917.  5918.  5919.   592.  5920.]\n",
      "[19 54 47 38 54 52 65 85 36 31]\n",
      "[ 5921.  5922.  5923.  5924.  5925.  5926.  5927.  5928.  5929.   593.]\n",
      "[ 97  87 103  43 126  93  54  65 106  75]\n",
      "[ 5930.  5931.  5932.  5933.  5934.  5935.  5936.  5937.  5938.  5939.]\n",
      "[ 45 111  37  43  29 128  79  83  18  30]\n",
      "[  594.  5940.  5941.  5942.  5943.  5944.  5945.  5946.  5947.  5948.]\n",
      "[ 23  11  61 101  78   7  88  19  64  81]\n",
      "[ 5949.   595.  5950.  5951.  5952.  5953.  5954.  5955.  5956.  5957.]\n",
      "[117  95 123 117  96 111  67  41  85 116]\n",
      "[ 5958.  5959.   596.  5960.  5961.  5962.  5963.  5964.  5965.  5966.]\n",
      "[44  1  4 95 81 49 28 96  1 19]\n",
      "[ 5967.  5968.  5969.   597.  5970.  5971.  5972.  5973.  5974.  5975.]\n",
      "[90 96 19 80 10 21 96  9 31 65]\n",
      "[ 5976.  5977.  5978.  5979.   598.  5980.  5981.  5982.  5983.  5984.]\n",
      "[ 94  14  85 109  54   4  73 101 116  16]\n",
      "[ 5985.  5986.  5987.  5988.  5989.   599.  5990.  5991.  5992.  5993.]\n",
      "[ 38 122   4 117  20  65 106 115 117  44]\n",
      "[ 5994.  5995.  5996.  5997.  5998.  5999.     6.    60.   600.  6000.]\n",
      "[ 54   7  88  74 121  66   2 112 117  58]\n",
      "[ 6001.  6002.  6003.  6004.  6005.  6006.  6007.  6008.  6009.   601.]\n",
      "[40 35 83 74  1 40 39 60 19 35]\n",
      "[ 6010.  6011.  6012.  6013.  6014.  6015.  6016.  6017.  6018.  6019.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94  13  58  10  33  85 110 123  74  85]\n",
      "[  602.  6020.  6021.  6022.  6023.  6024.  6025.  6026.  6027.  6028.]\n",
      "[ 40  28  58  49  86  75  83   3 108  44]\n",
      "[ 6029.   603.  6030.  6031.  6032.  6033.  6034.  6035.  6036.  6037.]\n",
      "[ 31  22 110 122 117 113 124  43 120 121]\n",
      "[ 6038.  6039.   604.  6040.  6041.  6042.  6043.  6044.  6045.  6046.]\n",
      "[ 90  83   4 107  10  52  52  74   5  53]\n",
      "[ 6047.  6048.  6049.   605.  6050.  6051.  6052.  6053.  6054.  6055.]\n",
      "[ 74  58  10  54  99 117  84  68  77 126]\n",
      "[ 6056.  6057.  6058.  6059.   606.  6060.  6061.  6062.  6063.  6064.]\n",
      "[ 20 117  77 121  45  85  49  49  52 124]\n",
      "[ 6065.  6066.  6067.  6068.  6069.   607.  6070.  6071.  6072.  6073.]\n",
      "[102   5  89  78  38  80 121  72  41   3]\n",
      "[ 6074.  6075.  6076.  6077.  6078.  6079.   608.  6080.  6081.  6082.]\n",
      "[97  8 54 82  1 35 54 68 84 58]\n",
      "[ 6083.  6084.  6085.  6086.  6087.  6088.  6089.   609.  6090.  6091.]\n",
      "[ 63  49  67   7  20 101 124  22  27  38]\n",
      "[ 6092.  6093.  6094.  6095.  6096.  6097.  6098.  6099.    61.   610.]\n",
      "[ 94  75 121  28  94 117  65  78  94 109]\n",
      "[ 6100.  6101.  6102.  6103.  6104.  6105.  6106.  6107.  6108.  6109.]\n",
      "[65 17 35 40 60 54 10 74 75 83]\n",
      "[  611.  6110.  6111.  6112.  6113.  6114.  6115.  6116.  6117.  6118.]\n",
      "[122 126 108   1 104 102  27  80  63  16]\n",
      "[ 6119.   612.  6120.  6121.  6122.  6123.  6124.  6125.  6126.  6127.]\n",
      "[ 83  83  54  95   4 109  73  77  62  40]\n",
      "[ 6128.  6129.   613.  6130.  6131.  6132.  6133.  6134.  6135.  6136.]\n",
      "[96 84  8 98 70 83  9 74 31 31]\n",
      "[ 6137.  6138.  6139.   614.  6140.  6141.  6142.  6143.  6144.  6145.]\n",
      "[ 83 103  87  78   9  35  13  65 123   9]\n",
      "[ 6146.  6147.  6148.  6149.   615.  6150.  6151.  6152.  6153.  6154.]\n",
      "[107  97  74   1 108  95  34  14  27  94]\n",
      "[ 6155.  6156.  6157.  6158.  6159.   616.  6160.  6161.  6162.  6163.]\n",
      "[ 16  96 128 123  27  94  68 111  53  94]\n",
      "[ 6164.  6165.  6166.  6167.  6168.  6169.   617.  6170.  6171.  6172.]\n",
      "[ 83   4  53  23   9  35  54  79 116  67]\n",
      "[ 6173.  6174.  6175.  6176.  6177.  6178.  6179.   618.  6180.  6181.]\n",
      "[ 24  82  83 109  96  40  11 117  36  83]\n",
      "[ 6182.  6183.  6184.  6185.  6186.  6187.  6188.  6189.   619.  6190.]\n",
      "[ 11  96  58  36 122  20  83  40  96  14]\n",
      "[ 6191.  6192.  6193.  6194.  6195.  6196.  6197.  6198.  6199.    62.]\n",
      "[ 74 116  63  15  97 108   8  95  88 111]\n",
      "[  620.  6200.  6201.  6202.  6203.  6204.  6205.  6206.  6207.  6208.]\n",
      "[ 24  95  52  11  64  60  85  82  78 123]\n",
      "[ 6209.   621.  6210.  6211.  6212.  6213.  6214.  6215.  6216.  6217.]\n",
      "[ 11  23 117  58  66  20  11  28  60  88]\n",
      "[ 6218.  6219.   622.  6220.  6221.  6222.  6223.  6224.  6225.  6226.]\n",
      "[ 38  78  31  96  27 101  83  44  24   3]\n",
      "[ 6227.  6228.  6229.   623.  6230.  6231.  6232.  6233.  6234.  6235.]\n",
      "[ 45  48  85  41 106  80  53  88  22   7]\n",
      "[ 6236.  6237.  6238.  6239.   624.  6240.  6241.  6242.  6243.  6244.]\n",
      "[ 65  40  10 117  64  28 104  43  13  88]\n",
      "[ 6245.  6246.  6247.  6248.  6249.   625.  6250.  6251.  6252.  6253.]\n",
      "[ 95  20  41  54  27   1 120  53  13 107]\n",
      "[ 6254.  6255.  6256.  6257.  6258.  6259.   626.  6260.  6261.  6262.]\n",
      "[54 54 19 44 36 10 94 13 34 74]\n",
      "[ 6263.  6264.  6265.  6266.  6267.  6268.  6269.   627.  6270.  6271.]\n",
      "[ 83  54  74 123  36  50  30 107  80 116]\n",
      "[ 6272.  6273.  6274.  6275.  6276.  6277.  6278.  6279.   628.  6280.]\n",
      "[ 22  38  84  83  88  68 101  19  76  99]\n",
      "[ 6281.  6282.  6283.  6284.  6285.  6286.  6287.  6288.  6289.   629.]\n",
      "[ 41 121   9  46 116  10  83 114  65  28]\n",
      "[ 6290.  6291.  6292.  6293.  6294.  6295.  6296.  6297.  6298.  6299.]\n",
      "[ 13  79  73  10 122 122  67  74  41  26]\n",
      "[   63.   630.  6300.  6301.  6302.  6303.  6304.  6305.  6306.  6307.]\n",
      "[123  58   2  30  11  89 107  91  83  13]\n",
      "[ 6308.  6309.   631.  6310.  6311.  6312.  6313.  6314.  6315.  6316.]\n",
      "[ 87  30 122  78  98  85 126   3  45  81]\n",
      "[ 6317.  6318.  6319.   632.  6320.  6321.  6322.  6323.  6324.  6325.]\n",
      "[ 98  95  74  48  84  87  18  19  10 111]\n",
      "[ 6326.  6327.  6328.  6329.   633.  6330.  6331.  6332.  6333.  6334.]\n",
      "[112  19  79  95  44  98 107  24 122  80]\n",
      "[ 6335.  6336.  6337.  6338.  6339.   634.  6340.  6341.  6342.  6343.]\n",
      "[ 49  85  58 128  72  22  28  60  74  45]\n",
      "[ 6344.  6345.  6346.  6347.  6348.  6349.   635.  6350.  6351.  6352.]\n",
      "[109  40  96 116  53  37  72  67  60 111]\n",
      "[ 6353.  6354.  6355.  6356.  6357.  6358.  6359.   636.  6360.  6361.]\n",
      "[123  16  66  74 124   9  17  83  54 101]\n",
      "[ 6362.  6363.  6364.  6365.  6366.  6367.  6368.  6369.   637.  6370.]\n",
      "[123 101  83  86  84 110  27  18  44  22]\n",
      "[ 6371.  6372.  6373.  6374.  6375.  6376.  6377.  6378.  6379.   638.]\n",
      "[74  5 94  5 86 99  3 67  1 96]\n",
      "[ 6380.  6381.  6382.  6383.  6384.  6385.  6386.  6387.  6388.  6389.]\n",
      "[ 28  88  29  35  86  40  16 108  74  20]\n",
      "[  639.  6390.  6391.  6392.  6393.  6394.  6395.  6396.  6397.  6398.]\n",
      "[ 98  29  74  84 108  94 117  87  72  76]\n",
      "[ 6399.    64.   640.  6400.  6401.  6402.  6403.  6404.  6405.  6406.]\n",
      "[ 95  68  50 109  83  95  13   3  69  54]\n",
      "[ 6407.  6408.  6409.   641.  6410.  6411.  6412.  6413.  6414.  6415.]\n",
      "[ 53  53  95  73  87  78  85 120  62 111]\n",
      "[ 6416.  6417.  6418.  6419.   642.  6420.  6421.  6422.  6423.  6424.]\n",
      "[  8  66  35  24  63  65  79  68 101  67]\n",
      "[ 6425.  6426.  6427.  6428.  6429.   643.  6430.  6431.  6432.  6433.]\n",
      "[121  83   4   5  20  39  11  45  40  78]\n",
      "[ 6434.  6435.  6436.  6437.  6438.  6439.   644.  6440.  6441.  6442.]\n",
      "[ 91  13  27 107  35  52  58  88  61  62]\n",
      "[ 6443.  6444.  6445.  6446.  6447.  6448.  6449.   645.  6450.  6451.]\n",
      "[95 14 85 27 68 81  7 38 93 17]\n",
      "[ 6452.  6453.  6454.  6455.  6456.  6457.  6458.  6459.   646.  6460.]\n",
      "[ 62  52  94  31  52  26 107   8  74  96]\n",
      "[ 6461.  6462.  6463.  6464.  6465.  6466.  6467.  6468.  6469.   647.]\n",
      "[ 14 113 101  76   4   8 101 107  97  40]\n",
      "[ 6470.  6471.  6472.  6473.  6474.  6475.  6476.  6477.  6478.  6479.]\n",
      "[ 79  79  40 116  67  68  52 101  77  88]\n",
      "[  648.  6480.  6481.  6482.  6483.  6484.  6485.  6486.  6487.  6488.]\n",
      "[ 27  14  27  85 101 122  52  24  58 102]\n",
      "[ 6489.   649.  6490.  6491.  6492.  6493.  6494.  6495.  6496.  6497.]\n",
      "[ 96  96 104   8  49  18   4  62  19  49]\n",
      "[ 6498.  6499.    65.   650.  6500.  6501.  6502.  6503.  6504.  6505.]\n",
      "[ 68   4  83  96 117   9   3  31  68  11]\n",
      "[ 6506.  6507.  6508.  6509.   651.  6510.  6511.  6512.  6513.  6514.]\n",
      "[117 107  23  96  10  58 108  53 122  87]\n",
      "[ 6515.  6516.  6517.  6518.  6519.   652.  6520.  6521.  6522.  6523.]\n",
      "[ 45  10  72 122  78  16  54 122  28  13]\n",
      "[ 6524.  6525.  6526.  6527.  6528.  6529.   653.  6530.  6531.  6532.]\n",
      "[ 35  48  79  67  63  16  28  98 112  83]\n",
      "[ 6533.  6534.  6535.  6536.  6537.  6538.  6539.   654.  6540.  6541.]\n",
      "[ 45  36  78   7  31   3  67  83 111   7]\n",
      "[ 6542.  6543.  6544.  6545.  6546.  6547.  6548.  6549.   655.  6550.]\n",
      "[  6  13  28 104  18  94  52 104   8  89]\n",
      "[ 6551.  6552.  6553.  6554.  6555.  6556.  6557.  6558.  6559.   656.]\n",
      "[ 75  65  54  54 117  38 128  75  58  16]\n",
      "[ 6560.  6561.  6562.  6563.  6564.  6565.  6566.  6567.  6568.  6569.]\n",
      "[106  54  87  78  11  93  27   9  80  94]\n",
      "[  657.  6570.  6571.  6572.  6573.  6574.  6575.  6576.  6577.  6578.]\n",
      "[ 56  28  28  20 101  85 111 117 108 108]\n",
      "[ 6579.   658.  6580.  6581.  6582.  6583.  6584.  6585.  6586.  6587.]\n",
      "[ 82   6  19  54   8  94 122  45  35  54]\n",
      "[ 6588.  6589.   659.  6590.  6591.  6592.  6593.  6594.  6595.  6596.]\n",
      "[115  50  85  87  65  49  61  74  37  45]\n",
      "[ 6597.  6598.  6599.    66.   660.  6600.  6601.  6602.  6603.  6604.]\n",
      "[122 108  67  75  74  49  55  78  21 107]\n",
      "[ 6605.  6606.  6607.  6608.  6609.   661.  6610.  6611.  6612.  6613.]\n",
      "[65 20 67 96 61 51 68 14 53 63]\n",
      "[ 6614.  6615.  6616.  6617.  6618.  6619.   662.  6620.  6621.  6622.]\n",
      "[109  79  79  52  79 121  11  37 111  74]\n",
      "[ 6623.  6624.  6625.  6626.  6627.  6628.  6629.   663.  6630.  6631.]\n",
      "[85 36 93 99 94 68 19 40 45 17]\n",
      "[ 6632.  6633.  6634.  6635.  6636.  6637.  6638.  6639.   664.  6640.]\n",
      "[ 79  83 115  43 122  75  33  91 120  22]\n",
      "[ 6641.  6642.  6643.  6644.  6645.  6646.  6647.  6648.  6649.   665.]\n",
      "[ 95  19  78  83  41  58  26  94  85 121]\n",
      "[ 6650.  6651.  6652.  6653.  6654.  6655.  6656.  6657.  6658.  6659.]\n",
      "[ 10 123 122  67  44 111 117 110  13 110]\n",
      "[  666.  6660.  6661.  6662.  6663.  6664.  6665.  6666.  6667.  6668.]\n",
      "[ 13  87  54 110  53  95  68  54  79  37]\n",
      "[ 6669.   667.  6670.  6671.  6672.  6673.  6674.  6675.  6676.  6677.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85  83   4  68   5 121  38  80  28 106]\n",
      "[ 6678.  6679.   668.  6680.  6681.  6682.  6683.  6684.  6685.  6686.]\n",
      "[ 38 107  98  62  67  79 117  89  41  84]\n",
      "[ 6687.  6688.  6689.   669.  6690.  6691.  6692.  6693.  6694.  6695.]\n",
      "[ 83   9  77 117  11 107 116  54  23  19]\n",
      "[ 6696.  6697.  6698.  6699.    67.   670.  6700.  6701.  6702.  6703.]\n",
      "[ 4 62 31 40 67 11  1 75 23 79]\n",
      "[ 6704.  6705.  6706.  6707.  6708.  6709.   671.  6710.  6711.  6712.]\n",
      "[104 121  54  45 107 109  50  50   6   1]\n",
      "[ 6713.  6714.  6715.  6716.  6717.  6718.  6719.   672.  6720.  6721.]\n",
      "[ 79  67 107  45  63  85  10 116  46  28]\n",
      "[ 6722.  6723.  6724.  6725.  6726.  6727.  6728.  6729.   673.  6730.]\n",
      "[ 19  95  86 116  82  81 117  50 123 100]\n",
      "[ 6731.  6732.  6733.  6734.  6735.  6736.  6737.  6738.  6739.   674.]\n",
      "[ 45  31 123  97  19  54  30 108   6  45]\n",
      "[ 6740.  6741.  6742.  6743.  6744.  6745.  6746.  6747.  6748.  6749.]\n",
      "[ 18  11 111 101  19  33  84 124  20  77]\n",
      "[  675.  6750.  6751.  6752.  6753.  6754.  6755.  6756.  6757.  6758.]\n",
      "[ 96 106  95  67  45   7  40 123   6  84]\n",
      "[ 6759.   676.  6760.  6761.  6762.  6763.  6764.  6765.  6766.  6767.]\n",
      "[108  83 122  68  10  46  28  27  10  61]\n",
      "[ 6768.  6769.   677.  6770.  6771.  6772.  6773.  6774.  6775.  6776.]\n",
      "[ 61  83  63  40  85  54  74   7  13 108]\n",
      "[ 6777.  6778.  6779.   678.  6780.  6781.  6782.  6783.  6784.  6785.]\n",
      "[117  84  87  65  75  36  29  48  95  44]\n",
      "[ 6786.  6787.  6788.  6789.   679.  6790.  6791.  6792.  6793.  6794.]\n",
      "[103  68 114 117  94  54  93  94  98  35]\n",
      "[ 6795.  6796.  6797.  6798.  6799.    68.   680.  6800.  6801.  6802.]\n",
      "[ 80  35  50  28  87 111   5  43  84  93]\n",
      "[ 6803.  6804.  6805.  6806.  6807.  6808.  6809.   681.  6810.  6811.]\n",
      "[ 19   3  83  94  95  56 106   5 109  38]\n",
      "[ 6812.  6813.  6814.  6815.  6816.  6817.  6818.  6819.   682.  6820.]\n",
      "[ 87  85  73  45  87  24   8  38 126  24]\n",
      "[ 6821.  6822.  6823.  6824.  6825.  6826.  6827.  6828.  6829.   683.]\n",
      "[121  95 108  65   8 116   1 108 110  78]\n",
      "[ 6830.  6831.  6832.  6833.  6834.  6835.  6836.  6837.  6838.  6839.]\n",
      "[ 67   5  40   8   8  67  38 117  67  74]\n",
      "[  684.  6840.  6841.  6842.  6843.  6844.  6845.  6846.  6847.  6848.]\n",
      "[ 24 123  17  94  34  35 108 111  78  83]\n",
      "[ 6849.   685.  6850.  6851.  6852.  6853.  6854.  6855.  6856.  6857.]\n",
      "[ 5 87 38 75 83 83 74 54 95 37]\n",
      "[ 6858.  6859.   686.  6860.  6861.  6862.  6863.  6864.  6865.  6866.]\n",
      "[ 78  41  66  31  17  32  98 107   9  11]\n",
      "[ 6867.  6868.  6869.   687.  6870.  6871.  6872.  6873.  6874.  6875.]\n",
      "[107 121  85  96  85   5  84  68  77  34]\n",
      "[ 6876.  6877.  6878.  6879.   688.  6880.  6881.  6882.  6883.  6884.]\n",
      "[ 23 122  40  35  20 124 111  33 115  28]\n",
      "[ 6885.  6886.  6887.  6888.  6889.   689.  6890.  6891.  6892.  6893.]\n",
      "[107  13  45  62  16  74   8  93  14  43]\n",
      "[ 6894.  6895.  6896.  6897.  6898.  6899.    69.   690.  6900.  6901.]\n",
      "[ 31  66   7  73  38  54  19  72  93 111]\n",
      "[ 6902.  6903.  6904.  6905.  6906.  6907.  6908.  6909.   691.  6910.]\n",
      "[ 87 115  54  13  35 125  41  54 124  94]\n",
      "[ 6911.  6912.  6913.  6914.  6915.  6916.  6917.  6918.  6919.   692.]\n",
      "[ 44  93 123  43  13 109 106  34  68  83]\n",
      "[ 6920.  6921.  6922.  6923.  6924.  6925.  6926.  6927.  6928.  6929.]\n",
      "[ 17  14  76  11  77   4   9  54 127  10]\n",
      "[  693.  6930.  6931.  6932.  6933.  6934.  6935.  6936.  6937.  6938.]\n",
      "[ 78 124  13  11  45  82  45  74 102  95]\n",
      "[ 6939.   694.  6940.  6941.  6942.  6943.  6944.  6945.  6946.  6947.]\n",
      "[ 86 121   4   3  24 111 104  72   6  20]\n",
      "[ 6948.  6949.   695.  6950.  6951.  6952.  6953.  6954.  6955.  6956.]\n",
      "[ 86  22  21 101 110  83  96  20 111 123]\n",
      "[ 6957.  6958.  6959.   696.  6960.  6961.  6962.  6963.  6964.  6965.]\n",
      "[  5 122  87  58  72  77  11  74  93 120]\n",
      "[ 6966.  6967.  6968.  6969.   697.  6970.  6971.  6972.  6973.  6974.]\n",
      "[ 48  41   8 117 110  82  41  84 111 122]\n",
      "[ 6975.  6976.  6977.  6978.  6979.   698.  6980.  6981.  6982.  6983.]\n",
      "[ 19  82  95 127 106  55  46 126  78 114]\n",
      "[ 6984.  6985.  6986.  6987.  6988.  6989.   699.  6990.  6991.  6992.]\n",
      "[19 83 67 17 11 45 31 58 46  9]\n",
      "[ 6993.  6994.  6995.  6996.  6997.  6998.  6999.     7.    70.   700.]\n",
      "[ 54  29  85  92  40  98  95 108  75  19]\n",
      "[ 7000.  7001.  7002.  7003.  7004.  7005.  7006.  7007.  7008.  7009.]\n",
      "[65 19 22 11 35 96 88 58 73 80]\n",
      "[  701.  7010.  7011.  7012.  7013.  7014.  7015.  7016.  7017.  7018.]\n",
      "[ 64 111  56  84  81  53  97 117  17  94]\n",
      "[ 7019.   702.  7020.  7021.  7022.  7023.  7024.  7025.  7026.  7027.]\n",
      "[ 88 101  10  68  38   3  53 106  33  49]\n",
      "[ 7028.  7029.   703.  7030.  7031.  7032.  7033.  7034.  7035.  7036.]\n",
      "[ 83  11  78   8  96 114  94  83  38 123]\n",
      "[ 7037.  7038.  7039.   704.  7040.  7041.  7042.  7043.  7044.  7045.]\n",
      "[ 79  96 101  41  99 116  87  88  10 107]\n",
      "[ 7046.  7047.  7048.  7049.   705.  7050.  7051.  7052.  7053.  7054.]\n",
      "[109  98  44  95  85  19  74  17  10  75]\n",
      "[ 7055.  7056.  7057.  7058.  7059.   706.  7060.  7061.  7062.  7063.]\n",
      "[ 31  75  62  19  22  97  22 104  45  80]\n",
      "[ 7064.  7065.  7066.  7067.  7068.  7069.   707.  7070.  7071.  7072.]\n",
      "[ 95   4  27 110   1  52  95 103 114  76]\n",
      "[ 7073.  7074.  7075.  7076.  7077.  7078.  7079.   708.  7080.  7081.]\n",
      "[ 54 117  36  30  19  83  95  43  97  11]\n",
      "[ 7082.  7083.  7084.  7085.  7086.  7087.  7088.  7089.   709.  7090.]\n",
      "[64 57 28 87 39 67 74  8 97 68]\n",
      "[ 7091.  7092.  7093.  7094.  7095.  7096.  7097.  7098.  7099.    71.]\n",
      "[ 56  78  46  19 112  58  54  13  50 110]\n",
      "[  710.  7100.  7101.  7102.  7103.  7104.  7105.  7106.  7107.  7108.]\n",
      "[111  81 106  99  74 108 113   9  83  17]\n",
      "[ 7109.   711.  7110.  7111.  7112.  7113.  7114.  7115.  7116.  7117.]\n",
      "[ 40  68  81  34  40  41 114 108  19   9]\n",
      "[ 7118.  7119.   712.  7120.  7121.  7122.  7123.  7124.  7125.  7126.]\n",
      "[ 83  11 116   4  53  74 121  94  89 114]\n",
      "[ 7127.  7128.  7129.   713.  7130.  7131.  7132.  7133.  7134.  7135.]\n",
      "[ 56  78 122 123  16 122  86 120  49  40]\n",
      "[ 7136.  7137.  7138.  7139.   714.  7140.  7141.  7142.  7143.  7144.]\n",
      "[123   3   1 122  23 128  54  57  24   1]\n",
      "[ 7145.  7146.  7147.  7148.  7149.   715.  7150.  7151.  7152.  7153.]\n",
      "[ 63 116 107  20  50  21  20   8 106   7]\n",
      "[ 7154.  7155.  7156.  7157.  7158.  7159.   716.  7160.  7161.  7162.]\n",
      "[ 53  78   5 114  27 106  62  63 123  20]\n",
      "[ 7163.  7164.  7165.  7166.  7167.  7168.  7169.   717.  7170.  7171.]\n",
      "[111 108  96  65  54  84  22  76   9  74]\n",
      "[ 7172.  7173.  7174.  7175.  7176.  7177.  7178.  7179.   718.  7180.]\n",
      "[ 67  31 101  54   6 121  95  16  20  95]\n",
      "[ 7181.  7182.  7183.  7184.  7185.  7186.  7187.  7188.  7189.   719.]\n",
      "[122 122  94  93   6  19  68 114  93 106]\n",
      "[ 7190.  7191.  7192.  7193.  7194.  7195.  7196.  7197.  7198.  7199.]\n",
      "[ 65  28  68  93  28  74  40  13  66 108]\n",
      "[   72.   720.  7200.  7201.  7202.  7203.  7204.  7205.  7206.  7207.]\n",
      "[11 28 63 29 94 83  5 10 67 35]\n",
      "[ 7208.  7209.   721.  7210.  7211.  7212.  7213.  7214.  7215.  7216.]\n",
      "[ 86 123  41  51  52 106 108  66  30  45]\n",
      "[ 7217.  7218.  7219.   722.  7220.  7221.  7222.  7223.  7224.  7225.]\n",
      "[ 67  77  58  53  52 117  45  78  96  95]\n",
      "[ 7226.  7227.  7228.  7229.   723.  7230.  7231.  7232.  7233.  7234.]\n",
      "[126  74  68   8  18  63  19   9  87  88]\n",
      "[ 7235.  7236.  7237.  7238.  7239.   724.  7240.  7241.  7242.  7243.]\n",
      "[101  48  79  31  22  28  49 117 124  45]\n",
      "[ 7244.  7245.  7246.  7247.  7248.  7249.   725.  7250.  7251.  7252.]\n",
      "[  1  36  88   9  67  54  53  49  78 122]\n",
      "[ 7253.  7254.  7255.  7256.  7257.  7258.  7259.   726.  7260.  7261.]\n",
      "[  8  85  87  45   5  83  89 110  83  11]\n",
      "[ 7262.  7263.  7264.  7265.  7266.  7267.  7268.  7269.   727.  7270.]\n",
      "[  5  45  19  95  77  87  35 116  83  95]\n",
      "[ 7271.  7272.  7273.  7274.  7275.  7276.  7277.  7278.  7279.   728.]\n",
      "[ 35  16  58  33 117  33  52  20  80  58]\n",
      "[ 7280.  7281.  7282.  7283.  7284.  7285.  7286.  7287.  7288.  7289.]\n",
      "[ 54  45 117  54  39  94  84  11  45  10]\n",
      "[  729.  7290.  7291.  7292.  7293.  7294.  7295.  7296.  7297.  7298.]\n",
      "[ 21  19 108  52  35  78   1  54  58  62]\n",
      "[ 7299.    73.   730.  7300.  7301.  7302.  7303.  7304.  7305.  7306.]\n",
      "[  3  98  54 128  45   3  56  14 115  54]\n",
      "[ 7307.  7308.  7309.   731.  7310.  7311.  7312.  7313.  7314.  7315.]\n",
      "[ 35  75 126 110  74 117 106  76  56 116]\n",
      "[ 7316.  7317.  7318.  7319.   732.  7320.  7321.  7322.  7323.  7324.]\n",
      "[ 94  82   4  28  18  17  94 102  52   5]\n",
      "[ 7325.  7326.  7327.  7328.  7329.   733.  7330.  7331.  7332.  7333.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50  53 113  28  85  40 104 117 122  46]\n",
      "[ 7334.  7335.  7336.  7337.  7338.  7339.   734.  7340.  7341.  7342.]\n",
      "[ 54  38  43  72  80 114  83   9  35  67]\n",
      "[ 7343.  7344.  7345.  7346.  7347.  7348.  7349.   735.  7350.  7351.]\n",
      "[  4  49  52  96  54 106  37 127  94  63]\n",
      "[ 7352.  7353.  7354.  7355.  7356.  7357.  7358.  7359.   736.  7360.]\n",
      "[ 11  74  68  45  58  79  14 106  89 107]\n",
      "[ 7361.  7362.  7363.  7364.  7365.  7366.  7367.  7368.  7369.   737.]\n",
      "[101 108  95 111  72  27  19  68  27   1]\n",
      "[ 7370.  7371.  7372.  7373.  7374.  7375.  7376.  7377.  7378.  7379.]\n",
      "[ 13  83   8  65  17 111  35 108  67 114]\n",
      "[  738.  7380.  7381.  7382.  7383.  7384.  7385.  7386.  7387.  7388.]\n",
      "[107 107  80  77   9  36  20  85 113   8]\n",
      "[ 7389.   739.  7390.  7391.  7392.  7393.  7394.  7395.  7396.  7397.]\n",
      "[ 45 122 107  96  80   6  77 122  49  99]\n",
      "[ 7398.  7399.    74.   740.  7400.  7401.  7402.  7403.  7404.  7405.]\n",
      "[102 128 106  74   8  65   7  88  24  46]\n",
      "[ 7406.  7407.  7408.  7409.   741.  7410.  7411.  7412.  7413.  7414.]\n",
      "[108  62 121  28 117 116  20  79   6  11]\n",
      "[ 7415.  7416.  7417.  7418.  7419.   742.  7420.  7421.  7422.  7423.]\n",
      "[101  98  99  79  44  62  95 124  88 101]\n",
      "[ 7424.  7425.  7426.  7427.  7428.  7429.   743.  7430.  7431.  7432.]\n",
      "[ 17  72 123  28  87   8  63  28  50  93]\n",
      "[ 7433.  7434.  7435.  7436.  7437.  7438.  7439.   744.  7440.  7441.]\n",
      "[ 35  85 102  85  43 106  27  57  19  18]\n",
      "[ 7442.  7443.  7444.  7445.  7446.  7447.  7448.  7449.   745.  7450.]\n",
      "[122 106  43 122 122  10 107  97  41  86]\n",
      "[ 7451.  7452.  7453.  7454.  7455.  7456.  7457.  7458.  7459.   746.]\n",
      "[101  68 127  44 109  44  79  14 121  86]\n",
      "[ 7460.  7461.  7462.  7463.  7464.  7465.  7466.  7467.  7468.  7469.]\n",
      "[ 75  97  28 111  56  95  45 108  74  95]\n",
      "[  747.  7470.  7471.  7472.  7473.  7474.  7475.  7476.  7477.  7478.]\n",
      "[109  88  83  68  79  83  54  35  20 110]\n",
      "[ 7479.   748.  7480.  7481.  7482.  7483.  7484.  7485.  7486.  7487.]\n",
      "[ 65 126 110  26 127  82  46  19  13 101]\n",
      "[ 7488.  7489.   749.  7490.  7491.  7492.  7493.  7494.  7495.  7496.]\n",
      "[ 84  96  80  28  49  38  54  56 121  86]\n",
      "[ 7497.  7498.  7499.    75.   750.  7500.  7501.  7502.  7503.  7504.]\n",
      "[ 77  96 123  37 123  62  85  54  68  54]\n",
      "[ 7505.  7506.  7507.  7508.  7509.   751.  7510.  7511.  7512.  7513.]\n",
      "[109  83  96 123  85  54  78   9 107   4]\n",
      "[ 7514.  7515.  7516.  7517.  7518.  7519.   752.  7520.  7521.  7522.]\n",
      "[ 31  78  80 114  38   7  11  54  54 105]\n",
      "[ 7523.  7524.  7525.  7526.  7527.  7528.  7529.   753.  7530.  7531.]\n",
      "[ 38  52  20 117  67 117 121  94  84  24]\n",
      "[ 7532.  7533.  7534.  7535.  7536.  7537.  7538.  7539.   754.  7540.]\n",
      "[ 54  84   4 109  60  17  46  61 102  90]\n",
      "[ 7541.  7542.  7543.  7544.  7545.  7546.  7547.  7548.  7549.   755.]\n",
      "[ 93  16  74  83  19  22  96 110  94 110]\n",
      "[ 7550.  7551.  7552.  7553.  7554.  7555.  7556.  7557.  7558.  7559.]\n",
      "[ 77  44  97 125   8  48  37 127  13  19]\n",
      "[  756.  7560.  7561.  7562.  7563.  7564.  7565.  7566.  7567.  7568.]\n",
      "[80 83 35 41 54 72 62 35  5 86]\n",
      "[ 7569.   757.  7570.  7571.  7572.  7573.  7574.  7575.  7576.  7577.]\n",
      "[ 10   4   8  67  32  79  53   5 114   1]\n",
      "[ 7578.  7579.   758.  7580.  7581.  7582.  7583.  7584.  7585.  7586.]\n",
      "[ 95  19 115  10  93 107  31  41  39  95]\n",
      "[ 7587.  7588.  7589.   759.  7590.  7591.  7592.  7593.  7594.  7595.]\n",
      "[128 118  72  18  83  39  78  26  20  48]\n",
      "[ 7596.  7597.  7598.  7599.    76.   760.  7600.  7601.  7602.  7603.]\n",
      "[ 35   4 123  19 106  99 110  74   3 122]\n",
      "[ 7604.  7605.  7606.  7607.  7608.  7609.   761.  7610.  7611.  7612.]\n",
      "[ 49  88 111  72  75 123  45  84  77  34]\n",
      "[ 7613.  7614.  7615.  7616.  7617.  7618.  7619.   762.  7620.  7621.]\n",
      "[ 38  68  18  68  83  31  83  76 124   4]\n",
      "[ 7622.  7623.  7624.  7625.  7626.  7627.  7628.  7629.   763.  7630.]\n",
      "[ 48   5  16  97   3 108  78  23  20 117]\n",
      "[ 7631.  7632.  7633.  7634.  7635.  7636.  7637.  7638.  7639.   764.]\n",
      "[110  95  78 108  10 115  18  19 122  95]\n",
      "[ 7640.  7641.  7642.  7643.  7644.  7645.  7646.  7647.  7648.  7649.]\n",
      "[ 27  52  95  40  13  80 121  75  39   8]\n",
      "[  765.  7650.  7651.  7652.  7653.  7654.  7655.  7656.  7657.  7658.]\n",
      "[ 39   3  94 120  95  28  10  83  45  97]\n",
      "[ 7659.   766.  7660.  7661.  7662.  7663.  7664.  7665.  7666.  7667.]\n",
      "[ 68  67 123 126 117  35 123   5  23 104]\n",
      "[ 7668.  7669.   767.  7670.  7671.  7672.  7673.  7674.  7675.  7676.]\n",
      "[ 45  33 127  77  95  94 128  75  52  48]\n",
      "[ 7677.  7678.  7679.   768.  7680.  7681.  7682.  7683.  7684.  7685.]\n",
      "[106  72  19  28  13  78  54   4  22  17]\n",
      "[ 7686.  7687.  7688.  7689.   769.  7690.  7691.  7692.  7693.  7694.]\n",
      "[118  22  78  11 116  83  19  86 122 108]\n",
      "[ 7695.  7696.  7697.  7698.  7699.    77.   770.  7700.  7701.  7702.]\n",
      "[ 58  87 117  20  65  53  43  54 111  35]\n",
      "[ 7703.  7704.  7705.  7706.  7707.  7708.  7709.   771.  7710.  7711.]\n",
      "[ 95  35 123  19  45  45  28  58  83  98]\n",
      "[ 7712.  7713.  7714.  7715.  7716.  7717.  7718.  7719.   772.  7720.]\n",
      "[106 116   9  36 124   5  78  23  49  91]\n",
      "[ 7721.  7722.  7723.  7724.  7725.  7726.  7727.  7728.  7729.   773.]\n",
      "[ 74  79 117 106  53  87  68 117 104  61]\n",
      "[ 7730.  7731.  7732.  7733.  7734.  7735.  7736.  7737.  7738.  7739.]\n",
      "[ 27  43  33  35  80 108  18  68  45 121]\n",
      "[  774.  7740.  7741.  7742.  7743.  7744.  7745.  7746.  7747.  7748.]\n",
      "[  8  95 123  83  68 111  19  41  93  35]\n",
      "[ 7749.   775.  7750.  7751.  7752.  7753.  7754.  7755.  7756.  7757.]\n",
      "[ 28 102  98  37  43  98  94  46  67 108]\n",
      "[ 7758.  7759.   776.  7760.  7761.  7762.  7763.  7764.  7765.  7766.]\n",
      "[ 58  67  49  98  46  86  46 102  41 101]\n",
      "[ 7767.  7768.  7769.   777.  7770.  7771.  7772.  7773.  7774.  7775.]\n",
      "[ 49   4 121  35  58  99  29 117  86  44]\n",
      "[ 7776.  7777.  7778.  7779.   778.  7780.  7781.  7782.  7783.  7784.]\n",
      "[116  19  40 110 127  52  68  95  53   8]\n",
      "[ 7785.  7786.  7787.  7788.  7789.   779.  7790.  7791.  7792.  7793.]\n",
      "[ 60   4  95  37  20  78 126  62  95  19]\n",
      "[ 7794.  7795.  7796.  7797.  7798.  7799.    78.   780.  7800.  7801.]\n",
      "[ 96 108  95  87  85  67 122  85  33 120]\n",
      "[ 7802.  7803.  7804.  7805.  7806.  7807.  7808.  7809.   781.  7810.]\n",
      "[ 37   3  74 127 122 108  78   9  96 114]\n",
      "[ 7811.  7812.  7813.  7814.  7815.  7816.  7817.  7818.  7819.   782.]\n",
      "[ 89  28  79 114  38  83   5  95  83  96]\n",
      "[ 7820.  7821.  7822.  7823.  7824.  7825.  7826.  7827.  7828.  7829.]\n",
      "[ 36   5  40  84  74   6 102   9  19 117]\n",
      "[  783.  7830.  7831.  7832.  7833.  7834.  7835.  7836.  7837.  7838.]\n",
      "[  9 111  49  56 106  54  94 108 101  28]\n",
      "[ 7839.   784.  7840.  7841.  7842.  7843.  7844.  7845.  7846.  7847.]\n",
      "[ 83  63 101  82 124  68  83 127  28  29]\n",
      "[ 7848.  7849.   785.  7850.  7851.  7852.  7853.  7854.  7855.  7856.]\n",
      "[110 122  77  87  21 115   6  84 107  74]\n",
      "[ 7857.  7858.  7859.   786.  7860.  7861.  7862.  7863.  7864.  7865.]\n",
      "[ 56   4 110   1  14 104  19  43  98  43]\n",
      "[ 7866.  7867.  7868.  7869.   787.  7870.  7871.  7872.  7873.  7874.]\n",
      "[ 54  96  68 127  93  31  52   3  69  19]\n",
      "[ 7875.  7876.  7877.  7878.  7879.   788.  7880.  7881.  7882.  7883.]\n",
      "[ 79  83   3  81  98 117 121  38  28   7]\n",
      "[ 7884.  7885.  7886.  7887.  7888.  7889.   789.  7890.  7891.  7892.]\n",
      "[ 65  98  22  58 115  76   7 123  82   7]\n",
      "[ 7893.  7894.  7895.  7896.  7897.  7898.  7899.    79.   790.  7900.]\n",
      "[11 96 28 95 96 17  5 20 55 96]\n",
      "[ 7901.  7902.  7903.  7904.  7905.  7906.  7907.  7908.  7909.   791.]\n",
      "[ 72  79  78  28 104 123  35  54 116  68]\n",
      "[ 7910.  7911.  7912.  7913.  7914.  7915.  7916.  7917.  7918.  7919.]\n",
      "[  1   7 122  75   4  17  53  43  68  65]\n",
      "[  792.  7920.  7921.  7922.  7923.  7924.  7925.  7926.  7927.  7928.]\n",
      "[ 19  46 121 117  78  99  55  57 116  52]\n",
      "[ 7929.   793.  7930.  7931.  7932.  7933.  7934.  7935.  7936.  7937.]\n",
      "[  6  48  40 111  28  84  83   8  11  52]\n",
      "[ 7938.  7939.   794.  7940.  7941.  7942.  7943.  7944.  7945.  7946.]\n",
      "[ 83  74  19  66  90 124   8  13  36   3]\n",
      "[ 7947.  7948.  7949.   795.  7950.  7951.  7952.  7953.  7954.  7955.]\n",
      "[ 97 106  96  53  95  68 120 117 124  83]\n",
      "[ 7956.  7957.  7958.  7959.   796.  7960.  7961.  7962.  7963.  7964.]\n",
      "[ 20 108   8  38  38  41  13  30  78 127]\n",
      "[ 7965.  7966.  7967.  7968.  7969.   797.  7970.  7971.  7972.  7973.]\n",
      "[ 67   1  13  86  95  74  56 123 120  84]\n",
      "[ 7974.  7975.  7976.  7977.  7978.  7979.   798.  7980.  7981.  7982.]\n",
      "[ 94  20  67  10 106  43  13  94  65 109]\n",
      "[ 7983.  7984.  7985.  7986.  7987.  7988.  7989.   799.  7990.  7991.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106   8  62  74  74  83 120  68  89  83]\n",
      "[ 7992.  7993.  7994.  7995.  7996.  7997.  7998.  7999.     8.    80.]\n",
      "[74 65 40 19  8 40 83 19 28 20]\n",
      "[  800.  8000.  8001.  8002.  8003.  8004.  8005.  8006.  8007.  8008.]\n",
      "[ 74  86  20  97  53  35  19 117 110 116]\n",
      "[ 8009.   801.  8010.  8011.  8012.  8013.  8014.  8015.  8016.  8017.]\n",
      "[ 79   4  98   9  78  42  40 104  98  10]\n",
      "[ 8018.  8019.   802.  8020.  8021.  8022.  8023.  8024.  8025.  8026.]\n",
      "[106  76 106  54  20  46  63  48 117  79]\n",
      "[ 8027.  8028.  8029.   803.  8030.  8031.  8032.  8033.  8034.  8035.]\n",
      "[ 14  20  83  64 107  16 115  58  69  10]\n",
      "[ 8036.  8037.  8038.  8039.   804.  8040.  8041.  8042.  8043.  8044.]\n",
      "[124  54   4  89   5  11  85  93  38  85]\n",
      "[ 8045.  8046.  8047.  8048.  8049.   805.  8050.  8051.  8052.  8053.]\n",
      "[ 58  35  87  31  27  85  68 123  50 127]\n",
      "[ 8054.  8055.  8056.  8057.  8058.  8059.   806.  8060.  8061.  8062.]\n",
      "[ 61  10  63  94  24  98  99 106 108 114]\n",
      "[ 8063.  8064.  8065.  8066.  8067.  8068.  8069.   807.  8070.  8071.]\n",
      "[98 16 52 11 77 80 52 67 36 83]\n",
      "[ 8072.  8073.  8074.  8075.  8076.  8077.  8078.  8079.   808.  8080.]\n",
      "[112  19  41  62  14  36  16  49  95  94]\n",
      "[ 8081.  8082.  8083.  8084.  8085.  8086.  8087.  8088.  8089.   809.]\n",
      "[ 83  94  67  83 118 114  79  63  19  53]\n",
      "[ 8090.  8091.  8092.  8093.  8094.  8095.  8096.  8097.  8098.  8099.]\n",
      "[ 90  50  18   3  58  65 115  52  26  95]\n",
      "[   81.   810.  8100.  8101.  8102.  8103.  8104.  8105.  8106.  8107.]\n",
      "[ 65  22 122 108 111  62  68  70  94 113]\n",
      "[ 8108.  8109.   811.  8110.  8111.  8112.  8113.  8114.  8115.  8116.]\n",
      "[ 52  17  87  43  22  67 116  78  40  67]\n",
      "[ 8117.  8118.  8119.   812.  8120.  8121.  8122.  8123.  8124.  8125.]\n",
      "[ 61  88  17   9  84 106  27  28  77 106]\n",
      "[ 8126.  8127.  8128.  8129.   813.  8130.  8131.  8132.  8133.  8134.]\n",
      "[ 67  63   5  54 109  27 117 121  90   3]\n",
      "[ 8135.  8136.  8137.  8138.  8139.   814.  8140.  8141.  8142.  8143.]\n",
      "[ 83  68  76  80  79  49  35 111  80  43]\n",
      "[ 8144.  8145.  8146.  8147.  8148.  8149.   815.  8150.  8151.  8152.]\n",
      "[107   2  19  68 106  13  45  20  67  28]\n",
      "[ 8153.  8154.  8155.  8156.  8157.  8158.  8159.   816.  8160.  8161.]\n",
      "[ 68 124  67  77  78   8  48 122  63  27]\n",
      "[ 8162.  8163.  8164.  8165.  8166.  8167.  8168.  8169.   817.  8170.]\n",
      "[ 28  80 108   3  78  87  87   5  36 122]\n",
      "[ 8171.  8172.  8173.  8174.  8175.  8176.  8177.  8178.  8179.   818.]\n",
      "[ 62 117 115   4  80  18 108  89  10  46]\n",
      "[ 8180.  8181.  8182.  8183.  8184.  8185.  8186.  8187.  8188.  8189.]\n",
      "[ 50  84  84  49  78 123  67 108   7  99]\n",
      "[  819.  8190.  8191.  8192.  8193.  8194.  8195.  8196.  8197.  8198.]\n",
      "[ 54  44  58  45  48 107  67  63   8  40]\n",
      "[ 8199.    82.   820.  8200.  8201.  8202.  8203.  8204.  8205.  8206.]\n",
      "[ 10  10  27  19  40 111  37  83 117 124]\n",
      "[ 8207.  8208.  8209.   821.  8210.  8211.  8212.  8213.  8214.  8215.]\n",
      "[54 52 46 53 53 35 45 26 78 38]\n",
      "[ 8216.  8217.  8218.  8219.   822.  8220.  8221.  8222.  8223.  8224.]\n",
      "[121  74  18  23  49  95 106  52  95  83]\n",
      "[ 8225.  8226.  8227.  8228.  8229.   823.  8230.  8231.  8232.  8233.]\n",
      "[106 101  78  82  28  40  82 108 117  68]\n",
      "[ 8234.  8235.  8236.  8237.  8238.  8239.   824.  8240.  8241.  8242.]\n",
      "[  6  28  52  97  16   9 117   4  77 117]\n",
      "[ 8243.  8244.  8245.  8246.  8247.  8248.  8249.   825.  8250.  8251.]\n",
      "[107  83  83 123 115  90  48 121  31  94]\n",
      "[ 8252.  8253.  8254.  8255.  8256.  8257.  8258.  8259.   826.  8260.]\n",
      "[ 69  97 108 108  52 128 127 128  45  31]\n",
      "[ 8261.  8262.  8263.  8264.  8265.  8266.  8267.  8268.  8269.   827.]\n",
      "[ 78 124  86 126 110   9  61  20  74 107]\n",
      "[ 8270.  8271.  8272.  8273.  8274.  8275.  8276.  8277.  8278.  8279.]\n",
      "[  4 104  40  46  28 122  53  22  52  65]\n",
      "[  828.  8280.  8281.  8282.  8283.  8284.  8285.  8286.  8287.  8288.]\n",
      "[  8  75  31  13 122  54  79  76  84  96]\n",
      "[ 8289.   829.  8290.  8291.  8292.  8293.  8294.  8295.  8296.  8297.]\n",
      "[64 66 58 95 81  8 91 65 75 20]\n",
      "[ 8298.  8299.    83.   830.  8300.  8301.  8302.  8303.  8304.  8305.]\n",
      "[ 95  44  11   5  40 117  37  78  68  93]\n",
      "[ 8306.  8307.  8308.  8309.   831.  8310.  8311.  8312.  8313.  8314.]\n",
      "[ 33  27  63  62  89  94  78  63 108 117]\n",
      "[ 8315.  8316.  8317.  8318.  8319.   832.  8320.  8321.  8322.  8323.]\n",
      "[ 36  83   1  19  16  95 108  53 120  27]\n",
      "[ 8324.  8325.  8326.  8327.  8328.  8329.   833.  8330.  8331.  8332.]\n",
      "[122   5  62  20  68  90 116 126  94  88]\n",
      "[ 8333.  8334.  8335.  8336.  8337.  8338.  8339.   834.  8340.  8341.]\n",
      "[122  10  31   3  77  95  65  54  80  83]\n",
      "[ 8342.  8343.  8344.  8345.  8346.  8347.  8348.  8349.   835.  8350.]\n",
      "[ 35   5  52  65  16   8 123 107  75 123]\n",
      "[ 8351.  8352.  8353.  8354.  8355.  8356.  8357.  8358.  8359.   836.]\n",
      "[117  67  65  11  54  16  44  84 127   5]\n",
      "[ 8360.  8361.  8362.  8363.  8364.  8365.  8366.  8367.  8368.  8369.]\n",
      "[121  20  73  75  13  95  53 115  39  83]\n",
      "[  837.  8370.  8371.  8372.  8373.  8374.  8375.  8376.  8377.  8378.]\n",
      "[  8 117  35  83 106 109  68  40 116  85]\n",
      "[ 8379.   838.  8380.  8381.  8382.  8383.  8384.  8385.  8386.  8387.]\n",
      "[ 45  54 117 106  24  95  11  52  54   6]\n",
      "[ 8388.  8389.   839.  8390.  8391.  8392.  8393.  8394.  8395.  8396.]\n",
      "[ 54  83  56 123  74  43 122  96   7  74]\n",
      "[ 8397.  8398.  8399.    84.   840.  8400.  8401.  8402.  8403.  8404.]\n",
      "[122  63 114   3   9  46 110  68 117 116]\n",
      "[ 8405.  8406.  8407.  8408.  8409.   841.  8410.  8411.  8412.  8413.]\n",
      "[ 78  28  28  10 110  68 119   7  13  20]\n",
      "[ 8414.  8415.  8416.  8417.  8418.  8419.   842.  8420.  8421.  8422.]\n",
      "[ 84 101  60  38   6 111  75  43  95  13]\n",
      "[ 8423.  8424.  8425.  8426.  8427.  8428.  8429.   843.  8430.  8431.]\n",
      "[ 77 110  48  67  83  44 121   1  95  85]\n",
      "[ 8432.  8433.  8434.  8435.  8436.  8437.  8438.  8439.   844.  8440.]\n",
      "[ 81 107  64 123 110 117 117 123  64 104]\n",
      "[ 8441.  8442.  8443.  8444.  8445.  8446.  8447.  8448.  8449.   845.]\n",
      "[ 84 126  82  83  45  95  43  18  74   7]\n",
      "[ 8450.  8451.  8452.  8453.  8454.  8455.  8456.  8457.  8458.  8459.]\n",
      "[ 76  96  14  88   5 117  38  80  54  82]\n",
      "[  846.  8460.  8461.  8462.  8463.  8464.  8465.  8466.  8467.  8468.]\n",
      "[ 62  31 116   4  35  98 102  95  35 107]\n",
      "[ 8469.   847.  8470.  8471.  8472.  8473.  8474.  8475.  8476.  8477.]\n",
      "[ 33  56  88  77   4  76 123  20  53  72]\n",
      "[ 8478.  8479.   848.  8480.  8481.  8482.  8483.  8484.  8485.  8486.]\n",
      "[ 78  60  70 121  53  82 123  54  21  68]\n",
      "[ 8487.  8488.  8489.   849.  8490.  8491.  8492.  8493.  8494.  8495.]\n",
      "[ 16 104  28 107  86  27  49 112  93  49]\n",
      "[ 8496.  8497.  8498.  8499.    85.   850.  8500.  8501.  8502.  8503.]\n",
      "[110  93  20  28  62  68  39  35  54  19]\n",
      "[ 8504.  8505.  8506.  8507.  8508.  8509.   851.  8510.  8511.  8512.]\n",
      "[121 123  28 122  28  13  74   1  49  83]\n",
      "[ 8513.  8514.  8515.  8516.  8517.  8518.  8519.   852.  8520.  8521.]\n",
      "[  8 111  79  98  80  52 126 122  83 102]\n",
      "[ 8522.  8523.  8524.  8525.  8526.  8527.  8528.  8529.   853.  8530.]\n",
      "[ 96 120  30  73 114 108   6  44  28   3]\n",
      "[ 8531.  8532.  8533.  8534.  8535.  8536.  8537.  8538.  8539.   854.]\n",
      "[ 74  35 121  37  68 110 121  44  89  48]\n",
      "[ 8540.  8541.  8542.  8543.  8544.  8545.  8546.  8547.  8548.  8549.]\n",
      "[ 33  35  27 116  28  91  51  45  41   2]\n",
      "[  855.  8550.  8551.  8552.  8553.  8554.  8555.  8556.  8557.  8558.]\n",
      "[108  36  96  98  54 102  28  19  54 124]\n",
      "[ 8559.   856.  8560.  8561.  8562.  8563.  8564.  8565.  8566.  8567.]\n",
      "[ 45 111  85  17  44  89  65  13 121 104]\n",
      "[ 8568.  8569.   857.  8570.  8571.  8572.  8573.  8574.  8575.  8576.]\n",
      "[ 20 101  86 117 117  73  20  80  85  97]\n",
      "[ 8577.  8578.  8579.   858.  8580.  8581.  8582.  8583.  8584.  8585.]\n",
      "[ 94  76   3  86  17 122  83   5 122 123]\n",
      "[ 8586.  8587.  8588.  8589.   859.  8590.  8591.  8592.  8593.  8594.]\n",
      "[ 17  27  53  51  88 124   5 122  78  38]\n",
      "[ 8595.  8596.  8597.  8598.  8599.    86.   860.  8600.  8601.  8602.]\n",
      "[53 93 85 65 10 45 53 89 54 34]\n",
      "[ 8603.  8604.  8605.  8606.  8607.  8608.  8609.   861.  8610.  8611.]\n",
      "[126  18 121  83  41 122  27  83  75   8]\n",
      "[ 8612.  8613.  8614.  8615.  8616.  8617.  8618.  8619.   862.  8620.]\n",
      "[ 77  48  23  45  45 111  98  17  11  72]\n",
      "[ 8621.  8622.  8623.  8624.  8625.  8626.  8627.  8628.  8629.   863.]\n",
      "[38 40 17 80 56 82  8 38 85 75]\n",
      "[ 8630.  8631.  8632.  8633.  8634.  8635.  8636.  8637.  8638.  8639.]\n",
      "[110  44  39  19  22 120  94  35  56 117]\n",
      "[  864.  8640.  8641.  8642.  8643.  8644.  8645.  8646.  8647.  8648.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 80  96 114 109  93  10  88  45  53  94]\n",
      "[ 8649.   865.  8650.  8651.  8652.  8653.  8654.  8655.  8656.  8657.]\n",
      "[ 45  79 122 123  39  49  76  28  83  38]\n",
      "[ 8658.  8659.   866.  8660.  8661.  8662.  8663.  8664.  8665.  8666.]\n",
      "[107  49 122  28  38  97  63  11 108  98]\n",
      "[ 8667.  8668.  8669.   867.  8670.  8671.  8672.  8673.  8674.  8675.]\n",
      "[ 16  64  86 124  83 106 117  19   4  81]\n",
      "[ 8676.  8677.  8678.  8679.   868.  8680.  8681.  8682.  8683.  8684.]\n",
      "[124 122 107  83 111   3  87  92  35 115]\n",
      "[ 8685.  8686.  8687.  8688.  8689.   869.  8690.  8691.  8692.  8693.]\n",
      "[122  75  78  34  50  86  74  80  21  94]\n",
      "[ 8694.  8695.  8696.  8697.  8698.  8699.    87.   870.  8700.  8701.]\n",
      "[ 60 117 107  54 106  58  60   1  19  49]\n",
      "[ 8702.  8703.  8704.  8705.  8706.  8707.  8708.  8709.   871.  8710.]\n",
      "[  5  95  86  19  49  76 108  74  58  52]\n",
      "[ 8711.  8712.  8713.  8714.  8715.  8716.  8717.  8718.  8719.   872.]\n",
      "[110  24 122   2  80  74  98  35  56 110]\n",
      "[ 8720.  8721.  8722.  8723.  8724.  8725.  8726.  8727.  8728.  8729.]\n",
      "[ 54  28  95  49  10  74   2  67   5 109]\n",
      "[  873.  8730.  8731.  8732.  8733.  8734.  8735.  8736.  8737.  8738.]\n",
      "[ 85   1 127 106 117  78 107   6  74  26]\n",
      "[ 8739.   874.  8740.  8741.  8742.  8743.  8744.  8745.  8746.  8747.]\n",
      "[111 128  84 116  88  22 127  46  74  35]\n",
      "[ 8748.  8749.   875.  8750.  8751.  8752.  8753.  8754.  8755.  8756.]\n",
      "[ 33   7  79  65  63  35 111  23  17  20]\n",
      "[ 8757.  8758.  8759.   876.  8760.  8761.  8762.  8763.  8764.  8765.]\n",
      "[ 35 116 109  52  38  62 111  56  87  58]\n",
      "[ 8766.  8767.  8768.  8769.   877.  8770.  8771.  8772.  8773.  8774.]\n",
      "[ 28  40 122  45  22  94  33  79  54  68]\n",
      "[ 8775.  8776.  8777.  8778.  8779.   878.  8780.  8781.  8782.  8783.]\n",
      "[ 80   5  84 116  76  19 116  19  94  45]\n",
      "[ 8784.  8785.  8786.  8787.  8788.  8789.   879.  8790.  8791.  8792.]\n",
      "[85 83 71 20 61 94 27 23 81 46]\n",
      "[ 8793.  8794.  8795.  8796.  8797.  8798.  8799.    88.   880.  8800.]\n",
      "[ 35 123   8  20 107  94  43 106 110  19]\n",
      "[ 8801.  8802.  8803.  8804.  8805.  8806.  8807.  8808.  8809.   881.]\n",
      "[ 68  46  77  95  17  83  19  44  48 122]\n",
      "[ 8810.  8811.  8812.  8813.  8814.  8815.  8816.  8817.  8818.  8819.]\n",
      "[117  34  49  87  48  53  54  20  95  95]\n",
      "[  882.  8820.  8821.  8822.  8823.  8824.  8825.  8826.  8827.  8828.]\n",
      "[104  17  20  54  87  89 116  96 111  74]\n",
      "[ 8829.   883.  8830.  8831.  8832.  8833.  8834.  8835.  8836.  8837.]\n",
      "[  8  73 122 111  13  40  74  78  74  17]\n",
      "[ 8838.  8839.   884.  8840.  8841.  8842.  8843.  8844.  8845.  8846.]\n",
      "[ 96 108 108  78 107 117 111   7  20  68]\n",
      "[ 8847.  8848.  8849.   885.  8850.  8851.  8852.  8853.  8854.  8855.]\n",
      "[49 54 77 63  8 45  3 54 50 66]\n",
      "[ 8856.  8857.  8858.  8859.   886.  8860.  8861.  8862.  8863.  8864.]\n",
      "[ 5 48 83 11 52 20 87 98 53 35]\n",
      "[ 8865.  8866.  8867.  8868.  8869.   887.  8870.  8871.  8872.  8873.]\n",
      "[ 90  76 111  10 110 114 108  82  95 102]\n",
      "[ 8874.  8875.  8876.  8877.  8878.  8879.   888.  8880.  8881.  8882.]\n",
      "[ 63  66  57 101  52  83  83   8  19  22]\n",
      "[ 8883.  8884.  8885.  8886.  8887.  8888.  8889.   889.  8890.  8891.]\n",
      "[ 65  87  95  67 123  74  84  43  72 122]\n",
      "[ 8892.  8893.  8894.  8895.  8896.  8897.  8898.  8899.    89.   890.]\n",
      "[ 85 110  48 114 116 122 124  89 108 111]\n",
      "[ 8900.  8901.  8902.  8903.  8904.  8905.  8906.  8907.  8908.  8909.]\n",
      "[ 60  79  35  94  22   5  29 122  48   5]\n",
      "[  891.  8910.  8911.  8912.  8913.  8914.  8915.  8916.  8917.  8918.]\n",
      "[122 117  98  44  68 117  74 114  19 116]\n",
      "[ 8919.   892.  8920.  8921.  8922.  8923.  8924.  8925.  8926.  8927.]\n",
      "[ 83  94  13   9   8  87 106  86  17  38]\n",
      "[ 8928.  8929.   893.  8930.  8931.  8932.  8933.  8934.  8935.  8936.]\n",
      "[ 83  86  56  41 123 114  87  18  63  98]\n",
      "[ 8937.  8938.  8939.   894.  8940.  8941.  8942.  8943.  8944.  8945.]\n",
      "[ 40 121   7  99  68  43  20  20  21 117]\n",
      "[ 8946.  8947.  8948.  8949.   895.  8950.  8951.  8952.  8953.  8954.]\n",
      "[114  95  53  78 111  76  80  79  54  72]\n",
      "[ 8955.  8956.  8957.  8958.  8959.   896.  8960.  8961.  8962.  8963.]\n",
      "[ 71  95 107  11  35 121 122  74  52  58]\n",
      "[ 8964.  8965.  8966.  8967.  8968.  8969.   897.  8970.  8971.  8972.]\n",
      "[ 85  67  16  33   8  95 111  78  57  54]\n",
      "[ 8973.  8974.  8975.  8976.  8977.  8978.  8979.   898.  8980.  8981.]\n",
      "[ 83 122   5 111  95  79   7  83 106  53]\n",
      "[ 8982.  8983.  8984.  8985.  8986.  8987.  8988.  8989.   899.  8990.]\n",
      "[121  95 127  93  86  14  68  35   5 127]\n",
      "[ 8991.  8992.  8993.  8994.  8995.  8996.  8997.  8998.  8999.     9.]\n",
      "[107   9 107  76  74  63  98  43  20  19]\n",
      "[   90.   900.  9000.  9001.  9002.  9003.  9004.  9005.  9006.  9007.]\n",
      "[ 78 101  31  74 124  10  97  27  53  83]\n",
      "[ 9008.  9009.   901.  9010.  9011.  9012.  9013.  9014.  9015.  9016.]\n",
      "[116 110  44  84 112  86   9 111  54 108]\n",
      "[ 9017.  9018.  9019.   902.  9020.  9021.  9022.  9023.  9024.  9025.]\n",
      "[ 97 101  43 101  22  19  19 124  74 122]\n",
      "[ 9026.  9027.  9028.  9029.   903.  9030.  9031.  9032.  9033.  9034.]\n",
      "[ 19  52 101 126  98  53  45  37  19  74]\n",
      "[ 9035.  9036.  9037.  9038.  9039.   904.  9040.  9041.  9042.  9043.]\n",
      "[ 78 117  22   5  79   1  27  44  35  94]\n",
      "[ 9044.  9045.  9046.  9047.  9048.  9049.   905.  9050.  9051.  9052.]\n",
      "[  7  61  45  53  13  84 111 126 122  91]\n",
      "[ 9053.  9054.  9055.  9056.  9057.  9058.  9059.   906.  9060.  9061.]\n",
      "[ 67 111  45  52  10  73  56   5 122 108]\n",
      "[ 9062.  9063.  9064.  9065.  9066.  9067.  9068.  9069.   907.  9070.]\n",
      "[18 74 99 10 83 97  5 83 13 84]\n",
      "[ 9071.  9072.  9073.  9074.  9075.  9076.  9077.  9078.  9079.   908.]\n",
      "[ 11  28   1  11 122 112  48 108   3  14]\n",
      "[ 9080.  9081.  9082.  9083.  9084.  9085.  9086.  9087.  9088.  9089.]\n",
      "[ 14   4  79  88  96  95 123  14  14  54]\n",
      "[  909.  9090.  9091.  9092.  9093.  9094.  9095.  9096.  9097.  9098.]\n",
      "[ 19  95  74 116  44 103  75  66  78  78]\n",
      "[ 9099.    91.   910.  9100.  9101.  9102.  9103.  9104.  9105.  9106.]\n",
      "[112  78  98  74 108   1  65  91  19  14]\n",
      "[ 9107.  9108.  9109.   911.  9110.  9111.  9112.  9113.  9114.  9115.]\n",
      "[106 110  94  95  74  52  74   8  14  67]\n",
      "[ 9116.  9117.  9118.  9119.   912.  9120.  9121.  9122.  9123.  9124.]\n",
      "[ 45  73  54 101   4  49  81 106  88 111]\n",
      "[ 9125.  9126.  9127.  9128.  9129.   913.  9130.  9131.  9132.  9133.]\n",
      "[104 122  29  49  27  79  78  85  65  45]\n",
      "[ 9134.  9135.  9136.  9137.  9138.  9139.   914.  9140.  9141.  9142.]\n",
      "[101  67  17  88  94 114  13  54   1  54]\n",
      "[ 9143.  9144.  9145.  9146.  9147.  9148.  9149.   915.  9150.  9151.]\n",
      "[ 79  40  85  77 101  96 106 110 122  65]\n",
      "[ 9152.  9153.  9154.  9155.  9156.  9157.  9158.  9159.   916.  9160.]\n",
      "[ 17  20  85  72 110  23  83 126  26  85]\n",
      "[ 9161.  9162.  9163.  9164.  9165.  9166.  9167.  9168.  9169.   917.]\n",
      "[ 95  21 106  24  38 126  45 108   1  87]\n",
      "[ 9170.  9171.  9172.  9173.  9174.  9175.  9176.  9177.  9178.  9179.]\n",
      "[ 93 110  65 117   4  27  60  79  77  54]\n",
      "[  918.  9180.  9181.  9182.  9183.  9184.  9185.  9186.  9187.  9188.]\n",
      "[ 96 109  36 104 104  61  50  72  68  28]\n",
      "[ 9189.   919.  9190.  9191.  9192.  9193.  9194.  9195.  9196.  9197.]\n",
      "[117  40  96  79  45  96  43  28  79  17]\n",
      "[ 9198.  9199.    92.   920.  9200.  9201.  9202.  9203.  9204.  9205.]\n",
      "[ 19  33  67 124  58   4  76 122  10  45]\n",
      "[ 9206.  9207.  9208.  9209.   921.  9210.  9211.  9212.  9213.  9214.]\n",
      "[121 111  10   8  86  67  40  80   8  96]\n",
      "[ 9215.  9216.  9217.  9218.  9219.   922.  9220.  9221.  9222.  9223.]\n",
      "[ 98 121   5 124  45   8  67  40  27 106]\n",
      "[ 9224.  9225.  9226.  9227.  9228.  9229.   923.  9230.  9231.  9232.]\n",
      "[ 49  53  40  23  30  85   5  96 116  19]\n",
      "[ 9233.  9234.  9235.  9236.  9237.  9238.  9239.   924.  9240.  9241.]\n",
      "[ 96 108  38  75 123   7  43 106 128 123]\n",
      "[ 9242.  9243.  9244.  9245.  9246.  9247.  9248.  9249.   925.  9250.]\n",
      "[ 99  65  16  56 102  27  19  63  58  49]\n",
      "[ 9251.  9252.  9253.  9254.  9255.  9256.  9257.  9258.  9259.   926.]\n",
      "[ 18   9  97  45  49  45 102  98  83   7]\n",
      "[ 9260.  9261.  9262.  9263.  9264.  9265.  9266.  9267.  9268.  9269.]\n",
      "[122  72  58  10   8  83  35 123  79 126]\n",
      "[  927.  9270.  9271.  9272.  9273.  9274.  9275.  9276.  9277.  9278.]\n",
      "[ 45  39  63 106  85 111 108 124  16  76]\n",
      "[ 9279.   928.  9280.  9281.  9282.  9283.  9284.  9285.  9286.  9287.]\n",
      "[ 41  36  20  83  13   1  94  68 117  53]\n",
      "[ 9288.  9289.   929.  9290.  9291.  9292.  9293.  9294.  9295.  9296.]\n",
      "[83 90 28 78 18 46 84 94 68 85]\n",
      "[ 9297.  9298.  9299.    93.   930.  9300.  9301.  9302.  9303.  9304.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 78  96  17  87  10  82 114  77 111  42]\n",
      "[ 9305.  9306.  9307.  9308.  9309.   931.  9310.  9311.  9312.  9313.]\n",
      "[ 10  74  98  68 111  72  37  36  87 106]\n",
      "[ 9314.  9315.  9316.  9317.  9318.  9319.   932.  9320.  9321.  9322.]\n",
      "[122  83  68  74  49  53  83  28  78 109]\n",
      "[ 9323.  9324.  9325.  9326.  9327.  9328.  9329.   933.  9330.  9331.]\n",
      "[ 27   5   3 117  56 122  58  95  80  92]\n",
      "[ 9332.  9333.  9334.  9335.  9336.  9337.  9338.  9339.   934.  9340.]\n",
      "[ 45  38   1  20 110 104 117 127  97  96]\n",
      "[ 9341.  9342.  9343.  9344.  9345.  9346.  9347.  9348.  9349.   935.]\n",
      "[ 62  31  81  27 106 110  83  39  66  54]\n",
      "[ 9350.  9351.  9352.  9353.  9354.  9355.  9356.  9357.  9358.  9359.]\n",
      "[ 78  13  53  19  40  20 122  49 122  54]\n",
      "[  936.  9360.  9361.  9362.  9363.  9364.  9365.  9366.  9367.  9368.]\n",
      "[29 19  4 56 27 89 20 83 95 68]\n",
      "[ 9369.   937.  9370.  9371.  9372.  9373.  9374.  9375.  9376.  9377.]\n",
      "[ 95 127 108  99 103 108  48  75  10 123]\n",
      "[ 9378.  9379.   938.  9380.  9381.  9382.  9383.  9384.  9385.  9386.]\n",
      "[ 85  72  54  87  95  20 117  70  95  61]\n",
      "[ 9387.  9388.  9389.   939.  9390.  9391.  9392.  9393.  9394.  9395.]\n",
      "[ 61  54  96  57  29 107  87 108  54 107]\n",
      "[ 9396.  9397.  9398.  9399.    94.   940.  9400.  9401.  9402.  9403.]\n",
      "[ 79  95  63 111  11  74  75   3  19  90]\n",
      "[ 9404.  9405.  9406.  9407.  9408.  9409.   941.  9410.  9411.  9412.]\n",
      "[ 31  83  40  79 110 111 122  85   5  68]\n",
      "[ 9413.  9414.  9415.  9416.  9417.  9418.  9419.   942.  9420.  9421.]\n",
      "[ 93  45 110   4   4   7 121  13  50 121]\n",
      "[ 9422.  9423.  9424.  9425.  9426.  9427.  9428.  9429.   943.  9430.]\n",
      "[ 85  52  20  23  23  67  19  38  68 106]\n",
      "[ 9431.  9432.  9433.  9434.  9435.  9436.  9437.  9438.  9439.   944.]\n",
      "[ 8 98 20 90 38 54 40 67 85  8]\n",
      "[ 9440.  9441.  9442.  9443.  9444.  9445.  9446.  9447.  9448.  9449.]\n",
      "[  3  67  54  20 106  79  45  46  19  79]\n",
      "[  945.  9450.  9451.  9452.  9453.  9454.  9455.  9456.  9457.  9458.]\n",
      "[ 93  67 122  10 123  16  11  95  31 122]\n",
      "[ 9459.   946.  9460.  9461.  9462.  9463.  9464.  9465.  9466.  9467.]\n",
      "[101 106  83   7  44  79  83  48  19  86]\n",
      "[ 9468.  9469.   947.  9470.  9471.  9472.  9473.  9474.  9475.  9476.]\n",
      "[ 77  28  20 107  79  58  53 117   5  20]\n",
      "[ 9477.  9478.  9479.   948.  9480.  9481.  9482.  9483.  9484.  9485.]\n",
      "[86 80 67 54 79 11 60 50 48  5]\n",
      "[ 9486.  9487.  9488.  9489.   949.  9490.  9491.  9492.  9493.  9494.]\n",
      "[ 58  43  50  46 108  24  74  39  85  58]\n",
      "[ 9495.  9496.  9497.  9498.  9499.    95.   950.  9500.  9501.  9502.]\n",
      "[ 78  24  54 122 110  67  39 121 113  67]\n",
      "[ 9503.  9504.  9505.  9506.  9507.  9508.  9509.   951.  9510.  9511.]\n",
      "[128  27   6 113 106  83  44  80  75  38]\n",
      "[ 9512.  9513.  9514.  9515.  9516.  9517.  9518.  9519.   952.  9520.]\n",
      "[  2  53  94  65  79  53  19 108  62  68]\n",
      "[ 9521.  9522.  9523.  9524.  9525.  9526.  9527.  9528.  9529.   953.]\n",
      "[116  86  62 110   6 117  79  85  45  96]\n",
      "[ 9530.  9531.  9532.  9533.  9534.  9535.  9536.  9537.  9538.  9539.]\n",
      "[ 52  67  27  31 116  65   8  28  68  94]\n",
      "[  954.  9540.  9541.  9542.  9543.  9544.  9545.  9546.  9547.  9548.]\n",
      "[ 74  76  96 117  11  20  40   1  10  35]\n",
      "[ 9549.   955.  9550.  9551.  9552.  9553.  9554.  9555.  9556.  9557.]\n",
      "[ 83  20  78  49  68 122  83  39  53   3]\n",
      "[ 9558.  9559.   956.  9560.  9561.  9562.  9563.  9564.  9565.  9566.]\n",
      "[  4  40  41 122  16  19  41  26  94  10]\n",
      "[ 9567.  9568.  9569.   957.  9570.  9571.  9572.  9573.  9574.  9575.]\n",
      "[ 28  69 109  45  28 121 122  33  78  27]\n",
      "[ 9576.  9577.  9578.  9579.   958.  9580.  9581.  9582.  9583.  9584.]\n",
      "[112  90  13  99 126  95   4  22  54 117]\n",
      "[ 9585.  9586.  9587.  9588.  9589.   959.  9590.  9591.  9592.  9593.]\n",
      "[ 96   2  93  74 108  73 121  19  16  37]\n",
      "[ 9594.  9595.  9596.  9597.  9598.  9599.    96.   960.  9600.  9601.]\n",
      "[63 48 64 78 78  1 80 77 53 35]\n",
      "[ 9602.  9603.  9604.  9605.  9606.  9607.  9608.  9609.   961.  9610.]\n",
      "[31 44 96 43 56 94 22 86 81 84]\n",
      "[ 9611.  9612.  9613.  9614.  9615.  9616.  9617.  9618.  9619.   962.]\n",
      "[107  87  80  54  74  61  54  54  38  44]\n",
      "[ 9620.  9621.  9622.  9623.  9624.  9625.  9626.  9627.  9628.  9629.]\n",
      "[104  40  11  81  13  64  20  85  45  20]\n",
      "[  963.  9630.  9631.  9632.  9633.  9634.  9635.  9636.  9637.  9638.]\n",
      "[ 83 116  65   3 115 108  53  50  20  93]\n",
      "[ 9639.   964.  9640.  9641.  9642.  9643.  9644.  9645.  9646.  9647.]\n",
      "[ 98 107  28 106  50   7   4  74  94   5]\n",
      "[ 9648.  9649.   965.  9650.  9651.  9652.  9653.  9654.  9655.  9656.]\n",
      "[ 94  96 123  46  38 122 118  11  76  33]\n",
      "[ 9657.  9658.  9659.   966.  9660.  9661.  9662.  9663.  9664.  9665.]\n",
      "[110  68  40  46  68  97  19 111  38  99]\n",
      "[ 9666.  9667.  9668.  9669.   967.  9670.  9671.  9672.  9673.  9674.]\n",
      "[ 82  94  27  80 116   3 117   9  49  27]\n",
      "[ 9675.  9676.  9677.  9678.  9679.   968.  9680.  9681.  9682.  9683.]\n",
      "[128  39  19 104  27  57   8  82  13  10]\n",
      "[ 9684.  9685.  9686.  9687.  9688.  9689.   969.  9690.  9691.  9692.]\n",
      "[ 83  82  45  95  18  78 110 102 128 106]\n",
      "[ 9693.  9694.  9695.  9696.  9697.  9698.  9699.    97.   970.  9700.]\n",
      "[ 68  58  88  35 117  74  27  18  68  95]\n",
      "[ 9701.  9702.  9703.  9704.  9705.  9706.  9707.  9708.  9709.   971.]\n",
      "[  8  96  79   3  19 108  96  28   9   1]\n",
      "[ 9710.  9711.  9712.  9713.  9714.  9715.  9716.  9717.  9718.  9719.]\n",
      "[ 80  58  34  66  83 117  14  40  65  31]\n",
      "[  972.  9720.  9721.  9722.  9723.  9724.  9725.  9726.  9727.  9728.]\n",
      "[94 62  2 38 99 80 20 45 72 68]\n",
      "[ 9729.   973.  9730.  9731.  9732.  9733.  9734.  9735.  9736.  9737.]\n",
      "[ 95  31  40  19  77   5 124  76 107  78]\n",
      "[ 9738.  9739.   974.  9740.  9741.  9742.  9743.  9744.  9745.  9746.]\n",
      "[ 78  56  11 114  22  79 114  20  80  62]\n",
      "[ 9747.  9748.  9749.   975.  9750.  9751.  9752.  9753.  9754.  9755.]\n",
      "[ 28  40 107 117  40  52  20  65  68  87]\n",
      "[ 9756.  9757.  9758.  9759.   976.  9760.  9761.  9762.  9763.  9764.]\n",
      "[117  40  28  85  51 101  63  97  74 102]\n",
      "[ 9765.  9766.  9767.  9768.  9769.   977.  9770.  9771.  9772.  9773.]\n",
      "[ 67  67  78 108  46  11  28  46  56  99]\n",
      "[ 9774.  9775.  9776.  9777.  9778.  9779.   978.  9780.  9781.  9782.]\n",
      "[80 73 28 96 64 49 78 95 79 41]\n",
      "[ 9783.  9784.  9785.  9786.  9787.  9788.  9789.   979.  9790.  9791.]\n",
      "[  5  67  95   3  74   7  29  98 104  19]\n",
      "[ 9792.  9793.  9794.  9795.  9796.  9797.  9798.  9799.    98.   980.]\n",
      "[ 67  97  78 117   4  20  78  83  96  86]\n",
      "[ 9800.  9801.  9802.  9803.  9804.  9805.  9806.  9807.  9808.  9809.]\n",
      "[122  58 117  11  91   9   9  11  20  54]\n",
      "[  981.  9810.  9811.  9812.  9813.  9814.  9815.  9816.  9817.  9818.]\n",
      "[ 54  96  83 122  33  89  28  23 113   7]\n",
      "[ 9819.   982.  9820.  9821.  9822.  9823.  9824.  9825.  9826.  9827.]\n",
      "[101 117   3 122  74   8  88  35  18   7]\n",
      "[ 9828.  9829.   983.  9830.  9831.  9832.  9833.  9834.  9835.  9836.]\n",
      "[  3 121  40 110  97  87 109  94  16  45]\n",
      "[ 9837.  9838.  9839.   984.  9840.  9841.  9842.  9843.  9844.  9845.]\n",
      "[ 74  28  19  49  21  79  74 121   8  10]\n",
      "[ 9846.  9847.  9848.  9849.   985.  9850.  9851.  9852.  9853.  9854.]\n",
      "[104 122 111  13  85  31 124  67  53  83]\n",
      "[ 9855.  9856.  9857.  9858.  9859.   986.  9860.  9861.  9862.  9863.]\n",
      "[  1  23  53  96  45  86  46 123  54   6]\n",
      "[ 9864.  9865.  9866.  9867.  9868.  9869.   987.  9870.  9871.  9872.]\n",
      "[ 94  19  10  27  19  94 115  81   8  77]\n",
      "[ 9873.  9874.  9875.  9876.  9877.  9878.  9879.   988.  9880.  9881.]\n",
      "[117  96  27 122 111  98  27  72  19  19]\n",
      "[ 9882.  9883.  9884.  9885.  9886.  9887.  9888.  9889.   989.  9890.]\n",
      "[ 23  67 117  54  36  54 108   9  80  86]\n",
      "[ 9891.  9892.  9893.  9894.  9895.  9896.  9897.  9898.  9899.    99.]\n",
      "[ 17  20  40 107  23  81  14  45  17  34]\n",
      "[  990.  9900.  9901.  9902.  9903.  9904.  9905.  9906.  9907.  9908.]\n",
      "[  9  74  29 114  68  89  97  35 121  95]\n",
      "[ 9909.   991.  9910.  9911.  9912.  9913.  9914.  9915.  9916.  9917.]\n",
      "[ 51  97  98 116  86 106 109  43  62  67]\n",
      "[ 9918.  9919.   992.  9920.  9921.  9922.  9923.  9924.  9925.  9926.]\n",
      "[116  37  10  67 113 115 122 126  24  47]\n",
      "[ 9927.  9928.  9929.   993.  9930.  9931.  9932.  9933.  9934.  9935.]\n",
      "[ 11 108  58  50 108  40  27  63  85  26]\n",
      "[ 9936.  9937.  9938.  9939.   994.  9940.  9941.  9942.  9943.  9944.]\n",
      "[94 76 76 78 68 83 70 87 52 65]\n",
      "[ 9945.  9946.  9947.  9948.  9949.   995.  9950.  9951.  9952.  9953.]\n",
      "[122   7  41 103 108 111 107 108   3  27]\n",
      "[ 9954.  9955.  9956.  9957.  9958.  9959.   996.  9960.  9961.  9962.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123  22  83 124  30  94  85  88  35 124]\n",
      "[ 9963.  9964.  9965.  9966.  9967.  9968.  9969.   997.  9970.  9971.]\n",
      "[ 38  74 108   3 123  62  57  65  65  28]\n",
      "[ 9972.  9973.  9974.  9975.  9976.  9977.  9978.  9979.   998.  9980.]\n",
      "[ 31  19  62 117  28 122  93  18 111  90]\n",
      "[ 9981.  9982.  9983.  9984.  9985.  9986.  9987.  9988.  9989.   999.]\n",
      "[ 83  58 106  67 108  23  53  83   8  83]\n",
      "[ 9990.  9991.  9992.  9993.  9994.  9995.  9996.  9997.  9998.  9999.]\n"
     ]
    }
   ],
   "source": [
    "total_test_count = len(X_test)\n",
    "correct_test_count = 0\n",
    "test_batch_size = 10\n",
    "total_test_batch = int(total_test_count/test_batch_size)\n",
    "#for i in range(total_test_batch):\n",
    "with open('pred.txt', 'w') as text_file:\n",
    "    for i in range(total_test_batch):\n",
    "        batch_test_x, x_id = X_test[i*test_batch_size:i*test_batch_size+test_batch_size], Y_test[i*test_batch_size:i*test_batch_size+test_batch_size]\n",
    "        pred = sess.run(prediction, feed_dict = {imgs: batch_test_x})\n",
    "        print(pred)\n",
    "        print(x_id[:])\n",
    "        for i in range(len(x_id)):\n",
    "            text_file.write('{0},{1}\\n'.format(int(x_id[i])+1,pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
